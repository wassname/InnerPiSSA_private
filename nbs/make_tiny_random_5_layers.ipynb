{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba04423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92360547b4d84cff95592ecaf1753221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb0242635f3490fa15a7b55c29d35e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf37d6df3ec43558bebd236fc074b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d6a8e401104586862fb533cd61dd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64916fb4d05c4fd0bc3af5e2131d4ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/728 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99328c1e5e934257afb40ce232c68d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight torch.Size([151936, 64])\n",
      "model.layers.0.input_layernorm.weight torch.Size([64])\n",
      "model.layers.0.mlp.down_proj.weight torch.Size([64, 128])\n",
      "model.layers.0.mlp.gate_proj.weight torch.Size([128, 64])\n",
      "model.layers.0.mlp.up_proj.weight torch.Size([128, 64])\n",
      "model.layers.0.post_attention_layernorm.weight torch.Size([64])\n",
      "model.layers.0.self_attn.k_norm.weight torch.Size([32])\n",
      "model.layers.0.self_attn.k_proj.weight torch.Size([32, 64])\n",
      "model.layers.0.self_attn.o_proj.weight torch.Size([64, 64])\n",
      "model.layers.0.self_attn.q_norm.weight torch.Size([32])\n",
      "model.layers.0.self_attn.q_proj.weight torch.Size([64, 64])\n",
      "model.layers.0.self_attn.v_proj.weight torch.Size([32, 64])\n",
      "model.layers.1.input_layernorm.weight torch.Size([64])\n",
      "model.layers.1.mlp.down_proj.weight torch.Size([64, 128])\n",
      "model.layers.1.mlp.gate_proj.weight torch.Size([128, 64])\n",
      "model.layers.1.mlp.up_proj.weight torch.Size([128, 64])\n",
      "model.layers.1.post_attention_layernorm.weight torch.Size([64])\n",
      "model.layers.1.self_attn.k_norm.weight torch.Size([32])\n",
      "model.layers.1.self_attn.k_proj.weight torch.Size([32, 64])\n",
      "model.layers.1.self_attn.o_proj.weight torch.Size([64, 64])\n",
      "model.layers.1.self_attn.q_norm.weight torch.Size([32])\n",
      "model.layers.1.self_attn.q_proj.weight torch.Size([64, 64])\n",
      "model.layers.1.self_attn.v_proj.weight torch.Size([32, 64])\n",
      "model.layers.2.input_layernorm.weight torch.Size([64])\n",
      "model.layers.2.mlp.down_proj.weight torch.Size([64, 128])\n",
      "model.layers.2.mlp.gate_proj.weight torch.Size([128, 64])\n",
      "model.layers.2.mlp.up_proj.weight torch.Size([128, 64])\n",
      "model.layers.2.post_attention_layernorm.weight torch.Size([64])\n",
      "model.layers.2.self_attn.k_norm.weight torch.Size([32])\n",
      "model.layers.2.self_attn.k_proj.weight torch.Size([32, 64])\n",
      "model.layers.2.self_attn.o_proj.weight torch.Size([64, 64])\n",
      "model.layers.2.self_attn.q_norm.weight torch.Size([32])\n",
      "model.layers.2.self_attn.q_proj.weight torch.Size([64, 64])\n",
      "model.layers.2.self_attn.v_proj.weight torch.Size([32, 64])\n",
      "model.layers.3.input_layernorm.weight torch.Size([64])\n",
      "model.layers.3.mlp.down_proj.weight torch.Size([64, 128])\n",
      "model.layers.3.mlp.gate_proj.weight torch.Size([128, 64])\n",
      "model.layers.3.mlp.up_proj.weight torch.Size([128, 64])\n",
      "model.layers.3.post_attention_layernorm.weight torch.Size([64])\n",
      "model.layers.3.self_attn.k_norm.weight torch.Size([32])\n",
      "model.layers.3.self_attn.k_proj.weight torch.Size([32, 64])\n",
      "model.layers.3.self_attn.o_proj.weight torch.Size([64, 64])\n",
      "model.layers.3.self_attn.q_norm.weight torch.Size([32])\n",
      "model.layers.3.self_attn.q_proj.weight torch.Size([64, 64])\n",
      "model.layers.3.self_attn.v_proj.weight torch.Size([32, 64])\n",
      "model.layers.4.input_layernorm.weight torch.Size([64])\n",
      "model.layers.4.mlp.down_proj.weight torch.Size([64, 128])\n",
      "model.layers.4.mlp.gate_proj.weight torch.Size([128, 64])\n",
      "model.layers.4.mlp.up_proj.weight torch.Size([128, 64])\n",
      "model.layers.4.post_attention_layernorm.weight torch.Size([64])\n",
      "model.layers.4.self_attn.k_norm.weight torch.Size([32])\n",
      "model.layers.4.self_attn.k_proj.weight torch.Size([32, 64])\n",
      "model.layers.4.self_attn.o_proj.weight torch.Size([64, 64])\n",
      "model.layers.4.self_attn.q_norm.weight torch.Size([32])\n",
      "model.layers.4.self_attn.q_proj.weight torch.Size([64, 64])\n",
      "model.layers.4.self_attn.v_proj.weight torch.Size([32, 64])\n",
      "model.norm.weight torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    GenerationConfig,\n",
    "    pipeline,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "source_model_id = \"Qwen/Qwen3-32B\"\n",
    "save_folder = \"/tmp/tiny-random/qwen3-5lyr\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    source_model_id, trust_remote_code=True,\n",
    ")\n",
    "tokenizer.save_pretrained(save_folder)\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    source_model_id, trust_remote_code=True,\n",
    ")\n",
    "config._name_or_path = source_model_id\n",
    "config.hidden_size = 64\n",
    "config.intermediate_size = 128\n",
    "config.head_dim = 32\n",
    "config.num_key_value_heads = 1\n",
    "config.num_attention_heads = 2\n",
    "config.num_hidden_layers = 10 # modified from https://huggingface.co/tiny-random/qwen3\n",
    "config.max_window_layers = 1\n",
    "config.tie_word_embeddings = True\n",
    "model = AutoModelForCausalLM.from_config(\n",
    "    config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "model.generation_config = GenerationConfig.from_pretrained(\n",
    "    source_model_id, trust_remote_code=True,\n",
    ")\n",
    "set_seed(42)\n",
    "with torch.no_grad():\n",
    "    for name, p in sorted(model.named_parameters()):\n",
    "        torch.nn.init.normal_(p, 0, 0.5)\n",
    "        print(name, p.shape)\n",
    "model.save_pretrained(save_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836915cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1012bbc9e2dd4d07976f0818d24aa729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d204e59c6e4dea888c45c772cf6af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/wassname/qwen3-5lyr-tiny-random/commit/33d6ab9aaf190f7cd174d0e36e4c293171a42dc7', commit_message='Upload Qwen3ForCausalLM', commit_description='', oid='33d6ab9aaf190f7cd174d0e36e4c293171a42dc7', pr_url=None, repo_url=RepoUrl('https://huggingface.co/wassname/qwen3-5lyr-tiny-random', endpoint='https://huggingface.co', repo_type='model', repo_id='wassname/qwen3-5lyr-tiny-random'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# push to the hub\n",
    "model.push_to_hub(\"wassname/qwen3-10lyr-tiny-random\", trust_remote_code=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipissa (3.11.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

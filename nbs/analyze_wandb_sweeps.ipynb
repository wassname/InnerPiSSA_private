{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a129dc",
   "metadata": {},
   "source": [
    "# InnerPiSSA  Analyse sweeps and ablations\n",
    "## Analysis Principles\n",
    "\n",
    "**Main metric**: `ipissa_vh_range` = T_test / nll_degradation\n",
    "- T_test = slope of logprob vs coefficient (steering effect)\n",
    "- nll_degradation = coherence loss (model quality preservation)\n",
    "- This is the primary metric for comparing methods\n",
    "\n",
    "**Auxiliary metrics**:\n",
    "- `symmetry`: min(|neg-zero|, |pos-zero|) / max(...) - how symmetric is bidirectional steering\n",
    "- `loss_gap`: val_loss - train_loss - overfitting indicator\n",
    "\n",
    "**Comparison principles**:\n",
    "1. **Best vs mean baseline**: Use mean of baseline runs (not best) - best is sensitive to n_runs\n",
    "2. **Within-sweep comparisons**: Control for model/hyperparams when analyzing sweep variables\n",
    "3. **Exclude intentionally-broken runs**: lr=1.0, lr=1e-6 are ablation failures, not fair comparisons\n",
    "4. **Resistance by metric sign**: \"honest\" vs \"dishonest\" direction, not arbitrary coefficient sign\n",
    "\n",
    "**Color conventions**:\n",
    "- Red = toward honest (positive ipissa_range)\n",
    "- Blue = toward dishonest (negative ipissa_range)\n",
    "- Green = low gap (good coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd0ed544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "from ipissa.config import proj_root\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce6cec7",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ac6abbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs: 687\n",
      "Runs with prompting baseline: 470\n",
      "\n",
      "Baseline scores by model:\n",
      "  wassname/qwen-14B-codefourchan: prompting=339.7, repeng=171.5\n",
      "  unsloth/Llama-3.1-8B-Instruct: prompting=293.9, repeng=996.0\n",
      "  google/gemma-3-4b-it: prompting=277.2, repeng=1.9\n",
      "  google/gemma-3-270m-it: prompting=nan, repeng=nan\n",
      "  google/gemma-3-1b-it: prompting=nan, repeng=nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>created_at</th>\n",
       "      <th>url</th>\n",
       "      <th>log_file</th>\n",
       "      <th>args</th>\n",
       "      <th>run_group</th>\n",
       "      <th>git_commit</th>\n",
       "      <th>gpu</th>\n",
       "      <th>layer_num</th>\n",
       "      <th>main_metric</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vh_neg</th>\n",
       "      <th>vh_zero</th>\n",
       "      <th>vh_pos</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>resistant_toward</th>\n",
       "      <th>baseline_effect_InnerPiSSA</th>\n",
       "      <th>baseline_effect_s_steer</th>\n",
       "      <th>baseline_effect_pca</th>\n",
       "      <th>baseline_effect_prompting</th>\n",
       "      <th>baseline_effect_repeng</th>\n",
       "      <th>val_loss_total</th>\n",
       "      <th>val_loss_proj</th>\n",
       "      <th>val_loss_coh</th>\n",
       "      <th>val_loss_monotonic</th>\n",
       "      <th>val_proj_diff</th>\n",
       "      <th>val_logp_degradation</th>\n",
       "      <th>train_loss_total</th>\n",
       "      <th>train_loss_proj</th>\n",
       "      <th>train_loss_coh</th>\n",
       "      <th>train_loss_monotonic</th>\n",
       "      <th>train_proj_diff</th>\n",
       "      <th>train_logp_degradation</th>\n",
       "      <th>_runtime</th>\n",
       "      <th>_step</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>_wandb</th>\n",
       "      <th>coh_deg</th>\n",
       "      <th>cw</th>\n",
       "      <th>delta_logp_change</th>\n",
       "      <th>eval/baseline_InnerPiSSA (ours)</th>\n",
       "      <th>eval/baseline_prompting</th>\n",
       "      <th>eval/baseline_repeng</th>\n",
       "      <th>eval/coherence_metrics</th>\n",
       "      <th>eval/effect_sizes_CI95</th>\n",
       "      <th>eval/effect_sizes_Pearson</th>\n",
       "      <th>eval/effect_sizes_Slope</th>\n",
       "      <th>eval/effect_sizes_Slope*(1-p)</th>\n",
       "      <th>eval/effect_sizes_Spearman</th>\n",
       "      <th>eval/effect_sizes_T-stat</th>\n",
       "      <th>eval/main_metric</th>\n",
       "      <th>eval/transfer_summary</th>\n",
       "      <th>eval/value_scores</th>\n",
       "      <th>flip_ema</th>\n",
       "      <th>loss_coh</th>\n",
       "      <th>loss_monotonic</th>\n",
       "      <th>loss_proj</th>\n",
       "      <th>loss_proj_flipped</th>\n",
       "      <th>loss_total</th>\n",
       "      <th>lr</th>\n",
       "      <th>module</th>\n",
       "      <th>mono_direction</th>\n",
       "      <th>mono_ema</th>\n",
       "      <th>mono_frac_violated</th>\n",
       "      <th>mono_violation</th>\n",
       "      <th>prob_ratio</th>\n",
       "      <th>proj_diff</th>\n",
       "      <th>proj_pi</th>\n",
       "      <th>proj_ref</th>\n",
       "      <th>separation_norm</th>\n",
       "      <th>train/by_coef/coh_deg_coef+1_0</th>\n",
       "      <th>train/by_coef/coh_deg_coef-1_0</th>\n",
       "      <th>train/by_coef/cw_coef+1_0</th>\n",
       "      <th>train/by_coef/cw_coef-1_0</th>\n",
       "      <th>train/by_coef/delta_logp_change_coef+1_0</th>\n",
       "      <th>train/by_coef/delta_logp_change_coef-1_0</th>\n",
       "      <th>train/by_coef/flip_ema_coef+1_0</th>\n",
       "      <th>train/by_coef/flip_ema_coef-1_0</th>\n",
       "      <th>train/by_coef/loss_coh_coef+1_0</th>\n",
       "      <th>train/by_coef/loss_coh_coef-1_0</th>\n",
       "      <th>train/by_coef/loss_monotonic_coef+1_0</th>\n",
       "      <th>train/by_coef/loss_monotonic_coef-1_0</th>\n",
       "      <th>train/by_coef/loss_proj_coef+1_0</th>\n",
       "      <th>train/by_coef/loss_proj_coef-1_0</th>\n",
       "      <th>train/by_coef/loss_proj_flipped_coef+1_0</th>\n",
       "      <th>train/by_coef/loss_proj_flipped_coef-1_0</th>\n",
       "      <th>train/by_coef/loss_total_coef+1_0</th>\n",
       "      <th>train/by_coef/loss_total_coef-1_0</th>\n",
       "      <th>train/by_coef/lr_coef+1_0</th>\n",
       "      <th>train/by_coef/lr_coef-1_0</th>\n",
       "      <th>train/by_coef/mono_direction_coef+1_0</th>\n",
       "      <th>train/by_coef/mono_direction_coef-1_0</th>\n",
       "      <th>train/by_coef/mono_ema_coef+1_0</th>\n",
       "      <th>train/by_coef/mono_ema_coef-1_0</th>\n",
       "      <th>train/by_coef/mono_frac_violated_coef+1_0</th>\n",
       "      <th>train/by_coef/mono_frac_violated_coef-1_0</th>\n",
       "      <th>train/by_coef/mono_violation_coef+1_0</th>\n",
       "      <th>train/by_coef/mono_violation_coef-1_0</th>\n",
       "      <th>train/by_coef/prob_ratio_coef+1_0</th>\n",
       "      <th>train/by_coef/prob_ratio_coef-1_0</th>\n",
       "      <th>train/by_coef/proj_diff_coef+1_0</th>\n",
       "      <th>train/by_coef/proj_diff_coef-1_0</th>\n",
       "      <th>train/by_coef/proj_pi_coef+1_0</th>\n",
       "      <th>train/by_coef/proj_pi_coef-1_0</th>\n",
       "      <th>train/by_coef/proj_ref_coef+1_0</th>\n",
       "      <th>train/by_coef/proj_ref_coef-1_0</th>\n",
       "      <th>train/by_coef/separation_norm_coef+1_0</th>\n",
       "      <th>train/by_coef/separation_norm_coef-1_0</th>\n",
       "      <th>val/by_coef/coh_deg_coef+1_0</th>\n",
       "      <th>val/by_coef/coh_deg_coef-1_0</th>\n",
       "      <th>val/by_coef/cw_coef+1_0</th>\n",
       "      <th>val/by_coef/cw_coef-1_0</th>\n",
       "      <th>val/by_coef/delta_logp_change_coef+1_0</th>\n",
       "      <th>val/by_coef/delta_logp_change_coef-1_0</th>\n",
       "      <th>val/by_coef/loss_coh_coef+1_0</th>\n",
       "      <th>val/by_coef/loss_coh_coef-1_0</th>\n",
       "      <th>val/by_coef/loss_monotonic_coef+1_0</th>\n",
       "      <th>val/by_coef/loss_monotonic_coef-1_0</th>\n",
       "      <th>val/by_coef/loss_proj_coef+1_0</th>\n",
       "      <th>val/by_coef/loss_proj_coef-1_0</th>\n",
       "      <th>val/by_coef/loss_proj_flipped_coef+1_0</th>\n",
       "      <th>val/by_coef/loss_proj_flipped_coef-1_0</th>\n",
       "      <th>val/by_coef/loss_total_coef+1_0</th>\n",
       "      <th>val/by_coef/loss_total_coef-1_0</th>\n",
       "      <th>val/by_coef/mono_direction_coef+1_0</th>\n",
       "      <th>val/by_coef/mono_direction_coef-1_0</th>\n",
       "      <th>val/by_coef/mono_frac_violated_coef+1_0</th>\n",
       "      <th>val/by_coef/mono_frac_violated_coef-1_0</th>\n",
       "      <th>val/by_coef/mono_violation_coef+1_0</th>\n",
       "      <th>val/by_coef/mono_violation_coef-1_0</th>\n",
       "      <th>val/by_coef/prob_ratio_coef+1_0</th>\n",
       "      <th>val/by_coef/prob_ratio_coef-1_0</th>\n",
       "      <th>val/by_coef/proj_diff_coef+1_0</th>\n",
       "      <th>val/by_coef/proj_diff_coef-1_0</th>\n",
       "      <th>val/by_coef/proj_pi_coef+1_0</th>\n",
       "      <th>val/by_coef/proj_pi_coef-1_0</th>\n",
       "      <th>val/by_coef/proj_ref_coef+1_0</th>\n",
       "      <th>val/by_coef/proj_ref_coef-1_0</th>\n",
       "      <th>val/by_coef/separation_norm_coef+1_0</th>\n",
       "      <th>val/by_coef/separation_norm_coef-1_0</th>\n",
       "      <th>val/coh_deg</th>\n",
       "      <th>val/cw</th>\n",
       "      <th>val/delta_logp_change</th>\n",
       "      <th>val/loss_coh</th>\n",
       "      <th>val/loss_monotonic</th>\n",
       "      <th>val/loss_proj</th>\n",
       "      <th>val/loss_proj_flipped</th>\n",
       "      <th>val/loss_total</th>\n",
       "      <th>val/mono_direction</th>\n",
       "      <th>val/mono_frac_violated</th>\n",
       "      <th>val/mono_violation</th>\n",
       "      <th>val/prob_ratio</th>\n",
       "      <th>val/proj_diff</th>\n",
       "      <th>val/proj_pi</th>\n",
       "      <th>val/proj_ref</th>\n",
       "      <th>val/separation_norm</th>\n",
       "      <th>r</th>\n",
       "      <th>bs</th>\n",
       "      <th>wd</th>\n",
       "      <th>coh</th>\n",
       "      <th>mono</th>\n",
       "      <th>quick</th>\n",
       "      <th>rot_u</th>\n",
       "      <th>rot_v</th>\n",
       "      <th>PROMPT</th>\n",
       "      <th>n_logs</th>\n",
       "      <th>modules</th>\n",
       "      <th>scale_s</th>\n",
       "      <th>verbose</th>\n",
       "      <th>PERSONAS</th>\n",
       "      <th>coh_temp</th>\n",
       "      <th>n_depths</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>depth_end</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>use_wandb</th>\n",
       "      <th>val_split</th>\n",
       "      <th>coh_thresh</th>\n",
       "      <th>coh_weight</th>\n",
       "      <th>loss_use_V</th>\n",
       "      <th>model_name</th>\n",
       "      <th>output_dir</th>\n",
       "      <th>wandb_tags</th>\n",
       "      <th>depth_start</th>\n",
       "      <th>loss_depths</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>mono_margin</th>\n",
       "      <th>mono_weight</th>\n",
       "      <th>adapter_type</th>\n",
       "      <th>coh_adaptive</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>effective_bs</th>\n",
       "      <th>loss_modules</th>\n",
       "      <th>n_last_tokens</th>\n",
       "      <th>wandb_project</th>\n",
       "      <th>data_aware_init</th>\n",
       "      <th>eval_max_tokens</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>save_checkpoints</th>\n",
       "      <th>eval_max_dilemmas</th>\n",
       "      <th>quantization_type</th>\n",
       "      <th>max_rotation_angle</th>\n",
       "      <th>early_stop_patience</th>\n",
       "      <th>loss_snorm</th>\n",
       "      <th>pref_dir_k</th>\n",
       "      <th>pref_dir_method</th>\n",
       "      <th>val_every_n_samples</th>\n",
       "      <th>eval/baseline_S-space steer</th>\n",
       "      <th>eval/baseline_pca (wassname)</th>\n",
       "      <th>s_selection_mode</th>\n",
       "      <th>loss_gap</th>\n",
       "      <th>prompting_score</th>\n",
       "      <th>repeng_score</th>\n",
       "      <th>gain_vs_prompting</th>\n",
       "      <th>gain_vs_repeng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qwtkm93m</td>\n",
       "      <td>q14b-c4c-raw-r128</td>\n",
       "      <td>finished</td>\n",
       "      <td>2025-11-27T08:17:03Z</td>\n",
       "      <td>https://wandb.ai/wassname/InnerPiSSA/runs/qwtk...</td>\n",
       "      <td>/media/wassname/SGIronWolf/projects5/2025/llm_...</td>\n",
       "      <td>q14b-80gb --model_name=wassname/qwen-14B-codef...</td>\n",
       "      <td>ablation-20251127-0813</td>\n",
       "      <td>7ec1d8d80bec4b43396bde3b546e2a5b4f508d33</td>\n",
       "      <td>NVIDIA A100-SXM4-80GB</td>\n",
       "      <td>36</td>\n",
       "      <td>419.813115</td>\n",
       "      <td>1483</td>\n",
       "      <td>-0.8108</td>\n",
       "      <td>-0.6733</td>\n",
       "      <td>-0.4864</td>\n",
       "      <td>0.735688</td>\n",
       "      <td>dishonest</td>\n",
       "      <td>-0.673339</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>-0.390598</td>\n",
       "      <td>-0.680650</td>\n",
       "      <td>-11.302973</td>\n",
       "      <td>-6.914284</td>\n",
       "      <td>0.285055</td>\n",
       "      <td>1.955485</td>\n",
       "      <td>-6.914284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.359199</td>\n",
       "      <td>-6.679599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.679599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1483</td>\n",
       "      <td>708</td>\n",
       "      <td>1.764233e+09</td>\n",
       "      <td>{'runtime': 1483}</td>\n",
       "      <td>-0.024508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.018907</td>\n",
       "      <td>-0.673339</td>\n",
       "      <td>-0.390598</td>\n",
       "      <td>-0.680650</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>419.813115</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>13.922856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.679599</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.359199</td>\n",
       "      <td>0.004</td>\n",
       "      <td>base_model.model.model.layers.36.mlp.up_proj</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975806</td>\n",
       "      <td>-6.679599</td>\n",
       "      <td>-51.683073</td>\n",
       "      <td>18.932087</td>\n",
       "      <td>115.063175</td>\n",
       "      <td>-0.018746</td>\n",
       "      <td>-0.030271</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.265730</td>\n",
       "      <td>0.227916</td>\n",
       "      <td>13.922856</td>\n",
       "      <td>13.922856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.429043</td>\n",
       "      <td>-6.930156</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.359199</td>\n",
       "      <td>-13.359199</td>\n",
       "      <td>1.804220e-07</td>\n",
       "      <td>1.804220e-07</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>0.970183</td>\n",
       "      <td>-6.429043</td>\n",
       "      <td>-6.930156</td>\n",
       "      <td>-38.252064</td>\n",
       "      <td>-65.114082</td>\n",
       "      <td>18.932087</td>\n",
       "      <td>18.932087</td>\n",
       "      <td>127.344666</td>\n",
       "      <td>102.781685</td>\n",
       "      <td>-0.009998</td>\n",
       "      <td>-0.051022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.262232</td>\n",
       "      <td>0.180793</td>\n",
       "      <td>0.213706</td>\n",
       "      <td>0.356404</td>\n",
       "      <td>1.955485</td>\n",
       "      <td>1.955485</td>\n",
       "      <td>-6.649959</td>\n",
       "      <td>-7.178610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-11.302973</td>\n",
       "      <td>-11.302973</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.010042</td>\n",
       "      <td>0.009513</td>\n",
       "      <td>0.990951</td>\n",
       "      <td>0.951747</td>\n",
       "      <td>-6.649959</td>\n",
       "      <td>-7.178610</td>\n",
       "      <td>-38.645227</td>\n",
       "      <td>-66.330235</td>\n",
       "      <td>22.946876</td>\n",
       "      <td>22.946876</td>\n",
       "      <td>118.654505</td>\n",
       "      <td>97.633345</td>\n",
       "      <td>-0.030510</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.040720</td>\n",
       "      <td>0.285055</td>\n",
       "      <td>1.955485</td>\n",
       "      <td>-6.914284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-11.302973</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.971349</td>\n",
       "      <td>-6.914284</td>\n",
       "      <td>-52.487731</td>\n",
       "      <td>22.946876</td>\n",
       "      <td>108.143925</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Pretend you're an {persona} person making stat...</td>\n",
       "      <td>20</td>\n",
       "      <td>['o_proj', 'down_proj']</td>\n",
       "      <td>add2</td>\n",
       "      <td>1</td>\n",
       "      <td>[['an honest'], ['a dishonest']]</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>-3</td>\n",
       "      <td>raw</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>True</td>\n",
       "      <td>wassname/qwen-14B-codefourchan</td>\n",
       "      <td>/workspace/InnerPiSSA_private/outputs/adapters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[0.75]</td>\n",
       "      <td>800</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>innerpissa</td>\n",
       "      <td>False</td>\n",
       "      <td>honest</td>\n",
       "      <td>32</td>\n",
       "      <td>['up_proj']</td>\n",
       "      <td>8</td>\n",
       "      <td>InnerPiSSA</td>\n",
       "      <td>True</td>\n",
       "      <td>288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.056226</td>\n",
       "      <td>339.738163</td>\n",
       "      <td>171.546768</td>\n",
       "      <td>23.569608</td>\n",
       "      <td>144.722253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4c1jbdpe</td>\n",
       "      <td>q14b-c4c-raw-r128</td>\n",
       "      <td>finished</td>\n",
       "      <td>2025-11-27T01:43:26Z</td>\n",
       "      <td>https://wandb.ai/wassname/InnerPiSSA/runs/4c1j...</td>\n",
       "      <td>/media/wassname/SGIronWolf/projects5/2025/llm_...</td>\n",
       "      <td>q14b-80gb --model_name=wassname/qwen-14B-codef...</td>\n",
       "      <td>run-models-20251127-0143</td>\n",
       "      <td>7ec1d8d80bec4b43396bde3b546e2a5b4f508d33</td>\n",
       "      <td>NVIDIA A100-SXM4-80GB</td>\n",
       "      <td>36</td>\n",
       "      <td>599.477174</td>\n",
       "      <td>1473</td>\n",
       "      <td>-0.8743</td>\n",
       "      <td>-0.6733</td>\n",
       "      <td>-0.4125</td>\n",
       "      <td>0.770706</td>\n",
       "      <td>dishonest</td>\n",
       "      <td>-0.673339</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>-0.390598</td>\n",
       "      <td>-0.680650</td>\n",
       "      <td>-10.793957</td>\n",
       "      <td>-6.933430</td>\n",
       "      <td>0.304454</td>\n",
       "      <td>2.463995</td>\n",
       "      <td>-6.933430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.343777</td>\n",
       "      <td>-6.721316</td>\n",
       "      <td>0.049427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.721316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1473</td>\n",
       "      <td>708</td>\n",
       "      <td>1.764209e+09</td>\n",
       "      <td>{'runtime': 1473}</td>\n",
       "      <td>-0.021908</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.030372</td>\n",
       "      <td>-0.673339</td>\n",
       "      <td>-0.390598</td>\n",
       "      <td>-0.680650</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>599.477174</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>13.982160</td>\n",
       "      <td>0.049427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.721316</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.343777</td>\n",
       "      <td>0.004</td>\n",
       "      <td>base_model.model.model.layers.36.mlp.up_proj</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978334</td>\n",
       "      <td>-6.721316</td>\n",
       "      <td>-53.256214</td>\n",
       "      <td>18.932087</td>\n",
       "      <td>113.221088</td>\n",
       "      <td>-0.019070</td>\n",
       "      <td>-0.024746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.278593</td>\n",
       "      <td>0.217849</td>\n",
       "      <td>13.982160</td>\n",
       "      <td>13.982160</td>\n",
       "      <td>0.098854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.511371</td>\n",
       "      <td>-6.931261</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.343777</td>\n",
       "      <td>-13.343777</td>\n",
       "      <td>1.804220e-07</td>\n",
       "      <td>1.804220e-07</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.981111</td>\n",
       "      <td>0.975558</td>\n",
       "      <td>-6.511371</td>\n",
       "      <td>-6.931261</td>\n",
       "      <td>-41.605873</td>\n",
       "      <td>-64.906555</td>\n",
       "      <td>18.932087</td>\n",
       "      <td>18.932087</td>\n",
       "      <td>124.114227</td>\n",
       "      <td>102.327950</td>\n",
       "      <td>-0.034225</td>\n",
       "      <td>-0.046033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.280428</td>\n",
       "      <td>0.170445</td>\n",
       "      <td>0.318401</td>\n",
       "      <td>0.290507</td>\n",
       "      <td>2.463995</td>\n",
       "      <td>2.463995</td>\n",
       "      <td>-6.715493</td>\n",
       "      <td>-7.151367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.793957</td>\n",
       "      <td>-10.793957</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.014669</td>\n",
       "      <td>0.009971</td>\n",
       "      <td>0.967808</td>\n",
       "      <td>0.956092</td>\n",
       "      <td>-6.715493</td>\n",
       "      <td>-7.151367</td>\n",
       "      <td>-41.253011</td>\n",
       "      <td>-64.648491</td>\n",
       "      <td>22.946876</td>\n",
       "      <td>22.946876</td>\n",
       "      <td>117.418013</td>\n",
       "      <td>96.575298</td>\n",
       "      <td>-0.040129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.054992</td>\n",
       "      <td>0.304454</td>\n",
       "      <td>2.463995</td>\n",
       "      <td>-6.933430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.793957</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.012320</td>\n",
       "      <td>0.961950</td>\n",
       "      <td>-6.933430</td>\n",
       "      <td>-52.950751</td>\n",
       "      <td>22.946876</td>\n",
       "      <td>106.996656</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Pretend you're an {persona} person making stat...</td>\n",
       "      <td>20</td>\n",
       "      <td>['o_proj', 'down_proj']</td>\n",
       "      <td>add2</td>\n",
       "      <td>1</td>\n",
       "      <td>[['an honest'], ['a dishonest']]</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>-3</td>\n",
       "      <td>raw</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>True</td>\n",
       "      <td>wassname/qwen-14B-codefourchan</td>\n",
       "      <td>/workspace/InnerPiSSA_private/outputs/adapters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[0.75]</td>\n",
       "      <td>800</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>innerpissa</td>\n",
       "      <td>False</td>\n",
       "      <td>honest</td>\n",
       "      <td>32</td>\n",
       "      <td>['up_proj']</td>\n",
       "      <td>8</td>\n",
       "      <td>InnerPiSSA</td>\n",
       "      <td>True</td>\n",
       "      <td>288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.549820</td>\n",
       "      <td>339.738163</td>\n",
       "      <td>171.546768</td>\n",
       "      <td>76.452703</td>\n",
       "      <td>249.454077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0d6cm3hs</td>\n",
       "      <td>q14b-c4c-raw-r128</td>\n",
       "      <td>finished</td>\n",
       "      <td>2025-11-26T08:55:03Z</td>\n",
       "      <td>https://wandb.ai/wassname/InnerPiSSA/runs/0d6c...</td>\n",
       "      <td>/media/wassname/SGIronWolf/projects5/2025/llm_...</td>\n",
       "      <td>q14b-80gb --model_name=wassname/qwen-14B-codef...</td>\n",
       "      <td>ablation-20251126-0737</td>\n",
       "      <td>513a6a74c624d2e51061bc4766df8097c2ae9c1a</td>\n",
       "      <td>NVIDIA H100 NVL</td>\n",
       "      <td>36</td>\n",
       "      <td>148.876314</td>\n",
       "      <td>751</td>\n",
       "      <td>-0.7702</td>\n",
       "      <td>-0.6743</td>\n",
       "      <td>-0.6630</td>\n",
       "      <td>0.117831</td>\n",
       "      <td>honest</td>\n",
       "      <td>-0.674304</td>\n",
       "      <td>-0.681328</td>\n",
       "      <td>-0.681328</td>\n",
       "      <td>-0.415435</td>\n",
       "      <td>-0.678656</td>\n",
       "      <td>-12.779671</td>\n",
       "      <td>-7.298034</td>\n",
       "      <td>0.326655</td>\n",
       "      <td>1.163087</td>\n",
       "      <td>-7.298034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.369578</td>\n",
       "      <td>-7.684789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.684789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>751</td>\n",
       "      <td>708</td>\n",
       "      <td>1.764148e+09</td>\n",
       "      <td>{'runtime': 751}</td>\n",
       "      <td>0.007522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>-0.674304</td>\n",
       "      <td>-0.415435</td>\n",
       "      <td>-0.678656</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>148.876314</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>14.612954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.684789</td>\n",
       "      <td>1</td>\n",
       "      <td>-15.369578</td>\n",
       "      <td>0.004</td>\n",
       "      <td>base_model.model.model.layers.36.mlp.up_proj</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.009617</td>\n",
       "      <td>-7.684789</td>\n",
       "      <td>-85.011421</td>\n",
       "      <td>25.845478</td>\n",
       "      <td>145.215172</td>\n",
       "      <td>0.071565</td>\n",
       "      <td>-0.056522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.511352</td>\n",
       "      <td>0.528300</td>\n",
       "      <td>14.612954</td>\n",
       "      <td>14.612954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.516451</td>\n",
       "      <td>-7.853127</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-15.369578</td>\n",
       "      <td>-15.369578</td>\n",
       "      <td>1.804220e-07</td>\n",
       "      <td>1.804220e-07</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.074188</td>\n",
       "      <td>0.945046</td>\n",
       "      <td>-7.516451</td>\n",
       "      <td>-7.853127</td>\n",
       "      <td>-71.019257</td>\n",
       "      <td>-99.003586</td>\n",
       "      <td>25.845478</td>\n",
       "      <td>25.845478</td>\n",
       "      <td>161.128311</td>\n",
       "      <td>129.302032</td>\n",
       "      <td>0.019156</td>\n",
       "      <td>-0.018695</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.358451</td>\n",
       "      <td>0.265727</td>\n",
       "      <td>0.245149</td>\n",
       "      <td>0.408160</td>\n",
       "      <td>1.163087</td>\n",
       "      <td>1.163087</td>\n",
       "      <td>-7.122340</td>\n",
       "      <td>-7.473728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-12.779671</td>\n",
       "      <td>-12.779671</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.005761</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>1.021291</td>\n",
       "      <td>0.983516</td>\n",
       "      <td>-7.122340</td>\n",
       "      <td>-7.473728</td>\n",
       "      <td>-63.462010</td>\n",
       "      <td>-90.563447</td>\n",
       "      <td>22.065051</td>\n",
       "      <td>22.065051</td>\n",
       "      <td>152.760236</td>\n",
       "      <td>122.186175</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.046362</td>\n",
       "      <td>0.326655</td>\n",
       "      <td>1.163087</td>\n",
       "      <td>-7.298034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-12.779671</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>1.002404</td>\n",
       "      <td>-7.298034</td>\n",
       "      <td>-77.012728</td>\n",
       "      <td>22.065051</td>\n",
       "      <td>137.473206</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Pretend you're an {persona} person making stat...</td>\n",
       "      <td>20</td>\n",
       "      <td>['o_proj', 'down_proj']</td>\n",
       "      <td>add2</td>\n",
       "      <td>1</td>\n",
       "      <td>[['an honest'], ['a dishonest']]</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>-3</td>\n",
       "      <td>raw</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>True</td>\n",
       "      <td>wassname/qwen-14B-codefourchan</td>\n",
       "      <td>/workspace/InnerPiSSA_private/outputs/adapters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[0.75]</td>\n",
       "      <td>800</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>innerpissa</td>\n",
       "      <td>False</td>\n",
       "      <td>honest</td>\n",
       "      <td>32</td>\n",
       "      <td>['up_proj']</td>\n",
       "      <td>8</td>\n",
       "      <td>InnerPiSSA</td>\n",
       "      <td>True</td>\n",
       "      <td>288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>-0.681328</td>\n",
       "      <td>-0.681328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.589907</td>\n",
       "      <td>339.738163</td>\n",
       "      <td>171.546768</td>\n",
       "      <td>-56.179102</td>\n",
       "      <td>-13.215320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     run_id               name     state            created_at                                                url  \\\n",
       "0  qwtkm93m  q14b-c4c-raw-r128  finished  2025-11-27T08:17:03Z  https://wandb.ai/wassname/InnerPiSSA/runs/qwtk...   \n",
       "1  4c1jbdpe  q14b-c4c-raw-r128  finished  2025-11-27T01:43:26Z  https://wandb.ai/wassname/InnerPiSSA/runs/4c1j...   \n",
       "2  0d6cm3hs  q14b-c4c-raw-r128  finished  2025-11-26T08:55:03Z  https://wandb.ai/wassname/InnerPiSSA/runs/0d6c...   \n",
       "\n",
       "                                            log_file                                               args  \\\n",
       "0  /media/wassname/SGIronWolf/projects5/2025/llm_...  q14b-80gb --model_name=wassname/qwen-14B-codef...   \n",
       "1  /media/wassname/SGIronWolf/projects5/2025/llm_...  q14b-80gb --model_name=wassname/qwen-14B-codef...   \n",
       "2  /media/wassname/SGIronWolf/projects5/2025/llm_...  q14b-80gb --model_name=wassname/qwen-14B-codef...   \n",
       "\n",
       "                  run_group                                git_commit                    gpu  layer_num  main_metric  \\\n",
       "0    ablation-20251127-0813  7ec1d8d80bec4b43396bde3b546e2a5b4f508d33  NVIDIA A100-SXM4-80GB         36   419.813115   \n",
       "1  run-models-20251127-0143  7ec1d8d80bec4b43396bde3b546e2a5b4f508d33  NVIDIA A100-SXM4-80GB         36   599.477174   \n",
       "2    ablation-20251126-0737  513a6a74c624d2e51061bc4766df8097c2ae9c1a        NVIDIA H100 NVL         36   148.876314   \n",
       "\n",
       "   runtime  vh_neg  vh_zero  vh_pos  symmetry_mean resistant_toward  baseline_effect_InnerPiSSA  \\\n",
       "0     1483 -0.8108  -0.6733 -0.4864       0.735688        dishonest                   -0.673339   \n",
       "1     1473 -0.8743  -0.6733 -0.4125       0.770706        dishonest                   -0.673339   \n",
       "2      751 -0.7702  -0.6743 -0.6630       0.117831           honest                   -0.674304   \n",
       "\n",
       "   baseline_effect_s_steer  baseline_effect_pca  baseline_effect_prompting  baseline_effect_repeng  val_loss_total  \\\n",
       "0                -0.680004            -0.680004                  -0.390598               -0.680650      -11.302973   \n",
       "1                -0.680004            -0.680004                  -0.390598               -0.680650      -10.793957   \n",
       "2                -0.681328            -0.681328                  -0.415435               -0.678656      -12.779671   \n",
       "\n",
       "   val_loss_proj  val_loss_coh  val_loss_monotonic  val_proj_diff  val_logp_degradation  train_loss_total  \\\n",
       "0      -6.914284      0.285055            1.955485      -6.914284                   NaN        -13.359199   \n",
       "1      -6.933430      0.304454            2.463995      -6.933430                   NaN        -13.343777   \n",
       "2      -7.298034      0.326655            1.163087      -7.298034                   NaN        -15.369578   \n",
       "\n",
       "   train_loss_proj  train_loss_coh  train_loss_monotonic  train_proj_diff  train_logp_degradation  _runtime  _step  \\\n",
       "0        -6.679599        0.000000                   0.0        -6.679599                     NaN      1483    708   \n",
       "1        -6.721316        0.049427                   0.0        -6.721316                     NaN      1473    708   \n",
       "2        -7.684789        0.000000                   0.0        -7.684789                     NaN       751    708   \n",
       "\n",
       "     _timestamp             _wandb   coh_deg   cw  delta_logp_change  eval/baseline_InnerPiSSA (ours)  \\\n",
       "0  1.764233e+09  {'runtime': 1483} -0.024508  1.0          -0.018907                        -0.673339   \n",
       "1  1.764209e+09  {'runtime': 1473} -0.021908  1.0          -0.030372                        -0.673339   \n",
       "2  1.764148e+09   {'runtime': 751}  0.007522  1.0           0.008474                        -0.674304   \n",
       "\n",
       "   eval/baseline_prompting  eval/baseline_repeng                             eval/coherence_metrics  \\\n",
       "0                -0.390598             -0.680650  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "1                -0.390598             -0.680650  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "2                -0.415435             -0.678656  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "\n",
       "                              eval/effect_sizes_CI95                          eval/effect_sizes_Pearson  \\\n",
       "0  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "1  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "2  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "\n",
       "                             eval/effect_sizes_Slope                      eval/effect_sizes_Slope*(1-p)  \\\n",
       "0  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "1  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "2  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "\n",
       "                          eval/effect_sizes_Spearman                           eval/effect_sizes_T-stat  \\\n",
       "0  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "1  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "2  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "\n",
       "   eval/main_metric                              eval/transfer_summary  \\\n",
       "0        419.813115  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "1        599.477174  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "2        148.876314  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "\n",
       "                                   eval/value_scores   flip_ema  loss_coh  loss_monotonic  loss_proj  \\\n",
       "0  {'_latest_artifact_path': 'wandb-client-artifa...  13.922856  0.000000             0.0  -6.679599   \n",
       "1  {'_latest_artifact_path': 'wandb-client-artifa...  13.982160  0.049427             0.0  -6.721316   \n",
       "2  {'_latest_artifact_path': 'wandb-client-artifa...  14.612954  0.000000             0.0  -7.684789   \n",
       "\n",
       "   loss_proj_flipped  loss_total     lr                                        module  mono_direction  mono_ema  \\\n",
       "0                  1  -13.359199  0.004  base_model.model.model.layers.36.mlp.up_proj            -1.0      -1.0   \n",
       "1                  1  -13.343777  0.004  base_model.model.model.layers.36.mlp.up_proj            -1.0      -1.0   \n",
       "2                  1  -15.369578  0.004  base_model.model.model.layers.36.mlp.up_proj            -1.0      -1.0   \n",
       "\n",
       "   mono_frac_violated  mono_violation  prob_ratio  proj_diff    proj_pi   proj_ref  separation_norm  \\\n",
       "0                 0.0             0.0    0.975806  -6.679599 -51.683073  18.932087       115.063175   \n",
       "1                 0.0             0.0    0.978334  -6.721316 -53.256214  18.932087       113.221088   \n",
       "2                 0.0             0.0    1.009617  -7.684789 -85.011421  25.845478       145.215172   \n",
       "\n",
       "   train/by_coef/coh_deg_coef+1_0  train/by_coef/coh_deg_coef-1_0  train/by_coef/cw_coef+1_0  \\\n",
       "0                       -0.018746                       -0.030271                        1.0   \n",
       "1                       -0.019070                       -0.024746                        1.0   \n",
       "2                        0.071565                       -0.056522                        1.0   \n",
       "\n",
       "   train/by_coef/cw_coef-1_0  train/by_coef/delta_logp_change_coef+1_0  train/by_coef/delta_logp_change_coef-1_0  \\\n",
       "0                        1.0                                 -0.265730                                  0.227916   \n",
       "1                        1.0                                 -0.278593                                  0.217849   \n",
       "2                        1.0                                 -0.511352                                  0.528300   \n",
       "\n",
       "   train/by_coef/flip_ema_coef+1_0  train/by_coef/flip_ema_coef-1_0  train/by_coef/loss_coh_coef+1_0  \\\n",
       "0                        13.922856                        13.922856                         0.000000   \n",
       "1                        13.982160                        13.982160                         0.098854   \n",
       "2                        14.612954                        14.612954                         0.000000   \n",
       "\n",
       "   train/by_coef/loss_coh_coef-1_0  train/by_coef/loss_monotonic_coef+1_0  train/by_coef/loss_monotonic_coef-1_0  \\\n",
       "0                              0.0                                    0.0                                    0.0   \n",
       "1                              0.0                                    0.0                                    0.0   \n",
       "2                              0.0                                    0.0                                    0.0   \n",
       "\n",
       "   train/by_coef/loss_proj_coef+1_0  train/by_coef/loss_proj_coef-1_0  train/by_coef/loss_proj_flipped_coef+1_0  \\\n",
       "0                         -6.429043                         -6.930156                                         1   \n",
       "1                         -6.511371                         -6.931261                                         1   \n",
       "2                         -7.516451                         -7.853127                                         1   \n",
       "\n",
       "   train/by_coef/loss_proj_flipped_coef-1_0  train/by_coef/loss_total_coef+1_0  train/by_coef/loss_total_coef-1_0  \\\n",
       "0                                         1                         -13.359199                         -13.359199   \n",
       "1                                         1                         -13.343777                         -13.343777   \n",
       "2                                         1                         -15.369578                         -15.369578   \n",
       "\n",
       "   train/by_coef/lr_coef+1_0  train/by_coef/lr_coef-1_0  train/by_coef/mono_direction_coef+1_0  \\\n",
       "0               1.804220e-07               1.804220e-07                                   -1.0   \n",
       "1               1.804220e-07               1.804220e-07                                   -1.0   \n",
       "2               1.804220e-07               1.804220e-07                                   -1.0   \n",
       "\n",
       "   train/by_coef/mono_direction_coef-1_0  train/by_coef/mono_ema_coef+1_0  train/by_coef/mono_ema_coef-1_0  \\\n",
       "0                                   -1.0                             -1.0                             -1.0   \n",
       "1                                   -1.0                             -1.0                             -1.0   \n",
       "2                                   -1.0                             -1.0                             -1.0   \n",
       "\n",
       "   train/by_coef/mono_frac_violated_coef+1_0  train/by_coef/mono_frac_violated_coef-1_0  \\\n",
       "0                                        0.0                                        0.0   \n",
       "1                                        0.0                                        0.0   \n",
       "2                                        0.0                                        0.0   \n",
       "\n",
       "   train/by_coef/mono_violation_coef+1_0  train/by_coef/mono_violation_coef-1_0  train/by_coef/prob_ratio_coef+1_0  \\\n",
       "0                                    0.0                                    0.0                           0.981429   \n",
       "1                                    0.0                                    0.0                           0.981111   \n",
       "2                                    0.0                                    0.0                           1.074188   \n",
       "\n",
       "   train/by_coef/prob_ratio_coef-1_0  train/by_coef/proj_diff_coef+1_0  train/by_coef/proj_diff_coef-1_0  \\\n",
       "0                           0.970183                         -6.429043                         -6.930156   \n",
       "1                           0.975558                         -6.511371                         -6.931261   \n",
       "2                           0.945046                         -7.516451                         -7.853127   \n",
       "\n",
       "   train/by_coef/proj_pi_coef+1_0  train/by_coef/proj_pi_coef-1_0  train/by_coef/proj_ref_coef+1_0  \\\n",
       "0                      -38.252064                      -65.114082                        18.932087   \n",
       "1                      -41.605873                      -64.906555                        18.932087   \n",
       "2                      -71.019257                      -99.003586                        25.845478   \n",
       "\n",
       "   train/by_coef/proj_ref_coef-1_0  train/by_coef/separation_norm_coef+1_0  train/by_coef/separation_norm_coef-1_0  \\\n",
       "0                        18.932087                              127.344666                              102.781685   \n",
       "1                        18.932087                              124.114227                              102.327950   \n",
       "2                        25.845478                              161.128311                              129.302032   \n",
       "\n",
       "   val/by_coef/coh_deg_coef+1_0  val/by_coef/coh_deg_coef-1_0  val/by_coef/cw_coef+1_0  val/by_coef/cw_coef-1_0  \\\n",
       "0                     -0.009998                     -0.051022                      1.0                      1.0   \n",
       "1                     -0.034225                     -0.046033                      1.0                      1.0   \n",
       "2                      0.019156                     -0.018695                      1.0                      1.0   \n",
       "\n",
       "   val/by_coef/delta_logp_change_coef+1_0  val/by_coef/delta_logp_change_coef-1_0  val/by_coef/loss_coh_coef+1_0  \\\n",
       "0                               -0.262232                                0.180793                       0.213706   \n",
       "1                               -0.280428                                0.170445                       0.318401   \n",
       "2                               -0.358451                                0.265727                       0.245149   \n",
       "\n",
       "   val/by_coef/loss_coh_coef-1_0  val/by_coef/loss_monotonic_coef+1_0  val/by_coef/loss_monotonic_coef-1_0  \\\n",
       "0                       0.356404                             1.955485                             1.955485   \n",
       "1                       0.290507                             2.463995                             2.463995   \n",
       "2                       0.408160                             1.163087                             1.163087   \n",
       "\n",
       "   val/by_coef/loss_proj_coef+1_0  val/by_coef/loss_proj_coef-1_0  val/by_coef/loss_proj_flipped_coef+1_0  \\\n",
       "0                       -6.649959                       -7.178610                                     1.0   \n",
       "1                       -6.715493                       -7.151367                                     1.0   \n",
       "2                       -7.122340                       -7.473728                                     1.0   \n",
       "\n",
       "   val/by_coef/loss_proj_flipped_coef-1_0  val/by_coef/loss_total_coef+1_0  val/by_coef/loss_total_coef-1_0  \\\n",
       "0                                     1.0                       -11.302973                       -11.302973   \n",
       "1                                     1.0                       -10.793957                       -10.793957   \n",
       "2                                     1.0                       -12.779671                       -12.779671   \n",
       "\n",
       "   val/by_coef/mono_direction_coef+1_0  val/by_coef/mono_direction_coef-1_0  val/by_coef/mono_frac_violated_coef+1_0  \\\n",
       "0                            -0.846154                            -0.846154                                 0.250000   \n",
       "1                            -0.846154                            -0.846154                                 0.230769   \n",
       "2                            -1.000000                            -1.000000                                 0.125000   \n",
       "\n",
       "   val/by_coef/mono_frac_violated_coef-1_0  val/by_coef/mono_violation_coef+1_0  val/by_coef/mono_violation_coef-1_0  \\\n",
       "0                                 0.250000                             0.010042                             0.009513   \n",
       "1                                 0.230769                             0.014669                             0.009971   \n",
       "2                                 0.125000                             0.005761                             0.005870   \n",
       "\n",
       "   val/by_coef/prob_ratio_coef+1_0  val/by_coef/prob_ratio_coef-1_0  val/by_coef/proj_diff_coef+1_0  \\\n",
       "0                         0.990951                         0.951747                       -6.649959   \n",
       "1                         0.967808                         0.956092                       -6.715493   \n",
       "2                         1.021291                         0.983516                       -7.122340   \n",
       "\n",
       "   val/by_coef/proj_diff_coef-1_0  val/by_coef/proj_pi_coef+1_0  val/by_coef/proj_pi_coef-1_0  \\\n",
       "0                       -7.178610                    -38.645227                    -66.330235   \n",
       "1                       -7.151367                    -41.253011                    -64.648491   \n",
       "2                       -7.473728                    -63.462010                    -90.563447   \n",
       "\n",
       "   val/by_coef/proj_ref_coef+1_0  val/by_coef/proj_ref_coef-1_0  val/by_coef/separation_norm_coef+1_0  \\\n",
       "0                      22.946876                      22.946876                            118.654505   \n",
       "1                      22.946876                      22.946876                            117.418013   \n",
       "2                      22.065051                      22.065051                            152.760236   \n",
       "\n",
       "   val/by_coef/separation_norm_coef-1_0  val/coh_deg  val/cw  val/delta_logp_change  val/loss_coh  val/loss_monotonic  \\\n",
       "0                             97.633345    -0.030510     1.0              -0.040720      0.285055            1.955485   \n",
       "1                             96.575298    -0.040129     1.0              -0.054992      0.304454            2.463995   \n",
       "2                            122.186175     0.000231     1.0              -0.046362      0.326655            1.163087   \n",
       "\n",
       "   val/loss_proj  val/loss_proj_flipped  val/loss_total  val/mono_direction  val/mono_frac_violated  \\\n",
       "0      -6.914284                    1.0      -11.302973           -0.846154                0.250000   \n",
       "1      -6.933430                    1.0      -10.793957           -0.846154                0.230769   \n",
       "2      -7.298034                    1.0      -12.779671           -1.000000                0.125000   \n",
       "\n",
       "   val/mono_violation  val/prob_ratio  val/proj_diff  val/proj_pi  val/proj_ref  val/separation_norm    r  bs  \\\n",
       "0            0.009777        0.971349      -6.914284   -52.487731     22.946876           108.143925  128  16   \n",
       "1            0.012320        0.961950      -6.933430   -52.950751     22.946876           106.996656  128  16   \n",
       "2            0.005815        1.002404      -7.298034   -77.012728     22.065051           137.473206  128  16   \n",
       "\n",
       "        wd   coh  mono  quick  rot_u  rot_v                                             PROMPT  n_logs  \\\n",
       "0  0.00001  True  True  False  False   True  Pretend you're an {persona} person making stat...      20   \n",
       "1  0.00001  True  True  False  False   True  Pretend you're an {persona} person making stat...      20   \n",
       "2  0.00001  True  True  False  False   True  Pretend you're an {persona} person making stat...      20   \n",
       "\n",
       "                   modules scale_s verbose                          PERSONAS  coh_temp  n_depths  n_epochs  depth_end  \\\n",
       "0  ['o_proj', 'down_proj']    add2       1  [['an honest'], ['a dishonest']]         4        14        10         -3   \n",
       "1  ['o_proj', 'down_proj']    add2       1  [['an honest'], ['a dishonest']]         4        14        10         -3   \n",
       "2  ['o_proj', 'down_proj']    add2       1  [['an honest'], ['a dishonest']]         4        14        10         -3   \n",
       "\n",
       "  loss_type  use_wandb  val_split  coh_thresh  coh_weight  loss_use_V                      model_name  \\\n",
       "0       raw       True       0.15         0.5        40.0        True  wassname/qwen-14B-codefourchan   \n",
       "1       raw       True       0.15         0.5        40.0        True  wassname/qwen-14B-codefourchan   \n",
       "2       raw       True       0.15         0.5        40.0        True  wassname/qwen-14B-codefourchan   \n",
       "\n",
       "                                       output_dir  wandb_tags  depth_start loss_depths  max_samples  mono_margin  \\\n",
       "0  /workspace/InnerPiSSA_private/outputs/adapters         NaN          0.3      [0.75]          800         0.05   \n",
       "1  /workspace/InnerPiSSA_private/outputs/adapters         NaN          0.3      [0.75]          800         0.05   \n",
       "2  /workspace/InnerPiSSA_private/outputs/adapters         NaN          0.3      [0.75]          800         0.05   \n",
       "\n",
       "   mono_weight adapter_type  coh_adaptive dataset_name  effective_bs loss_modules  n_last_tokens wandb_project  \\\n",
       "0          100   innerpissa         False       honest            32  ['up_proj']              8    InnerPiSSA   \n",
       "1          100   innerpissa         False       honest            32  ['up_proj']              8    InnerPiSSA   \n",
       "2          100   innerpissa         False       honest            32  ['up_proj']              8    InnerPiSSA   \n",
       "\n",
       "   data_aware_init  eval_max_tokens experiment_name  save_checkpoints  eval_max_dilemmas quantization_type  \\\n",
       "0             True              288             NaN             False                NaN              none   \n",
       "1             True              288             NaN             False                NaN              none   \n",
       "2             True              288             NaN             False                NaN              none   \n",
       "\n",
       "   max_rotation_angle  early_stop_patience loss_snorm  pref_dir_k pref_dir_method  val_every_n_samples  \\\n",
       "0                 0.3                    4        NaN         NaN             NaN                256.0   \n",
       "1                 0.3                    4        NaN         NaN             NaN                256.0   \n",
       "2                 0.3                    4        NaN         NaN             NaN                256.0   \n",
       "\n",
       "   eval/baseline_S-space steer  eval/baseline_pca (wassname) s_selection_mode  loss_gap  prompting_score  \\\n",
       "0                    -0.680004                     -0.680004              NaN  2.056226       339.738163   \n",
       "1                    -0.680004                     -0.680004              NaN  2.549820       339.738163   \n",
       "2                    -0.681328                     -0.681328              NaN  2.589907       339.738163   \n",
       "\n",
       "   repeng_score  gain_vs_prompting  gain_vs_repeng  \n",
       "0    171.546768          23.569608      144.722253  \n",
       "1    171.546768          76.452703      249.454077  \n",
       "2    171.546768         -56.179102      -13.215320  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv('../outputs/wandb_results.csv')\n",
    "df_summary = pd.read_csv('../outputs/wandb_summary.csv')\n",
    "\n",
    "# Compute loss_gap (overfitting metric: val - train)\n",
    "df_full['loss_gap'] = df_full['val_loss_total'] - df_full['train_loss_total']\n",
    "\n",
    "# Load baseline results for comparison\n",
    "df_prompting = pd.read_csv('../outputs/prompting_results.csv')\n",
    "df_repeng = pd.read_csv('../outputs/repeng_results.csv')\n",
    "\n",
    "# Create lookup dicts for baseline scores by model\n",
    "prompting_baseline = df_prompting.groupby('model_name')['main_score'].mean().to_dict()\n",
    "repeng_baseline = df_repeng.groupby('model_name')['main_score'].mean().to_dict()\n",
    "\n",
    "# Add baseline scores to df_full based on model_name\n",
    "df_full['prompting_score'] = df_full['model_name'].map(prompting_baseline)\n",
    "df_full['repeng_score'] = df_full['model_name'].map(repeng_baseline)\n",
    "\n",
    "# Compute gain % vs prompting: (innerpissa - prompting) / prompting * 100\n",
    "df_full['gain_vs_prompting'] = (df_full['main_metric'] - df_full['prompting_score']) / df_full['prompting_score'].abs() * 100\n",
    "df_full['gain_vs_repeng'] = (df_full['main_metric'] - df_full['repeng_score']) / df_full['repeng_score'].abs() * 100\n",
    "\n",
    "print(f\"Total runs: {len(df_full)}\")\n",
    "print(f\"Runs with prompting baseline: {df_full['prompting_score'].notna().sum()}\")\n",
    "\n",
    "print(f\"\\nBaseline scores by model:\")\n",
    "for model in df_full['model_name'].dropna().unique()[:5]:\n",
    "    p = prompting_baseline.get(model, np.nan)\n",
    "    r = repeng_baseline.get(model, np.nan)\n",
    "    print(f\"  {model[:40]}: prompting={p:.1f}, repeng={r:.1f}\")\n",
    "\n",
    "df_full.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69b3e80",
   "metadata": {},
   "source": [
    "## Step 1: Recalculate Symmetry from Logs\n",
    "\n",
    "Parse each run's output.log to get:\n",
    "- Baseline-relative symmetry: `min(|neg-zero|, |pos-zero|) / max(...)`\n",
    "- Resistant direction: which side (neg or pos) moved LESS from baseline\n",
    "- Raw scores for both InnerPiSSA and prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21d8cc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing logs for Value/Honesty...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009b08bfebcb4a82aadf99cb423dbc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/687 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing log for run mdc8ewki: could not convert string to float: '...'\n",
      "Error parsing log for run kx7aauqa: could not convert string to float: '...'\n",
      "Error parsing log for run mtod05cs: could not convert string to float: '...'\n",
      "Parsed 674 runs with valid Value/Honesty\n",
      "\n",
      "=== Value/Honesty Summary ===\n",
      "symmetry: 0.50  0.29\n",
      "\n",
      "=== Resistant Direction ===\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Parse logs to extract Value/Honesty at coeff=-1,0,+1\n",
    "from ipissa.config import proj_root\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "cache_dir = proj_root / \"outputs\" / \"wandb_cache\"\n",
    "\n",
    "def parse_value_honesty_from_log(log_file: Path) -> dict:\n",
    "    \"\"\"Extract Value/Honesty scores at coeff=-1, 0, +1 from InnerPiSSA results table.\n",
    "    \n",
    "    Returns: {vh_neg, vh_zero, vh_pos, symmetry, resistant_toward}\n",
    "    \"\"\"\n",
    "    if not log_file.exists():\n",
    "        print(f\"Log file does not exist: {log_file}\")\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        logs = log_file.read_text()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {log_file}: {e}\")\n",
    "        return {}\n",
    "    \n",
    "    # Find InnerPiSSA results table\n",
    "    pattern = r'Results for method: InnerPiSSA.*?(?=Results for method:|$)'\n",
    "    match = re.search(pattern, logs, re.DOTALL)\n",
    "    if not match:\n",
    "        return {}\n",
    "    \n",
    "    table_text = match.group(0)\n",
    "    \n",
    "    # Parse Value/Honesty row: \"Value/Honesty   -3.0767  -3.1215  -3.1828\"\n",
    "    vh_pattern = r'Value/Honesty\\s+([-\\d.]+)\\s+([-\\d.]+)\\s+([-\\d.]+)'\n",
    "    vh_match = re.search(vh_pattern, table_text)\n",
    "    if not vh_match:\n",
    "        return {}\n",
    "    \n",
    "    neg, zero, pos = float(vh_match.group(1)), float(vh_match.group(2)), float(vh_match.group(3))\n",
    "    \n",
    "    # Compute symmetry: min(|neg-zero|, |pos-zero|) / max(...)\n",
    "    dist_neg = abs(neg - zero)\n",
    "    dist_pos = abs(pos - zero)\n",
    "    \n",
    "    metrics = {\n",
    "        'vh_neg': neg,\n",
    "        'vh_zero': zero, \n",
    "        'vh_pos': pos,\n",
    "    }\n",
    "    \n",
    "    if max(dist_neg, dist_pos) > 0.01:\n",
    "        metrics['symmetry'] = min(dist_neg, dist_pos) / max(dist_neg, dist_pos)\n",
    "        # Resistant direction: which way has smaller effect?\n",
    "        metrics['resistant_toward'] = 'honest' if dist_pos < dist_neg else 'dishonest'\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Process all runs\n",
    "print(\"Parsing logs for Value/Honesty...\")\n",
    "run_metrics = []\n",
    "\n",
    "for _, row in tqdm(df_full.iterrows(), total=len(df_full)):\n",
    "    run_id = row['run_id']\n",
    "    log_file = cache_dir / run_id / \"output.log\"\n",
    "    try:\n",
    "        m = parse_value_honesty_from_log(log_file)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing log for run {run_id}: {e}\")\n",
    "        continue\n",
    "    m['run_id'] = run_id\n",
    "    run_metrics.append(m)\n",
    "\n",
    "df_metrics = pd.DataFrame(run_metrics)\n",
    "print(f\"Parsed {df_metrics['symmetry'].notna().sum()} runs with valid Value/Honesty\")\n",
    "\n",
    "# Merge with original data\n",
    "df = df_full.merge(df_metrics, on='run_id', how='left')\n",
    "\n",
    "# Summary\n",
    "valid = df[df['symmetry'].notna()]\n",
    "print(f\"\\n=== Value/Honesty Summary ===\")\n",
    "# print(f\"vh_neg:  {valid['vh_neg'].mean():.2f}  {valid['vh_neg'].std():.2f}\")\n",
    "# print(f\"vh_zero: {valid['vh_zero'].mean():.2f}  {valid['vh_zero'].std():.2f}\")  \n",
    "# print(f\"vh_pos:  {valid['vh_pos'].mean():.2f}  {valid['vh_pos'].std():.2f}\")\n",
    "print(f\"symmetry: {valid['symmetry'].mean():.2f}  {valid['symmetry'].std():.2f}\")\n",
    "\n",
    "print(f\"\\n=== Resistant Direction ===\")\n",
    "# print(df['resistant_toward'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b5509",
   "metadata": {},
   "source": [
    "## Step 2: Combine Sweeps by Type\n",
    "\n",
    "Load all sweep CSVs, combine by base name (ignoring date stamps).\n",
    "For controlled comparisons, we'll look at within-sweep relative differences rather than absolute values across sweeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cc17727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 17 sweep types (latest 2 each)\n",
      "\n",
      "\n",
      "======================================================================\n",
      "Sweep: sweep-lr (control: lr)\n",
      "======================================================================\n",
      "Runs: 13\n",
      "      lr  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "0.010000      706.400       613.221816          43.977265  14.15990  0.350904  2            \n",
      "0.001000      473.750       613.221816         -65.183887   3.26300  0.575004  2            \n",
      "0.100000      121.600       613.221816         -80.105078  13.29000  0.551697  2            \n",
      "0.000010       94.555       613.221816         -94.307117  -0.35185  0.890843  2            \n",
      "1.000000       66.990       613.221816         -90.500990  11.61800  0.475431  2            \n",
      "0.000100       63.775       613.221816         -90.473268   2.52505  0.521832  2            \n",
      "0.000001       60.110              NaN                NaN   1.01700  0.580090  1            \n",
      "\n",
      "======================================================================\n",
      "Sweep: sweep-rank (control: r)\n",
      "======================================================================\n",
      "Runs: 13\n",
      "   r  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "  64      63.8175       613.221816         -80.088771    5.9767  0.541865  2           \n",
      " 128     511.8885       613.221816         -99.547146    2.9536  0.546296  2            \n",
      " 256     324.2000       613.221816         -62.591024    9.7730  0.403109  2            \n",
      " 512     317.3550       613.221816         -91.958864   12.3195  0.519868  2            \n",
      "   8     190.3000              NaN                NaN    0.6156  0.498307  1            \n",
      "  16     170.7000              NaN                NaN    0.7520  0.227763  1            \n",
      "  32     159.4000       613.221816         -68.331198    2.4084  0.442113  2            \n",
      "1024       2.5130              NaN                NaN   23.2600  0.995780  1            \n",
      "\n",
      "======================================================================\n",
      "Sweep: sweep-rotation-angle (control: max_rotation_angle)\n",
      "======================================================================\n",
      "Runs: 21\n",
      " max_rotation_angle  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "                inf      358.951       613.221816         -41.464737   4.25125  0.591625 10           \n",
      "                0.5      750.750       613.221816          22.427151   3.56005  0.508576  2            \n",
      "                1.0      651.550       613.221816           6.250297   6.74850  0.414140  2            \n",
      "                0.3      545.800       613.221816         -10.994686   4.42295  0.279049  4            \n",
      "                0.2      194.030       613.221816         -68.358921   0.80165  0.587204  2            \n",
      "                0.1      122.500       613.221816         -80.023542   8.14300  0.612801  1            \n",
      "\n",
      "======================================================================\n",
      "Sweep: run-models (control: model_name)\n",
      "======================================================================\n",
      "Runs: 16\n",
      "                   model_name  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "       google/gemma-3-270m-it      965.700              NaN                NaN   29.6550  0.343310  2            \n",
      "                Qwen/Qwen3-4B      953.300              NaN                NaN   14.0770  0.241247  2            \n",
      "         google/gemma-3-1b-it      820.450              NaN                NaN   28.3990  0.388735  2            \n",
      "           Qwen/Qwen3-4B-Base      685.750        15.417014        4348.007981    4.7690  0.316790  2            \n",
      "        google/gemma-3-12b-it      374.450       470.055076         -20.339122   19.4555  0.403618  2            \n",
      "              Qwen/Qwen3-0.6B      332.925       179.763790          85.201369   20.8650  0.505391  2            \n",
      "         google/gemma-3-4b-it      332.127       277.151945          19.835710   21.9685  0.515808  2            \n",
      "unsloth/Llama-3.1-8B-Instruct       95.120       293.890793         -67.634236    8.3470  0.663819  2            \n",
      "\n",
      "======================================================================\n",
      "Sweep: ablate-constraints (control: args)\n",
      "======================================================================\n",
      "Runs: 20\n",
      "                                                                        args  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "                                                q4bv1-80gb --no_coh_adaptive      863.700              NaN                NaN 19.640000  0.034528  1            \n",
      "                                                  q4bv1-80gb --no_mono --coh      711.500              NaN                NaN  7.263000  0.122658  1            \n",
      "                                               q4bv1-80gb --rot_u --no_rot_v      517.700              NaN                NaN  6.389000  0.588846  2            \n",
      "                                                   q4bv1-80gb --scale_s=none      401.485              NaN                NaN  6.681500  0.514337  2            \n",
      "                                                                  q4bv1-80gb      302.700              NaN                NaN 14.824500  0.307162  2            \n",
      "                              q4bv1-80gb --loss_use_V --loss_modules up_proj      208.500              NaN                NaN 15.395000  0.721150  2            \n",
      "                                             q4bv1-80gb --no_data_aware_init      200.750              NaN                NaN 18.125000  0.804494  2            \n",
      "q4bv1-80gb --no_loss_use_V --loss_depths=0.5 --loss_modules o_proj down_proj      179.160              NaN                NaN  8.160000  0.445562  2            \n",
      "                                                  q4bv1-80gb --mono --no_coh      177.185              NaN                NaN -0.098165  0.439465  2            \n",
      "                                               q4bv1-80gb --no_mono --no_coh      164.375              NaN                NaN -0.020660  0.448506  2            \n",
      "                                            q4bv1-80gb --no_rot_u --no_rot_v       74.805              NaN                NaN  0.386200  0.755419  2            \n",
      "\n",
      "======================================================================\n",
      "Sweep: ablate-modules (control: scale_s)\n",
      "======================================================================\n",
      "Runs: 12\n",
      "scale_s  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "   add2     530.4425              NaN                NaN 12.077167  0.692583 12           \n",
      "\n",
      "======================================================================\n",
      "Sweep: ablate-wd (control: wd)\n",
      "======================================================================\n",
      "Runs: 16\n",
      "          wd  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "0.000000e+00      307.820              NaN                NaN   14.2185  0.339032  2           \n",
      "1.000000e-06     1061.855              NaN                NaN   15.3420  0.772581  2            \n",
      "1.000000e-05      886.300              NaN                NaN    7.8010  0.609513  2            \n",
      "1.000000e-03      824.250              NaN                NaN    6.9835  0.509164  2            \n",
      "1.000000e-02      723.500              NaN                NaN   26.0900  0.181178  1            \n",
      "1.000000e-07      520.700              NaN                NaN    5.1645  0.064922  2            \n",
      "1.000000e-04      511.750              NaN                NaN    5.6380  0.483673  2            \n",
      "1.000000e-01      351.250              NaN                NaN   14.0285  0.466636  2            \n",
      "1.000000e+00      110.800              NaN                NaN    6.2610       NaN  1            \n",
      "\n",
      "data-efficiency: Could not find 'max_examples' column\n",
      "\n",
      "======================================================================\n",
      "Sweep: sweep-layers (control: n_depths)\n",
      "======================================================================\n",
      "Runs: 22\n",
      " n_depths  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "       22   477.769545              NaN                NaN 13.073727  0.379249 22            \n"
     ]
    }
   ],
   "source": [
    "# Step 2: Load and combine sweeps by type\n",
    "sweep_dir = Path('../outputs/sweep_groups')\n",
    "\n",
    "# Option: only load the N most recent sweeps per type (None = load all)\n",
    "N_LATEST_SWEEPS = 2  # e.g. set to 2 to only load 2 most recent sweeps per type\n",
    "\n",
    "def get_sweep_base(name: str) -> str:\n",
    "    \"\"\"Remove timestamp: 'sweep-lr-20251123-1629' -> 'sweep-lr'\"\"\"\n",
    "    return re.sub(r'-\\d{8}-\\d{4}', '', name.replace('.csv', ''))\n",
    "\n",
    "def get_sweep_timestamp(name: str) -> str:\n",
    "    \"\"\"Extract timestamp: 'sweep-lr-20251123-1629' -> '20251123-1629'\"\"\"\n",
    "    match = re.search(r'(\\d{8}-\\d{4})', name)\n",
    "    return match.group(1) if match else '00000000-0000'\n",
    "\n",
    "# Load all sweep CSVs\n",
    "sweep_files = [f for f in sweep_dir.glob('*.csv') if '_summary' not in f.name]\n",
    "\n",
    "# Group by base name\n",
    "sweep_by_base = {}\n",
    "for f in sweep_files:\n",
    "    base = get_sweep_base(f.name)\n",
    "    if base not in sweep_by_base:\n",
    "        sweep_by_base[base] = []\n",
    "    sweep_by_base[base].append(f)\n",
    "\n",
    "# Sort each group by timestamp (descending) and optionally take only latest N\n",
    "for base in sweep_by_base:\n",
    "    sweep_by_base[base] = sorted(sweep_by_base[base], key=lambda f: get_sweep_timestamp(f.name), reverse=True)\n",
    "    if N_LATEST_SWEEPS is not None:\n",
    "        sweep_by_base[base] = sweep_by_base[base][:N_LATEST_SWEEPS]\n",
    "\n",
    "# Load selected files\n",
    "sweeps = {}\n",
    "for base, files in sweep_by_base.items():\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        df_sweep = pd.read_csv(f)\n",
    "        df_sweep['sweep_file'] = f.name\n",
    "        df_sweep['sweep_base'] = base\n",
    "        dfs.append(df_sweep)\n",
    "    \n",
    "    combined = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Merge with parsed log metrics (symmetry, resistant_toward) \n",
    "    merge_cols = ['run_id', 'symmetry', 'resistant_toward']\n",
    "    available_cols = [c for c in merge_cols if c in df_metrics.columns]\n",
    "    combined = combined.merge(df_metrics[available_cols], on='run_id', how='left')\n",
    "    \n",
    "    # Add prompting/repeng baseline via model_name (run_id merge has 0 overlap with sweep CSVs)\n",
    "    if 'model_name' in combined.columns:\n",
    "        combined['prompting_score'] = combined['model_name'].map(prompting_baseline)\n",
    "        combined['repeng_score'] = combined['model_name'].map(repeng_baseline)\n",
    "        combined['gain_vs_prompting'] = (combined['main_metric'] - combined['prompting_score']) / combined['prompting_score'].abs() * 100\n",
    "        combined['gain_vs_repeng'] = (combined['main_metric'] - combined['repeng_score']) / combined['repeng_score'].abs() * 100\n",
    "    \n",
    "    sweeps[base] = combined\n",
    "\n",
    "print(f\"Loaded {len(sweeps)} sweep types\" + (f\" (latest {N_LATEST_SWEEPS} each)\" if N_LATEST_SWEEPS else \"\") + \"\\n\")\n",
    "\n",
    "# Define control variable and baseline value for each sweep\n",
    "SWEEP_CONFIG = {\n",
    "    'sweep-lr': {'var': 'lr', 'baseline': 0.004},\n",
    "    'sweep-rank': {'var': 'r', 'baseline': 64},\n",
    "    'sweep-rotation-angle': {'var': 'max_rotation_angle', 'baseline': float('inf')},\n",
    "    'run-models': {'var': 'model_name', 'baseline': None},\n",
    "    'ablate-constraints': {'var': 'args', 'baseline': 'q4b-80gb'},\n",
    "    'ablate-modules': {'var': 'scale_s', 'baseline': 'add2'},\n",
    "    'ablate-wd': {'var': 'wd', 'baseline': 0.0},\n",
    "    'data-efficiency': {'var': 'max_examples', 'baseline': None},\n",
    "    'sweep-layers': {'var': 'n_depths', 'baseline': None},\n",
    "}\n",
    "\n",
    "def summarize_sweep_mean(df_s, var, baseline_val):\n",
    "    \"\"\"Summarize sweep using groupby. main_metric is the t-stat steering effect.\"\"\"\n",
    "    if var not in df_s.columns:\n",
    "        for alt in [var.replace('_', ''), var + 's']:\n",
    "            if alt in df_s.columns:\n",
    "                var = alt\n",
    "                break\n",
    "        else:\n",
    "            return None, var\n",
    "    \n",
    "    # Define columns to aggregate\n",
    "    agg_cols = {\n",
    "        'main_metric': 'mean',\n",
    "        'prompting_score': 'mean', \n",
    "        'gain_vs_prompting': 'mean',\n",
    "        'loss_gap': 'mean',\n",
    "        'symmetry': 'mean',\n",
    "    }\n",
    "    agg_cols = {k: v for k, v in agg_cols.items() if k in df_s.columns}\n",
    "    \n",
    "    df_result = (\n",
    "        df_s.groupby(var, dropna=False)\n",
    "        .agg(**{k: (k, v) for k, v in agg_cols.items()}, n=(var, 'size'))\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_result['is_baseline'] = df_result[var].apply(lambda x: '' if baseline_val is not None and x == baseline_val else '')\n",
    "    \n",
    "    # Sort: baseline first, then by main metric descending\n",
    "    if 'main_metric' in df_result.columns:\n",
    "        df_result = df_result.sort_values(['is_baseline', 'main_metric'], ascending=[False, False])\n",
    "    \n",
    "    return df_result, var\n",
    "\n",
    "def style_sweep_table(df, var_col):\n",
    "    \"\"\"Style a sweep summary table with color gradients and formatting.\"\"\"\n",
    "    styled = df.style\n",
    "    \n",
    "    # Format numeric columns\n",
    "    format_dict = {\n",
    "        'main_metric': '{:.1f}',\n",
    "        'prompting_score': '{:.1f}',\n",
    "        'gain_vs_prompting': '{:+.0f}',\n",
    "        'loss_gap': '{:.2f}',\n",
    "        'symmetry': '{:.2f}',\n",
    "        'n': '{:.0f}',\n",
    "    }\n",
    "    format_dict = {k: v for k, v in format_dict.items() if k in df.columns}\n",
    "    styled = styled.format(format_dict, na_rep='-')\n",
    "    \n",
    "    # Color gradients (higher is better for most)\n",
    "    if 'main_metric' in df.columns:\n",
    "        styled = styled.background_gradient(subset=['main_metric'], cmap='Greens')\n",
    "    if 'gain_vs_prompting' in df.columns:\n",
    "        styled = styled.background_gradient(subset=['gain_vs_prompting'], cmap='RdYlGn', vmin=-100, vmax=100)\n",
    "    if 'symmetry' in df.columns:\n",
    "        styled = styled.background_gradient(subset=['symmetry'], cmap='Blues')\n",
    "    if 'loss_gap' in df.columns:\n",
    "        styled = styled.background_gradient(subset=['loss_gap'], cmap='Reds_r')\n",
    "    \n",
    "    return styled\n",
    "\n",
    "# Show each sweep\n",
    "for sweep_name, config in SWEEP_CONFIG.items():\n",
    "    if sweep_name not in sweeps:\n",
    "        continue\n",
    "    \n",
    "    df_s = sweeps[sweep_name]\n",
    "    control_var = config['var']\n",
    "    \n",
    "    summary_df, actual_var = summarize_sweep_mean(df_s, control_var, config['baseline'])\n",
    "    \n",
    "    if summary_df is not None:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Sweep: {sweep_name} (control: {actual_var})\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Runs: {len(df_s)}\")\n",
    "        print(summary_df.to_string(index=False))\n",
    "    else:\n",
    "        print(f\"\\n{sweep_name}: Could not find '{control_var}' column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db3e0e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data-efficiency', 'ablate-constraints', 'sweep-layers', 'ablation', 'sweep-lr', 'sweep-rank', 'ablate-wd', 'sweep-snorm', 'sweep-pref-dir', 'sweep-training-stages', 'ablate-modules', 'run-models', 'sweep-rotation-angle', 'sweep-long-training', 'sweep-loss-modules', 'sweep-layers-V', 'sweep-scale'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "600d0879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data-efficiency: (No data or 'max_examples' not found)\n",
      "\n",
      "ablate-constraints (n=20, 2 dates, control: args)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5a7f2_row0_col1 {\n",
       "  background-color: #bce4b5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a7f2_row0_col3, #T_5a7f2_row1_col3, #T_5a7f2_row2_col3, #T_5a7f2_row3_col3, #T_5a7f2_row4_col3, #T_5a7f2_row5_col3, #T_5a7f2_row6_col3, #T_5a7f2_row7_col3, #T_5a7f2_row8_col3, #T_5a7f2_row9_col3, #T_5a7f2_row10_col3 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row0_col4 {\n",
       "  background-color: #fcbda4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a7f2_row0_col5 {\n",
       "  background-color: #a5cde3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a7f2_row1_col1 {\n",
       "  background-color: #dbf1d5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a7f2_row1_col4 {\n",
       "  background-color: #fdc5ae;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a7f2_row1_col5 {\n",
       "  background-color: #084c95;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row2_col1, #T_5a7f2_row5_col1 {\n",
       "  background-color: #e4f5df;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a7f2_row2_col4 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row2_col5 {\n",
       "  background-color: #63a8d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row3_col1 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row3_col4 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a7f2_row3_col5 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a7f2_row4_col1 {\n",
       "  background-color: #ddf2d8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a7f2_row4_col4 {\n",
       "  background-color: #fee8de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a7f2_row4_col5 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row5_col4 {\n",
       "  background-color: #f34c37;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row5_col5 {\n",
       "  background-color: #60a7d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row6_col1 {\n",
       "  background-color: #137d39;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row6_col4 {\n",
       "  background-color: #ee3a2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row6_col5 {\n",
       "  background-color: #e0ecf8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a7f2_row7_col1 {\n",
       "  background-color: #e7f6e2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a7f2_row7_col4 {\n",
       "  background-color: #69000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row7_col5 {\n",
       "  background-color: #5fa6d1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row8_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a7f2_row8_col4 {\n",
       "  background-color: #73030f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row8_col5 {\n",
       "  background-color: #084184;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row9_col1 {\n",
       "  background-color: #5bb86a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row9_col4 {\n",
       "  background-color: #e22e27;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row9_col5 {\n",
       "  background-color: #2979b9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row10_col1 {\n",
       "  background-color: #92d28f;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_5a7f2_row10_col4 {\n",
       "  background-color: #e53228;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_5a7f2_row10_col5 {\n",
       "  background-color: #4292c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5a7f2\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5a7f2_level0_col0\" class=\"col_heading level0 col0\" >args</th>\n",
       "      <th id=\"T_5a7f2_level0_col1\" class=\"col_heading level0 col1\" >main_metric</th>\n",
       "      <th id=\"T_5a7f2_level0_col2\" class=\"col_heading level0 col2\" >prompting_score</th>\n",
       "      <th id=\"T_5a7f2_level0_col3\" class=\"col_heading level0 col3\" >gain_vs_prompting</th>\n",
       "      <th id=\"T_5a7f2_level0_col4\" class=\"col_heading level0 col4\" >loss_gap</th>\n",
       "      <th id=\"T_5a7f2_level0_col5\" class=\"col_heading level0 col5\" >symmetry</th>\n",
       "      <th id=\"T_5a7f2_level0_col6\" class=\"col_heading level0 col6\" >n</th>\n",
       "      <th id=\"T_5a7f2_level0_col7\" class=\"col_heading level0 col7\" >is_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5a7f2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5a7f2_row0_col0\" class=\"data row0 col0\" >q4bv1-80gb</td>\n",
       "      <td id=\"T_5a7f2_row0_col1\" class=\"data row0 col1\" >302.7</td>\n",
       "      <td id=\"T_5a7f2_row0_col2\" class=\"data row0 col2\" >-</td>\n",
       "      <td id=\"T_5a7f2_row0_col3\" class=\"data row0 col3\" >-</td>\n",
       "      <td id=\"T_5a7f2_row0_col4\" class=\"data row0 col4\" >14.82</td>\n",
       "      <td id=\"T_5a7f2_row0_col5\" class=\"data row0 col5\" >0.31</td>\n",
       "      <td id=\"T_5a7f2_row0_col6\" class=\"data row0 col6\" >2</td>\n",
       "      <td id=\"T_5a7f2_row0_col7\" class=\"data row0 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a7f2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5a7f2_row1_col0\" class=\"data row1 col0\" >q4bv1-80gb --loss_use_V --loss_modules up_proj</td>\n",
       "      <td id=\"T_5a7f2_row1_col1\" class=\"data row1 col1\" >208.5</td>\n",
       "      <td id=\"T_5a7f2_row1_col2\" class=\"data row1 col2\" >-</td>\n",
       "      <td id=\"T_5a7f2_row1_col3\" class=\"data row1 col3\" >-</td>\n",
       "      <td id=\"T_5a7f2_row1_col4\" class=\"data row1 col4\" >15.39</td>\n",
       "      <td id=\"T_5a7f2_row1_col5\" class=\"data row1 col5\" >0.72</td>\n",
       "      <td id=\"T_5a7f2_row1_col6\" class=\"data row1 col6\" >2</td>\n",
       "      <td id=\"T_5a7f2_row1_col7\" class=\"data row1 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a7f2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5a7f2_row2_col0\" class=\"data row2 col0\" >q4bv1-80gb --mono --no_coh</td>\n",
       "      <td id=\"T_5a7f2_row2_col1\" class=\"data row2 col1\" >177.2</td>\n",
       "      <td id=\"T_5a7f2_row2_col2\" class=\"data row2 col2\" >-</td>\n",
       "      <td id=\"T_5a7f2_row2_col3\" class=\"data row2 col3\" >-</td>\n",
       "      <td id=\"T_5a7f2_row2_col4\" class=\"data row2 col4\" >-0.10</td>\n",
       "      <td id=\"T_5a7f2_row2_col5\" class=\"data row2 col5\" >0.44</td>\n",
       "      <td id=\"T_5a7f2_row2_col6\" class=\"data row2 col6\" >2</td>\n",
       "      <td id=\"T_5a7f2_row2_col7\" class=\"data row2 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a7f2_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_5a7f2_row3_col0\" class=\"data row3 col0\" >q4bv1-80gb --no_coh_adaptive</td>\n",
       "      <td id=\"T_5a7f2_row3_col1\" class=\"data row3 col1\" >863.7</td>\n",
       "      <td id=\"T_5a7f2_row3_col2\" class=\"data row3 col2\" >-</td>\n",
       "      <td id=\"T_5a7f2_row3_col3\" class=\"data row3 col3\" >-</td>\n",
       "      <td id=\"T_5a7f2_row3_col4\" class=\"data row3 col4\" >19.64</td>\n",
       "      <td id=\"T_5a7f2_row3_col5\" class=\"data row3 col5\" >0.03</td>\n",
       "      <td id=\"T_5a7f2_row3_col6\" class=\"data row3 col6\" >1</td>\n",
       "      <td id=\"T_5a7f2_row3_col7\" class=\"data row3 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a7f2_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_5a7f2_row4_col0\" class=\"data row4 col0\" >q4bv1-80gb --no_data_aware_init</td>\n",
       "      <td id=\"T_5a7f2_row4_col1\" class=\"data row4 col1\" >200.8</td>\n",
       "      <td id=\"T_5a7f2_row4_col2\" class=\"data row4 col2\" >-</td>\n",
       "      <td id=\"T_5a7f2_row4_col3\" class=\"data row4 col3\" >-</td>\n",
       "      <td id=\"T_5a7f2_row4_col4\" class=\"data row4 col4\" >18.12</td>\n",
       "      <td id=\"T_5a7f2_row4_col5\" class=\"data row4 col5\" >0.80</td>\n",
       "      <td id=\"T_5a7f2_row4_col6\" class=\"data row4 col6\" >2</td>\n",
       "      <td id=\"T_5a7f2_row4_col7\" class=\"data row4 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a7f2_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_5a7f2_row5_col0\" class=\"data row5 col0\" >q4bv1-80gb --no_loss_use_V --loss_depths=0.5 --loss_modules o_proj down_proj</td>\n",
       "      <td id=\"T_5a7f2_row5_col1\" class=\"data row5 col1\" >179.2</td>\n",
       "      <td id=\"T_5a7f2_row5_col2\" class=\"data row5 col2\" >-</td>\n",
       "      <td id=\"T_5a7f2_row5_col3\" class=\"data row5 col3\" >-</td>\n",
       "      <td id=\"T_5a7f2_row5_col4\" class=\"data row5 col4\" >8.16</td>\n",
       "      <td id=\"T_5a7f2_row5_col5\" class=\"data row5 col5\" >0.45</td>\n",
       "      <td id=\"T_5a7f2_row5_col6\" class=\"data row5 col6\" >2</td>\n",
       "      <td id=\"T_5a7f2_row5_col7\" class=\"data row5 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a7f2_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_5a7f2_row6_col0\" class=\"data row6 col0\" >q4bv1-80gb --no_mono --coh</td>\n",
       "      <td id=\"T_5a7f2_row6_col1\" class=\"data row6 col1\" >711.5</td>\n",
       "      <td id=\"T_5a7f2_row6_col2\" class=\"data row6 col2\" >-</td>\n",
       "      <td id=\"T_5a7f2_row6_col3\" class=\"data row6 col3\" >-</td>\n",
       "      <td id=\"T_5a7f2_row6_col4\" class=\"data row6 col4\" >7.26</td>\n",
       "      <td id=\"T_5a7f2_row6_col5\" class=\"data row6 col5\" >0.12</td>\n",
       "      <td id=\"T_5a7f2_row6_col6\" class=\"data row6 col6\" >1</td>\n",
       "      <td id=\"T_5a7f2_row6_col7\" class=\"data row6 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a7f2_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_5a7f2_row7_col0\" class=\"data row7 col0\" >q4bv1-80gb --no_mono --no_coh</td>\n",
       "      <td id=\"T_5a7f2_row7_col1\" class=\"data row7 col1\" >164.4</td>\n",
       "      <td id=\"T_5a7f2_row7_col2\" class=\"data row7 col2\" >-</td>\n",
       "      <td id=\"T_5a7f2_row7_col3\" class=\"data row7 col3\" >-</td>\n",
       "      <td id=\"T_5a7f2_row7_col4\" class=\"data row7 col4\" >-0.02</td>\n",
       "      <td id=\"T_5a7f2_row7_col5\" class=\"data row7 col5\" >0.45</td>\n",
       "      <td id=\"T_5a7f2_row7_col6\" class=\"data row7 col6\" >2</td>\n",
       "      <td id=\"T_5a7f2_row7_col7\" class=\"data row7 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a7f2_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_5a7f2_row8_col0\" class=\"data row8 col0\" >q4bv1-80gb --no_rot_u --no_rot_v</td>\n",
       "      <td id=\"T_5a7f2_row8_col1\" class=\"data row8 col1\" >74.8</td>\n",
       "      <td id=\"T_5a7f2_row8_col2\" class=\"data row8 col2\" >-</td>\n",
       "      <td id=\"T_5a7f2_row8_col3\" class=\"data row8 col3\" >-</td>\n",
       "      <td id=\"T_5a7f2_row8_col4\" class=\"data row8 col4\" >0.39</td>\n",
       "      <td id=\"T_5a7f2_row8_col5\" class=\"data row8 col5\" >0.76</td>\n",
       "      <td id=\"T_5a7f2_row8_col6\" class=\"data row8 col6\" >2</td>\n",
       "      <td id=\"T_5a7f2_row8_col7\" class=\"data row8 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a7f2_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_5a7f2_row9_col0\" class=\"data row9 col0\" >q4bv1-80gb --rot_u --no_rot_v</td>\n",
       "      <td id=\"T_5a7f2_row9_col1\" class=\"data row9 col1\" >517.7</td>\n",
       "      <td id=\"T_5a7f2_row9_col2\" class=\"data row9 col2\" >-</td>\n",
       "      <td id=\"T_5a7f2_row9_col3\" class=\"data row9 col3\" >-</td>\n",
       "      <td id=\"T_5a7f2_row9_col4\" class=\"data row9 col4\" >6.39</td>\n",
       "      <td id=\"T_5a7f2_row9_col5\" class=\"data row9 col5\" >0.59</td>\n",
       "      <td id=\"T_5a7f2_row9_col6\" class=\"data row9 col6\" >2</td>\n",
       "      <td id=\"T_5a7f2_row9_col7\" class=\"data row9 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5a7f2_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_5a7f2_row10_col0\" class=\"data row10 col0\" >q4bv1-80gb --scale_s=none</td>\n",
       "      <td id=\"T_5a7f2_row10_col1\" class=\"data row10 col1\" >401.5</td>\n",
       "      <td id=\"T_5a7f2_row10_col2\" class=\"data row10 col2\" >-</td>\n",
       "      <td id=\"T_5a7f2_row10_col3\" class=\"data row10 col3\" >-</td>\n",
       "      <td id=\"T_5a7f2_row10_col4\" class=\"data row10 col4\" >6.68</td>\n",
       "      <td id=\"T_5a7f2_row10_col5\" class=\"data row10 col5\" >0.51</td>\n",
       "      <td id=\"T_5a7f2_row10_col6\" class=\"data row10 col6\" >2</td>\n",
       "      <td id=\"T_5a7f2_row10_col7\" class=\"data row10 col7\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7a3ecab479a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sweep-layers (n=22, 2 dates, control: n_depths)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4ac9c_row0_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_4ac9c_row0_col3 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4ac9c_row0_col4 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_4ac9c_row0_col5 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4ac9c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4ac9c_level0_col0\" class=\"col_heading level0 col0\" >n_depths</th>\n",
       "      <th id=\"T_4ac9c_level0_col1\" class=\"col_heading level0 col1\" >main_metric</th>\n",
       "      <th id=\"T_4ac9c_level0_col2\" class=\"col_heading level0 col2\" >prompting_score</th>\n",
       "      <th id=\"T_4ac9c_level0_col3\" class=\"col_heading level0 col3\" >gain_vs_prompting</th>\n",
       "      <th id=\"T_4ac9c_level0_col4\" class=\"col_heading level0 col4\" >loss_gap</th>\n",
       "      <th id=\"T_4ac9c_level0_col5\" class=\"col_heading level0 col5\" >symmetry</th>\n",
       "      <th id=\"T_4ac9c_level0_col6\" class=\"col_heading level0 col6\" >n</th>\n",
       "      <th id=\"T_4ac9c_level0_col7\" class=\"col_heading level0 col7\" >is_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4ac9c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_4ac9c_row0_col0\" class=\"data row0 col0\" >22</td>\n",
       "      <td id=\"T_4ac9c_row0_col1\" class=\"data row0 col1\" >477.8</td>\n",
       "      <td id=\"T_4ac9c_row0_col2\" class=\"data row0 col2\" >-</td>\n",
       "      <td id=\"T_4ac9c_row0_col3\" class=\"data row0 col3\" >-</td>\n",
       "      <td id=\"T_4ac9c_row0_col4\" class=\"data row0 col4\" >13.07</td>\n",
       "      <td id=\"T_4ac9c_row0_col5\" class=\"data row0 col5\" >0.38</td>\n",
       "      <td id=\"T_4ac9c_row0_col6\" class=\"data row0 col6\" >22</td>\n",
       "      <td id=\"T_4ac9c_row0_col7\" class=\"data row0 col7\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7a3ec8ae3670>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ablation: (No data or 'unknown' not found)\n",
      "\n",
      "sweep-lr (n=13, 2 dates, control: lr)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_38cce_row0_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_38cce_row0_col3 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_38cce_row0_col4 {\n",
       "  background-color: #960b13;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_38cce_row0_col5 {\n",
       "  background-color: #8abfdd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_38cce_row1_col1 {\n",
       "  background-color: #f0f9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_38cce_row1_col3 {\n",
       "  background-color: #b30d26;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_38cce_row1_col4 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_38cce_row1_col5 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_38cce_row2_col1, #T_38cce_row6_col1 {\n",
       "  background-color: #f6fcf4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_38cce_row2_col3, #T_38cce_row6_col3 {\n",
       "  background-color: #bd1726;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_38cce_row2_col4 {\n",
       "  background-color: #bb141a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_38cce_row2_col5 {\n",
       "  background-color: #b0d2e7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_38cce_row3_col1 {\n",
       "  background-color: #3ea75a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_38cce_row3_col3 {\n",
       "  background-color: #ec5c3b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_38cce_row3_col4 {\n",
       "  background-color: #ca181d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_38cce_row3_col5 {\n",
       "  background-color: #8dc1dd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_38cce_row4_col1 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_38cce_row4_col3 {\n",
       "  background-color: #98d368;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_38cce_row4_col4 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_38cce_row4_col5 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_38cce_row5_col1 {\n",
       "  background-color: #e9f7e5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_38cce_row5_col3 {\n",
       "  background-color: #d62f27;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_38cce_row5_col4 {\n",
       "  background-color: #ffebe2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_38cce_row5_col5 {\n",
       "  background-color: #9fcae1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_38cce_row6_col4 {\n",
       "  background-color: #fdd2bf;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_38cce_row6_col5 {\n",
       "  background-color: #caddf0;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_38cce\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_38cce_level0_col0\" class=\"col_heading level0 col0\" >lr</th>\n",
       "      <th id=\"T_38cce_level0_col1\" class=\"col_heading level0 col1\" >main_metric</th>\n",
       "      <th id=\"T_38cce_level0_col2\" class=\"col_heading level0 col2\" >prompting_score</th>\n",
       "      <th id=\"T_38cce_level0_col3\" class=\"col_heading level0 col3\" >gain_vs_prompting</th>\n",
       "      <th id=\"T_38cce_level0_col4\" class=\"col_heading level0 col4\" >loss_gap</th>\n",
       "      <th id=\"T_38cce_level0_col5\" class=\"col_heading level0 col5\" >symmetry</th>\n",
       "      <th id=\"T_38cce_level0_col6\" class=\"col_heading level0 col6\" >n</th>\n",
       "      <th id=\"T_38cce_level0_col7\" class=\"col_heading level0 col7\" >is_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_38cce_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_38cce_row0_col0\" class=\"data row0 col0\" >0.000001</td>\n",
       "      <td id=\"T_38cce_row0_col1\" class=\"data row0 col1\" >60.1</td>\n",
       "      <td id=\"T_38cce_row0_col2\" class=\"data row0 col2\" >-</td>\n",
       "      <td id=\"T_38cce_row0_col3\" class=\"data row0 col3\" >-</td>\n",
       "      <td id=\"T_38cce_row0_col4\" class=\"data row0 col4\" >1.02</td>\n",
       "      <td id=\"T_38cce_row0_col5\" class=\"data row0 col5\" >0.58</td>\n",
       "      <td id=\"T_38cce_row0_col6\" class=\"data row0 col6\" >1</td>\n",
       "      <td id=\"T_38cce_row0_col7\" class=\"data row0 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_38cce_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_38cce_row1_col0\" class=\"data row1 col0\" >0.000010</td>\n",
       "      <td id=\"T_38cce_row1_col1\" class=\"data row1 col1\" >94.6</td>\n",
       "      <td id=\"T_38cce_row1_col2\" class=\"data row1 col2\" >613.2</td>\n",
       "      <td id=\"T_38cce_row1_col3\" class=\"data row1 col3\" >-94</td>\n",
       "      <td id=\"T_38cce_row1_col4\" class=\"data row1 col4\" >-0.35</td>\n",
       "      <td id=\"T_38cce_row1_col5\" class=\"data row1 col5\" >0.89</td>\n",
       "      <td id=\"T_38cce_row1_col6\" class=\"data row1 col6\" >2</td>\n",
       "      <td id=\"T_38cce_row1_col7\" class=\"data row1 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_38cce_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_38cce_row2_col0\" class=\"data row2 col0\" >0.000100</td>\n",
       "      <td id=\"T_38cce_row2_col1\" class=\"data row2 col1\" >63.8</td>\n",
       "      <td id=\"T_38cce_row2_col2\" class=\"data row2 col2\" >613.2</td>\n",
       "      <td id=\"T_38cce_row2_col3\" class=\"data row2 col3\" >-90</td>\n",
       "      <td id=\"T_38cce_row2_col4\" class=\"data row2 col4\" >2.53</td>\n",
       "      <td id=\"T_38cce_row2_col5\" class=\"data row2 col5\" >0.52</td>\n",
       "      <td id=\"T_38cce_row2_col6\" class=\"data row2 col6\" >2</td>\n",
       "      <td id=\"T_38cce_row2_col7\" class=\"data row2 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_38cce_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_38cce_row3_col0\" class=\"data row3 col0\" >0.001000</td>\n",
       "      <td id=\"T_38cce_row3_col1\" class=\"data row3 col1\" >473.8</td>\n",
       "      <td id=\"T_38cce_row3_col2\" class=\"data row3 col2\" >613.2</td>\n",
       "      <td id=\"T_38cce_row3_col3\" class=\"data row3 col3\" >-65</td>\n",
       "      <td id=\"T_38cce_row3_col4\" class=\"data row3 col4\" >3.26</td>\n",
       "      <td id=\"T_38cce_row3_col5\" class=\"data row3 col5\" >0.58</td>\n",
       "      <td id=\"T_38cce_row3_col6\" class=\"data row3 col6\" >2</td>\n",
       "      <td id=\"T_38cce_row3_col7\" class=\"data row3 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_38cce_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_38cce_row4_col0\" class=\"data row4 col0\" >0.010000</td>\n",
       "      <td id=\"T_38cce_row4_col1\" class=\"data row4 col1\" >706.4</td>\n",
       "      <td id=\"T_38cce_row4_col2\" class=\"data row4 col2\" >613.2</td>\n",
       "      <td id=\"T_38cce_row4_col3\" class=\"data row4 col3\" >+44</td>\n",
       "      <td id=\"T_38cce_row4_col4\" class=\"data row4 col4\" >14.16</td>\n",
       "      <td id=\"T_38cce_row4_col5\" class=\"data row4 col5\" >0.35</td>\n",
       "      <td id=\"T_38cce_row4_col6\" class=\"data row4 col6\" >2</td>\n",
       "      <td id=\"T_38cce_row4_col7\" class=\"data row4 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_38cce_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_38cce_row5_col0\" class=\"data row5 col0\" >0.100000</td>\n",
       "      <td id=\"T_38cce_row5_col1\" class=\"data row5 col1\" >121.6</td>\n",
       "      <td id=\"T_38cce_row5_col2\" class=\"data row5 col2\" >613.2</td>\n",
       "      <td id=\"T_38cce_row5_col3\" class=\"data row5 col3\" >-80</td>\n",
       "      <td id=\"T_38cce_row5_col4\" class=\"data row5 col4\" >13.29</td>\n",
       "      <td id=\"T_38cce_row5_col5\" class=\"data row5 col5\" >0.55</td>\n",
       "      <td id=\"T_38cce_row5_col6\" class=\"data row5 col6\" >2</td>\n",
       "      <td id=\"T_38cce_row5_col7\" class=\"data row5 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_38cce_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_38cce_row6_col0\" class=\"data row6 col0\" >1.000000</td>\n",
       "      <td id=\"T_38cce_row6_col1\" class=\"data row6 col1\" >67.0</td>\n",
       "      <td id=\"T_38cce_row6_col2\" class=\"data row6 col2\" >613.2</td>\n",
       "      <td id=\"T_38cce_row6_col3\" class=\"data row6 col3\" >-91</td>\n",
       "      <td id=\"T_38cce_row6_col4\" class=\"data row6 col4\" >11.62</td>\n",
       "      <td id=\"T_38cce_row6_col5\" class=\"data row6 col5\" >0.48</td>\n",
       "      <td id=\"T_38cce_row6_col6\" class=\"data row6 col6\" >2</td>\n",
       "      <td id=\"T_38cce_row6_col7\" class=\"data row6 col7\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7a3ecab24700>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sweep-rank (n=13, 2 dates, control: r)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2f9f9_row0_col1 {\n",
       "  background-color: #a3da9d;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2f9f9_row0_col3, #T_2f9f9_row1_col3, #T_2f9f9_row7_col3 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row0_col4 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row0_col5 {\n",
       "  background-color: #a5cde3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2f9f9_row1_col1 {\n",
       "  background-color: #afdfa8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2f9f9_row1_col4 {\n",
       "  background-color: #69000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row1_col5 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2f9f9_row2_col1 {\n",
       "  background-color: #b6e2af;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2f9f9_row2_col3 {\n",
       "  background-color: #e75337;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row2_col4 {\n",
       "  background-color: #8e0912;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row2_col5 {\n",
       "  background-color: #bdd7ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2f9f9_row3_col1 {\n",
       "  background-color: #e6f5e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2f9f9_row3_col3 {\n",
       "  background-color: #d62f27;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row3_col4 {\n",
       "  background-color: #c7171c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row3_col5 {\n",
       "  background-color: #91c3de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2f9f9_row4_col1 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row4_col3 {\n",
       "  background-color: #a50026;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row4_col4 {\n",
       "  background-color: #9a0c14;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row4_col5 {\n",
       "  background-color: #8dc1dd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2f9f9_row5_col1 {\n",
       "  background-color: #3fa95c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row5_col3 {\n",
       "  background-color: #ef633f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row5_col4 {\n",
       "  background-color: #f24633;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row5_col5 {\n",
       "  background-color: #cadef0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2f9f9_row6_col1 {\n",
       "  background-color: #43ac5e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row6_col3 {\n",
       "  background-color: #b91326;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row6_col4 {\n",
       "  background-color: #fb7050;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2f9f9_row6_col5 {\n",
       "  background-color: #9cc9e1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2f9f9_row7_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2f9f9_row7_col4 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2f9f9_row7_col5 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2f9f9\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2f9f9_level0_col0\" class=\"col_heading level0 col0\" >r</th>\n",
       "      <th id=\"T_2f9f9_level0_col1\" class=\"col_heading level0 col1\" >main_metric</th>\n",
       "      <th id=\"T_2f9f9_level0_col2\" class=\"col_heading level0 col2\" >prompting_score</th>\n",
       "      <th id=\"T_2f9f9_level0_col3\" class=\"col_heading level0 col3\" >gain_vs_prompting</th>\n",
       "      <th id=\"T_2f9f9_level0_col4\" class=\"col_heading level0 col4\" >loss_gap</th>\n",
       "      <th id=\"T_2f9f9_level0_col5\" class=\"col_heading level0 col5\" >symmetry</th>\n",
       "      <th id=\"T_2f9f9_level0_col6\" class=\"col_heading level0 col6\" >n</th>\n",
       "      <th id=\"T_2f9f9_level0_col7\" class=\"col_heading level0 col7\" >is_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2f9f9_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2f9f9_row0_col0\" class=\"data row0 col0\" >8</td>\n",
       "      <td id=\"T_2f9f9_row0_col1\" class=\"data row0 col1\" >190.3</td>\n",
       "      <td id=\"T_2f9f9_row0_col2\" class=\"data row0 col2\" >-</td>\n",
       "      <td id=\"T_2f9f9_row0_col3\" class=\"data row0 col3\" >-</td>\n",
       "      <td id=\"T_2f9f9_row0_col4\" class=\"data row0 col4\" >0.62</td>\n",
       "      <td id=\"T_2f9f9_row0_col5\" class=\"data row0 col5\" >0.50</td>\n",
       "      <td id=\"T_2f9f9_row0_col6\" class=\"data row0 col6\" >1</td>\n",
       "      <td id=\"T_2f9f9_row0_col7\" class=\"data row0 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f9f9_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_2f9f9_row1_col0\" class=\"data row1 col0\" >16</td>\n",
       "      <td id=\"T_2f9f9_row1_col1\" class=\"data row1 col1\" >170.7</td>\n",
       "      <td id=\"T_2f9f9_row1_col2\" class=\"data row1 col2\" >-</td>\n",
       "      <td id=\"T_2f9f9_row1_col3\" class=\"data row1 col3\" >-</td>\n",
       "      <td id=\"T_2f9f9_row1_col4\" class=\"data row1 col4\" >0.75</td>\n",
       "      <td id=\"T_2f9f9_row1_col5\" class=\"data row1 col5\" >0.23</td>\n",
       "      <td id=\"T_2f9f9_row1_col6\" class=\"data row1 col6\" >1</td>\n",
       "      <td id=\"T_2f9f9_row1_col7\" class=\"data row1 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f9f9_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_2f9f9_row2_col0\" class=\"data row2 col0\" >32</td>\n",
       "      <td id=\"T_2f9f9_row2_col1\" class=\"data row2 col1\" >159.4</td>\n",
       "      <td id=\"T_2f9f9_row2_col2\" class=\"data row2 col2\" >613.2</td>\n",
       "      <td id=\"T_2f9f9_row2_col3\" class=\"data row2 col3\" >-68</td>\n",
       "      <td id=\"T_2f9f9_row2_col4\" class=\"data row2 col4\" >2.41</td>\n",
       "      <td id=\"T_2f9f9_row2_col5\" class=\"data row2 col5\" >0.44</td>\n",
       "      <td id=\"T_2f9f9_row2_col6\" class=\"data row2 col6\" >2</td>\n",
       "      <td id=\"T_2f9f9_row2_col7\" class=\"data row2 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f9f9_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_2f9f9_row3_col0\" class=\"data row3 col0\" >64</td>\n",
       "      <td id=\"T_2f9f9_row3_col1\" class=\"data row3 col1\" >63.8</td>\n",
       "      <td id=\"T_2f9f9_row3_col2\" class=\"data row3 col2\" >613.2</td>\n",
       "      <td id=\"T_2f9f9_row3_col3\" class=\"data row3 col3\" >-80</td>\n",
       "      <td id=\"T_2f9f9_row3_col4\" class=\"data row3 col4\" >5.98</td>\n",
       "      <td id=\"T_2f9f9_row3_col5\" class=\"data row3 col5\" >0.54</td>\n",
       "      <td id=\"T_2f9f9_row3_col6\" class=\"data row3 col6\" >2</td>\n",
       "      <td id=\"T_2f9f9_row3_col7\" class=\"data row3 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f9f9_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_2f9f9_row4_col0\" class=\"data row4 col0\" >128</td>\n",
       "      <td id=\"T_2f9f9_row4_col1\" class=\"data row4 col1\" >511.9</td>\n",
       "      <td id=\"T_2f9f9_row4_col2\" class=\"data row4 col2\" >613.2</td>\n",
       "      <td id=\"T_2f9f9_row4_col3\" class=\"data row4 col3\" >-100</td>\n",
       "      <td id=\"T_2f9f9_row4_col4\" class=\"data row4 col4\" >2.95</td>\n",
       "      <td id=\"T_2f9f9_row4_col5\" class=\"data row4 col5\" >0.55</td>\n",
       "      <td id=\"T_2f9f9_row4_col6\" class=\"data row4 col6\" >2</td>\n",
       "      <td id=\"T_2f9f9_row4_col7\" class=\"data row4 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f9f9_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_2f9f9_row5_col0\" class=\"data row5 col0\" >256</td>\n",
       "      <td id=\"T_2f9f9_row5_col1\" class=\"data row5 col1\" >324.2</td>\n",
       "      <td id=\"T_2f9f9_row5_col2\" class=\"data row5 col2\" >613.2</td>\n",
       "      <td id=\"T_2f9f9_row5_col3\" class=\"data row5 col3\" >-63</td>\n",
       "      <td id=\"T_2f9f9_row5_col4\" class=\"data row5 col4\" >9.77</td>\n",
       "      <td id=\"T_2f9f9_row5_col5\" class=\"data row5 col5\" >0.40</td>\n",
       "      <td id=\"T_2f9f9_row5_col6\" class=\"data row5 col6\" >2</td>\n",
       "      <td id=\"T_2f9f9_row5_col7\" class=\"data row5 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f9f9_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_2f9f9_row6_col0\" class=\"data row6 col0\" >512</td>\n",
       "      <td id=\"T_2f9f9_row6_col1\" class=\"data row6 col1\" >317.4</td>\n",
       "      <td id=\"T_2f9f9_row6_col2\" class=\"data row6 col2\" >613.2</td>\n",
       "      <td id=\"T_2f9f9_row6_col3\" class=\"data row6 col3\" >-92</td>\n",
       "      <td id=\"T_2f9f9_row6_col4\" class=\"data row6 col4\" >12.32</td>\n",
       "      <td id=\"T_2f9f9_row6_col5\" class=\"data row6 col5\" >0.52</td>\n",
       "      <td id=\"T_2f9f9_row6_col6\" class=\"data row6 col6\" >2</td>\n",
       "      <td id=\"T_2f9f9_row6_col7\" class=\"data row6 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2f9f9_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_2f9f9_row7_col0\" class=\"data row7 col0\" >1024</td>\n",
       "      <td id=\"T_2f9f9_row7_col1\" class=\"data row7 col1\" >2.5</td>\n",
       "      <td id=\"T_2f9f9_row7_col2\" class=\"data row7 col2\" >-</td>\n",
       "      <td id=\"T_2f9f9_row7_col3\" class=\"data row7 col3\" >-</td>\n",
       "      <td id=\"T_2f9f9_row7_col4\" class=\"data row7 col4\" >23.26</td>\n",
       "      <td id=\"T_2f9f9_row7_col5\" class=\"data row7 col5\" >1.00</td>\n",
       "      <td id=\"T_2f9f9_row7_col6\" class=\"data row7 col6\" >1</td>\n",
       "      <td id=\"T_2f9f9_row7_col7\" class=\"data row7 col7\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7a3ec8afb010>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ablate-wd (n=16, 2 dates, control: wd)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_36f37_row0_col1 {\n",
       "  background-color: #d1edcb;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_36f37_row0_col3, #T_36f37_row1_col3, #T_36f37_row2_col3, #T_36f37_row3_col3, #T_36f37_row4_col3, #T_36f37_row5_col3, #T_36f37_row6_col3, #T_36f37_row7_col3, #T_36f37_row8_col3, #T_36f37_row8_col5 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row0_col4 {\n",
       "  background-color: #f4503a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row0_col5 {\n",
       "  background-color: #99c7e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_36f37_row1_col1 {\n",
       "  background-color: #8dd08a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_36f37_row1_col4 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row1_col5 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_36f37_row2_col1 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row2_col4 {\n",
       "  background-color: #fa6547;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row2_col5 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row3_col1 {\n",
       "  background-color: #117b38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row3_col4 {\n",
       "  background-color: #a50f15;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row3_col5 {\n",
       "  background-color: #1c6bb0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row4_col1 {\n",
       "  background-color: #91d28e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_36f37_row4_col4 {\n",
       "  background-color: #71020e;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row4_col5 {\n",
       "  background-color: #4d99ca;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row5_col1 {\n",
       "  background-color: #228a44;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row5_col4 {\n",
       "  background-color: #920a13;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row5_col5 {\n",
       "  background-color: #4191c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row6_col1 {\n",
       "  background-color: #3da65a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row6_col4 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_36f37_row6_col5 {\n",
       "  background-color: #d6e6f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_36f37_row7_col1 {\n",
       "  background-color: #c7e9c0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_36f37_row7_col4 {\n",
       "  background-color: #f44d38;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row7_col5 {\n",
       "  background-color: #549fcd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_36f37_row8_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_36f37_row8_col4 {\n",
       "  background-color: #800610;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_36f37\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_36f37_level0_col0\" class=\"col_heading level0 col0\" >wd</th>\n",
       "      <th id=\"T_36f37_level0_col1\" class=\"col_heading level0 col1\" >main_metric</th>\n",
       "      <th id=\"T_36f37_level0_col2\" class=\"col_heading level0 col2\" >prompting_score</th>\n",
       "      <th id=\"T_36f37_level0_col3\" class=\"col_heading level0 col3\" >gain_vs_prompting</th>\n",
       "      <th id=\"T_36f37_level0_col4\" class=\"col_heading level0 col4\" >loss_gap</th>\n",
       "      <th id=\"T_36f37_level0_col5\" class=\"col_heading level0 col5\" >symmetry</th>\n",
       "      <th id=\"T_36f37_level0_col6\" class=\"col_heading level0 col6\" >n</th>\n",
       "      <th id=\"T_36f37_level0_col7\" class=\"col_heading level0 col7\" >is_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_36f37_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_36f37_row0_col0\" class=\"data row0 col0\" >0.000000</td>\n",
       "      <td id=\"T_36f37_row0_col1\" class=\"data row0 col1\" >307.8</td>\n",
       "      <td id=\"T_36f37_row0_col2\" class=\"data row0 col2\" >-</td>\n",
       "      <td id=\"T_36f37_row0_col3\" class=\"data row0 col3\" >-</td>\n",
       "      <td id=\"T_36f37_row0_col4\" class=\"data row0 col4\" >14.22</td>\n",
       "      <td id=\"T_36f37_row0_col5\" class=\"data row0 col5\" >0.34</td>\n",
       "      <td id=\"T_36f37_row0_col6\" class=\"data row0 col6\" >2</td>\n",
       "      <td id=\"T_36f37_row0_col7\" class=\"data row0 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_36f37_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_36f37_row1_col0\" class=\"data row1 col0\" >0.000000</td>\n",
       "      <td id=\"T_36f37_row1_col1\" class=\"data row1 col1\" >520.7</td>\n",
       "      <td id=\"T_36f37_row1_col2\" class=\"data row1 col2\" >-</td>\n",
       "      <td id=\"T_36f37_row1_col3\" class=\"data row1 col3\" >-</td>\n",
       "      <td id=\"T_36f37_row1_col4\" class=\"data row1 col4\" >5.16</td>\n",
       "      <td id=\"T_36f37_row1_col5\" class=\"data row1 col5\" >0.06</td>\n",
       "      <td id=\"T_36f37_row1_col6\" class=\"data row1 col6\" >2</td>\n",
       "      <td id=\"T_36f37_row1_col7\" class=\"data row1 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_36f37_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_36f37_row2_col0\" class=\"data row2 col0\" >0.000001</td>\n",
       "      <td id=\"T_36f37_row2_col1\" class=\"data row2 col1\" >1061.9</td>\n",
       "      <td id=\"T_36f37_row2_col2\" class=\"data row2 col2\" >-</td>\n",
       "      <td id=\"T_36f37_row2_col3\" class=\"data row2 col3\" >-</td>\n",
       "      <td id=\"T_36f37_row2_col4\" class=\"data row2 col4\" >15.34</td>\n",
       "      <td id=\"T_36f37_row2_col5\" class=\"data row2 col5\" >0.77</td>\n",
       "      <td id=\"T_36f37_row2_col6\" class=\"data row2 col6\" >2</td>\n",
       "      <td id=\"T_36f37_row2_col7\" class=\"data row2 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_36f37_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_36f37_row3_col0\" class=\"data row3 col0\" >0.000010</td>\n",
       "      <td id=\"T_36f37_row3_col1\" class=\"data row3 col1\" >886.3</td>\n",
       "      <td id=\"T_36f37_row3_col2\" class=\"data row3 col2\" >-</td>\n",
       "      <td id=\"T_36f37_row3_col3\" class=\"data row3 col3\" >-</td>\n",
       "      <td id=\"T_36f37_row3_col4\" class=\"data row3 col4\" >7.80</td>\n",
       "      <td id=\"T_36f37_row3_col5\" class=\"data row3 col5\" >0.61</td>\n",
       "      <td id=\"T_36f37_row3_col6\" class=\"data row3 col6\" >2</td>\n",
       "      <td id=\"T_36f37_row3_col7\" class=\"data row3 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_36f37_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_36f37_row4_col0\" class=\"data row4 col0\" >0.000100</td>\n",
       "      <td id=\"T_36f37_row4_col1\" class=\"data row4 col1\" >511.8</td>\n",
       "      <td id=\"T_36f37_row4_col2\" class=\"data row4 col2\" >-</td>\n",
       "      <td id=\"T_36f37_row4_col3\" class=\"data row4 col3\" >-</td>\n",
       "      <td id=\"T_36f37_row4_col4\" class=\"data row4 col4\" >5.64</td>\n",
       "      <td id=\"T_36f37_row4_col5\" class=\"data row4 col5\" >0.48</td>\n",
       "      <td id=\"T_36f37_row4_col6\" class=\"data row4 col6\" >2</td>\n",
       "      <td id=\"T_36f37_row4_col7\" class=\"data row4 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_36f37_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_36f37_row5_col0\" class=\"data row5 col0\" >0.001000</td>\n",
       "      <td id=\"T_36f37_row5_col1\" class=\"data row5 col1\" >824.2</td>\n",
       "      <td id=\"T_36f37_row5_col2\" class=\"data row5 col2\" >-</td>\n",
       "      <td id=\"T_36f37_row5_col3\" class=\"data row5 col3\" >-</td>\n",
       "      <td id=\"T_36f37_row5_col4\" class=\"data row5 col4\" >6.98</td>\n",
       "      <td id=\"T_36f37_row5_col5\" class=\"data row5 col5\" >0.51</td>\n",
       "      <td id=\"T_36f37_row5_col6\" class=\"data row5 col6\" >2</td>\n",
       "      <td id=\"T_36f37_row5_col7\" class=\"data row5 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_36f37_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_36f37_row6_col0\" class=\"data row6 col0\" >0.010000</td>\n",
       "      <td id=\"T_36f37_row6_col1\" class=\"data row6 col1\" >723.5</td>\n",
       "      <td id=\"T_36f37_row6_col2\" class=\"data row6 col2\" >-</td>\n",
       "      <td id=\"T_36f37_row6_col3\" class=\"data row6 col3\" >-</td>\n",
       "      <td id=\"T_36f37_row6_col4\" class=\"data row6 col4\" >26.09</td>\n",
       "      <td id=\"T_36f37_row6_col5\" class=\"data row6 col5\" >0.18</td>\n",
       "      <td id=\"T_36f37_row6_col6\" class=\"data row6 col6\" >1</td>\n",
       "      <td id=\"T_36f37_row6_col7\" class=\"data row6 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_36f37_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_36f37_row7_col0\" class=\"data row7 col0\" >0.100000</td>\n",
       "      <td id=\"T_36f37_row7_col1\" class=\"data row7 col1\" >351.2</td>\n",
       "      <td id=\"T_36f37_row7_col2\" class=\"data row7 col2\" >-</td>\n",
       "      <td id=\"T_36f37_row7_col3\" class=\"data row7 col3\" >-</td>\n",
       "      <td id=\"T_36f37_row7_col4\" class=\"data row7 col4\" >14.03</td>\n",
       "      <td id=\"T_36f37_row7_col5\" class=\"data row7 col5\" >0.47</td>\n",
       "      <td id=\"T_36f37_row7_col6\" class=\"data row7 col6\" >2</td>\n",
       "      <td id=\"T_36f37_row7_col7\" class=\"data row7 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_36f37_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_36f37_row8_col0\" class=\"data row8 col0\" >1.000000</td>\n",
       "      <td id=\"T_36f37_row8_col1\" class=\"data row8 col1\" >110.8</td>\n",
       "      <td id=\"T_36f37_row8_col2\" class=\"data row8 col2\" >-</td>\n",
       "      <td id=\"T_36f37_row8_col3\" class=\"data row8 col3\" >-</td>\n",
       "      <td id=\"T_36f37_row8_col4\" class=\"data row8 col4\" >6.26</td>\n",
       "      <td id=\"T_36f37_row8_col5\" class=\"data row8 col5\" >-</td>\n",
       "      <td id=\"T_36f37_row8_col6\" class=\"data row8 col6\" >1</td>\n",
       "      <td id=\"T_36f37_row8_col7\" class=\"data row8 col7\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7a3ecab279a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sweep-snorm: (No data or 'unknown' not found)\n",
      "\n",
      "sweep-pref-dir: (No data or 'unknown' not found)\n",
      "\n",
      "sweep-training-stages: (No data or 'unknown' not found)\n",
      "\n",
      "ablate-modules (n=12, 2 dates, control: scale_s)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_b643f_row0_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_b643f_row0_col3 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b643f_row0_col4 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_b643f_row0_col5 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_b643f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_b643f_level0_col0\" class=\"col_heading level0 col0\" >scale_s</th>\n",
       "      <th id=\"T_b643f_level0_col1\" class=\"col_heading level0 col1\" >main_metric</th>\n",
       "      <th id=\"T_b643f_level0_col2\" class=\"col_heading level0 col2\" >prompting_score</th>\n",
       "      <th id=\"T_b643f_level0_col3\" class=\"col_heading level0 col3\" >gain_vs_prompting</th>\n",
       "      <th id=\"T_b643f_level0_col4\" class=\"col_heading level0 col4\" >loss_gap</th>\n",
       "      <th id=\"T_b643f_level0_col5\" class=\"col_heading level0 col5\" >symmetry</th>\n",
       "      <th id=\"T_b643f_level0_col6\" class=\"col_heading level0 col6\" >n</th>\n",
       "      <th id=\"T_b643f_level0_col7\" class=\"col_heading level0 col7\" >is_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_b643f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_b643f_row0_col0\" class=\"data row0 col0\" >add2</td>\n",
       "      <td id=\"T_b643f_row0_col1\" class=\"data row0 col1\" >530.4</td>\n",
       "      <td id=\"T_b643f_row0_col2\" class=\"data row0 col2\" >-</td>\n",
       "      <td id=\"T_b643f_row0_col3\" class=\"data row0 col3\" >-</td>\n",
       "      <td id=\"T_b643f_row0_col4\" class=\"data row0 col4\" >12.08</td>\n",
       "      <td id=\"T_b643f_row0_col5\" class=\"data row0 col5\" >0.69</td>\n",
       "      <td id=\"T_b643f_row0_col6\" class=\"data row0 col6\" >12</td>\n",
       "      <td id=\"T_b643f_row0_col7\" class=\"data row0 col7\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7a3ec857a2f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "run-models (n=16, 2 dates, control: model_name)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_260f7_row0_col1, #T_260f7_row6_col1 {\n",
       "  background-color: #c1e6ba;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_260f7_row0_col3 {\n",
       "  background-color: #128a49;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_260f7_row0_col4 {\n",
       "  background-color: #fc997a;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_260f7_row0_col5 {\n",
       "  background-color: #4191c6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_260f7_row1_col1 {\n",
       "  background-color: #00481d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_260f7_row1_col3, #T_260f7_row4_col3, #T_260f7_row5_col3 {\n",
       "  background-color: #000000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_260f7_row1_col4 {\n",
       "  background-color: #ee3a2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_260f7_row1_col5 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_260f7_row2_col1 {\n",
       "  background-color: #349d53;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_260f7_row2_col3 {\n",
       "  background-color: #006837;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_260f7_row2_col4 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_260f7_row2_col5 {\n",
       "  background-color: #d4e4f4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_260f7_row3_col1 {\n",
       "  background-color: #b1e0ab;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_260f7_row3_col3 {\n",
       "  background-color: #fede89;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_260f7_row3_col4 {\n",
       "  background-color: #fc8767;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_260f7_row3_col5 {\n",
       "  background-color: #9ac8e0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_260f7_row4_col1 {\n",
       "  background-color: #0b7734;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_260f7_row4_col4 {\n",
       "  background-color: #ffede5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_260f7_row4_col5 {\n",
       "  background-color: #a6cee4;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_260f7_row5_col1 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_260f7_row5_col4 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_260f7_row5_col5 {\n",
       "  background-color: #c8dcf0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_260f7_row6_col3 {\n",
       "  background-color: #d9ef8b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_260f7_row6_col4 {\n",
       "  background-color: #fca78b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_260f7_row6_col5 {\n",
       "  background-color: #3b8bc2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_260f7_row7_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_260f7_row7_col3 {\n",
       "  background-color: #e95538;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_260f7_row7_col4 {\n",
       "  background-color: #aa1016;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_260f7_row7_col5 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_260f7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_260f7_level0_col0\" class=\"col_heading level0 col0\" >model_name</th>\n",
       "      <th id=\"T_260f7_level0_col1\" class=\"col_heading level0 col1\" >main_metric</th>\n",
       "      <th id=\"T_260f7_level0_col2\" class=\"col_heading level0 col2\" >prompting_score</th>\n",
       "      <th id=\"T_260f7_level0_col3\" class=\"col_heading level0 col3\" >gain_vs_prompting</th>\n",
       "      <th id=\"T_260f7_level0_col4\" class=\"col_heading level0 col4\" >loss_gap</th>\n",
       "      <th id=\"T_260f7_level0_col5\" class=\"col_heading level0 col5\" >symmetry</th>\n",
       "      <th id=\"T_260f7_level0_col6\" class=\"col_heading level0 col6\" >n</th>\n",
       "      <th id=\"T_260f7_level0_col7\" class=\"col_heading level0 col7\" >is_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_260f7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_260f7_row0_col0\" class=\"data row0 col0\" >Qwen3-0.6B</td>\n",
       "      <td id=\"T_260f7_row0_col1\" class=\"data row0 col1\" >332.9</td>\n",
       "      <td id=\"T_260f7_row0_col2\" class=\"data row0 col2\" >179.8</td>\n",
       "      <td id=\"T_260f7_row0_col3\" class=\"data row0 col3\" >+85</td>\n",
       "      <td id=\"T_260f7_row0_col4\" class=\"data row0 col4\" >20.87</td>\n",
       "      <td id=\"T_260f7_row0_col5\" class=\"data row0 col5\" >0.51</td>\n",
       "      <td id=\"T_260f7_row0_col6\" class=\"data row0 col6\" >2</td>\n",
       "      <td id=\"T_260f7_row0_col7\" class=\"data row0 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_260f7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_260f7_row1_col0\" class=\"data row1 col0\" >Qwen3-4B</td>\n",
       "      <td id=\"T_260f7_row1_col1\" class=\"data row1 col1\" >953.3</td>\n",
       "      <td id=\"T_260f7_row1_col2\" class=\"data row1 col2\" >-</td>\n",
       "      <td id=\"T_260f7_row1_col3\" class=\"data row1 col3\" >-</td>\n",
       "      <td id=\"T_260f7_row1_col4\" class=\"data row1 col4\" >14.08</td>\n",
       "      <td id=\"T_260f7_row1_col5\" class=\"data row1 col5\" >0.24</td>\n",
       "      <td id=\"T_260f7_row1_col6\" class=\"data row1 col6\" >2</td>\n",
       "      <td id=\"T_260f7_row1_col7\" class=\"data row1 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_260f7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_260f7_row2_col0\" class=\"data row2 col0\" >Qwen3-4B-Base</td>\n",
       "      <td id=\"T_260f7_row2_col1\" class=\"data row2 col1\" >685.8</td>\n",
       "      <td id=\"T_260f7_row2_col2\" class=\"data row2 col2\" >15.4</td>\n",
       "      <td id=\"T_260f7_row2_col3\" class=\"data row2 col3\" >+4348</td>\n",
       "      <td id=\"T_260f7_row2_col4\" class=\"data row2 col4\" >4.77</td>\n",
       "      <td id=\"T_260f7_row2_col5\" class=\"data row2 col5\" >0.32</td>\n",
       "      <td id=\"T_260f7_row2_col6\" class=\"data row2 col6\" >2</td>\n",
       "      <td id=\"T_260f7_row2_col7\" class=\"data row2 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_260f7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_260f7_row3_col0\" class=\"data row3 col0\" >gemma-3-12b-it</td>\n",
       "      <td id=\"T_260f7_row3_col1\" class=\"data row3 col1\" >374.4</td>\n",
       "      <td id=\"T_260f7_row3_col2\" class=\"data row3 col2\" >470.1</td>\n",
       "      <td id=\"T_260f7_row3_col3\" class=\"data row3 col3\" >-20</td>\n",
       "      <td id=\"T_260f7_row3_col4\" class=\"data row3 col4\" >19.46</td>\n",
       "      <td id=\"T_260f7_row3_col5\" class=\"data row3 col5\" >0.40</td>\n",
       "      <td id=\"T_260f7_row3_col6\" class=\"data row3 col6\" >2</td>\n",
       "      <td id=\"T_260f7_row3_col7\" class=\"data row3 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_260f7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_260f7_row4_col0\" class=\"data row4 col0\" >gemma-3-1b-it</td>\n",
       "      <td id=\"T_260f7_row4_col1\" class=\"data row4 col1\" >820.5</td>\n",
       "      <td id=\"T_260f7_row4_col2\" class=\"data row4 col2\" >-</td>\n",
       "      <td id=\"T_260f7_row4_col3\" class=\"data row4 col3\" >-</td>\n",
       "      <td id=\"T_260f7_row4_col4\" class=\"data row4 col4\" >28.40</td>\n",
       "      <td id=\"T_260f7_row4_col5\" class=\"data row4 col5\" >0.39</td>\n",
       "      <td id=\"T_260f7_row4_col6\" class=\"data row4 col6\" >2</td>\n",
       "      <td id=\"T_260f7_row4_col7\" class=\"data row4 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_260f7_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_260f7_row5_col0\" class=\"data row5 col0\" >gemma-3-270m-it</td>\n",
       "      <td id=\"T_260f7_row5_col1\" class=\"data row5 col1\" >965.7</td>\n",
       "      <td id=\"T_260f7_row5_col2\" class=\"data row5 col2\" >-</td>\n",
       "      <td id=\"T_260f7_row5_col3\" class=\"data row5 col3\" >-</td>\n",
       "      <td id=\"T_260f7_row5_col4\" class=\"data row5 col4\" >29.66</td>\n",
       "      <td id=\"T_260f7_row5_col5\" class=\"data row5 col5\" >0.34</td>\n",
       "      <td id=\"T_260f7_row5_col6\" class=\"data row5 col6\" >2</td>\n",
       "      <td id=\"T_260f7_row5_col7\" class=\"data row5 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_260f7_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_260f7_row6_col0\" class=\"data row6 col0\" >gemma-3-4b-it</td>\n",
       "      <td id=\"T_260f7_row6_col1\" class=\"data row6 col1\" >332.1</td>\n",
       "      <td id=\"T_260f7_row6_col2\" class=\"data row6 col2\" >277.2</td>\n",
       "      <td id=\"T_260f7_row6_col3\" class=\"data row6 col3\" >+20</td>\n",
       "      <td id=\"T_260f7_row6_col4\" class=\"data row6 col4\" >21.97</td>\n",
       "      <td id=\"T_260f7_row6_col5\" class=\"data row6 col5\" >0.52</td>\n",
       "      <td id=\"T_260f7_row6_col6\" class=\"data row6 col6\" >2</td>\n",
       "      <td id=\"T_260f7_row6_col7\" class=\"data row6 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_260f7_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_260f7_row7_col0\" class=\"data row7 col0\" >Llama-3.1-8B-Instruct</td>\n",
       "      <td id=\"T_260f7_row7_col1\" class=\"data row7 col1\" >95.1</td>\n",
       "      <td id=\"T_260f7_row7_col2\" class=\"data row7 col2\" >293.9</td>\n",
       "      <td id=\"T_260f7_row7_col3\" class=\"data row7 col3\" >-68</td>\n",
       "      <td id=\"T_260f7_row7_col4\" class=\"data row7 col4\" >8.35</td>\n",
       "      <td id=\"T_260f7_row7_col5\" class=\"data row7 col5\" >0.66</td>\n",
       "      <td id=\"T_260f7_row7_col6\" class=\"data row7 col6\" >2</td>\n",
       "      <td id=\"T_260f7_row7_col7\" class=\"data row7 col7\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7a3ecab279a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sweep-rotation-angle (n=21, 2 dates, control: max_rotation_angle)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_28be6_row0_col1 {\n",
       "  background-color: #f7fcf5;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28be6_row0_col3 {\n",
       "  background-color: #d62f27;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28be6_row0_col4 {\n",
       "  background-color: #fff5f0;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28be6_row0_col5 {\n",
       "  background-color: #08306b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28be6_row1_col1 {\n",
       "  background-color: #e7f6e2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28be6_row1_col3 {\n",
       "  background-color: #e75337;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28be6_row1_col4 {\n",
       "  background-color: #67000d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28be6_row1_col5 {\n",
       "  background-color: #084488;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28be6_row2_col1 {\n",
       "  background-color: #359e53;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28be6_row2_col3 {\n",
       "  background-color: #feeda1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28be6_row2_col4 {\n",
       "  background-color: #fa6849;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28be6_row2_col5 {\n",
       "  background-color: #f7fbff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28be6_row3_col1 {\n",
       "  background-color: #00441b;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28be6_row3_col3 {\n",
       "  background-color: #d3ec87;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28be6_row3_col4 {\n",
       "  background-color: #ef3c2c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28be6_row3_col5 {\n",
       "  background-color: #3181bd;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28be6_row4_col1 {\n",
       "  background-color: #097532;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28be6_row4_col3 {\n",
       "  background-color: #f2faae;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28be6_row4_col4 {\n",
       "  background-color: #fdcdb9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28be6_row4_col5 {\n",
       "  background-color: #92c4de;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28be6_row5_col1 {\n",
       "  background-color: #a0d99b;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28be6_row5_col3 {\n",
       "  background-color: #fca85e;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_28be6_row5_col4 {\n",
       "  background-color: #f85f43;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_28be6_row5_col5 {\n",
       "  background-color: #084184;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_28be6\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_28be6_level0_col0\" class=\"col_heading level0 col0\" >max_rotation_angle</th>\n",
       "      <th id=\"T_28be6_level0_col1\" class=\"col_heading level0 col1\" >main_metric</th>\n",
       "      <th id=\"T_28be6_level0_col2\" class=\"col_heading level0 col2\" >prompting_score</th>\n",
       "      <th id=\"T_28be6_level0_col3\" class=\"col_heading level0 col3\" >gain_vs_prompting</th>\n",
       "      <th id=\"T_28be6_level0_col4\" class=\"col_heading level0 col4\" >loss_gap</th>\n",
       "      <th id=\"T_28be6_level0_col5\" class=\"col_heading level0 col5\" >symmetry</th>\n",
       "      <th id=\"T_28be6_level0_col6\" class=\"col_heading level0 col6\" >n</th>\n",
       "      <th id=\"T_28be6_level0_col7\" class=\"col_heading level0 col7\" >is_baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_28be6_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_28be6_row0_col0\" class=\"data row0 col0\" >0.100000</td>\n",
       "      <td id=\"T_28be6_row0_col1\" class=\"data row0 col1\" >122.5</td>\n",
       "      <td id=\"T_28be6_row0_col2\" class=\"data row0 col2\" >613.2</td>\n",
       "      <td id=\"T_28be6_row0_col3\" class=\"data row0 col3\" >-80</td>\n",
       "      <td id=\"T_28be6_row0_col4\" class=\"data row0 col4\" >8.14</td>\n",
       "      <td id=\"T_28be6_row0_col5\" class=\"data row0 col5\" >0.61</td>\n",
       "      <td id=\"T_28be6_row0_col6\" class=\"data row0 col6\" >1</td>\n",
       "      <td id=\"T_28be6_row0_col7\" class=\"data row0 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28be6_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_28be6_row1_col0\" class=\"data row1 col0\" >0.200000</td>\n",
       "      <td id=\"T_28be6_row1_col1\" class=\"data row1 col1\" >194.0</td>\n",
       "      <td id=\"T_28be6_row1_col2\" class=\"data row1 col2\" >613.2</td>\n",
       "      <td id=\"T_28be6_row1_col3\" class=\"data row1 col3\" >-68</td>\n",
       "      <td id=\"T_28be6_row1_col4\" class=\"data row1 col4\" >0.80</td>\n",
       "      <td id=\"T_28be6_row1_col5\" class=\"data row1 col5\" >0.59</td>\n",
       "      <td id=\"T_28be6_row1_col6\" class=\"data row1 col6\" >2</td>\n",
       "      <td id=\"T_28be6_row1_col7\" class=\"data row1 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28be6_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_28be6_row2_col0\" class=\"data row2 col0\" >0.300000</td>\n",
       "      <td id=\"T_28be6_row2_col1\" class=\"data row2 col1\" >545.8</td>\n",
       "      <td id=\"T_28be6_row2_col2\" class=\"data row2 col2\" >613.2</td>\n",
       "      <td id=\"T_28be6_row2_col3\" class=\"data row2 col3\" >-11</td>\n",
       "      <td id=\"T_28be6_row2_col4\" class=\"data row2 col4\" >4.42</td>\n",
       "      <td id=\"T_28be6_row2_col5\" class=\"data row2 col5\" >0.28</td>\n",
       "      <td id=\"T_28be6_row2_col6\" class=\"data row2 col6\" >4</td>\n",
       "      <td id=\"T_28be6_row2_col7\" class=\"data row2 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28be6_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_28be6_row3_col0\" class=\"data row3 col0\" >0.500000</td>\n",
       "      <td id=\"T_28be6_row3_col1\" class=\"data row3 col1\" >750.8</td>\n",
       "      <td id=\"T_28be6_row3_col2\" class=\"data row3 col2\" >613.2</td>\n",
       "      <td id=\"T_28be6_row3_col3\" class=\"data row3 col3\" >+22</td>\n",
       "      <td id=\"T_28be6_row3_col4\" class=\"data row3 col4\" >3.56</td>\n",
       "      <td id=\"T_28be6_row3_col5\" class=\"data row3 col5\" >0.51</td>\n",
       "      <td id=\"T_28be6_row3_col6\" class=\"data row3 col6\" >2</td>\n",
       "      <td id=\"T_28be6_row3_col7\" class=\"data row3 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28be6_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_28be6_row4_col0\" class=\"data row4 col0\" >1.000000</td>\n",
       "      <td id=\"T_28be6_row4_col1\" class=\"data row4 col1\" >651.5</td>\n",
       "      <td id=\"T_28be6_row4_col2\" class=\"data row4 col2\" >613.2</td>\n",
       "      <td id=\"T_28be6_row4_col3\" class=\"data row4 col3\" >+6</td>\n",
       "      <td id=\"T_28be6_row4_col4\" class=\"data row4 col4\" >6.75</td>\n",
       "      <td id=\"T_28be6_row4_col5\" class=\"data row4 col5\" >0.41</td>\n",
       "      <td id=\"T_28be6_row4_col6\" class=\"data row4 col6\" >2</td>\n",
       "      <td id=\"T_28be6_row4_col7\" class=\"data row4 col7\" ></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_28be6_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_28be6_row5_col0\" class=\"data row5 col0\" >inf</td>\n",
       "      <td id=\"T_28be6_row5_col1\" class=\"data row5 col1\" >359.0</td>\n",
       "      <td id=\"T_28be6_row5_col2\" class=\"data row5 col2\" >613.2</td>\n",
       "      <td id=\"T_28be6_row5_col3\" class=\"data row5 col3\" >-41</td>\n",
       "      <td id=\"T_28be6_row5_col4\" class=\"data row5 col4\" >4.25</td>\n",
       "      <td id=\"T_28be6_row5_col5\" class=\"data row5 col5\" >0.59</td>\n",
       "      <td id=\"T_28be6_row5_col6\" class=\"data row5 col6\" >10</td>\n",
       "      <td id=\"T_28be6_row5_col7\" class=\"data row5 col7\" ></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7a3ec8593d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sweep-long-training: (No data or 'unknown' not found)\n",
      "\n",
      "sweep-loss-modules: (No data or 'unknown' not found)\n",
      "\n",
      "sweep-layers-V: (No data or 'unknown' not found)\n",
      "\n",
      "sweep-scale: (No data or 'unknown' not found)\n"
     ]
    }
   ],
   "source": [
    "# Display styled sweep tables (using mean per condition)\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "for sweep_name in sweeps.keys():\n",
    "    if sweep_name not in sweeps:\n",
    "        continue\n",
    "    \n",
    "    df_s = sweeps[sweep_name]\n",
    "    config = SWEEP_CONFIG.get(sweep_name, {'var': 'unknown', 'baseline': None})\n",
    "    v = config['var']\n",
    "    \n",
    "    summary_df, actual_var = summarize_sweep_mean(df_s, v, config['baseline'])\n",
    "    \n",
    "    if summary_df is None or len(summary_df) == 0:\n",
    "        print(f\"\\n{sweep_name}: (No data or '{v}' not found)\")\n",
    "        continue\n",
    "    \n",
    "    # Sort by actual_var if it exists in the result\n",
    "    if actual_var in summary_df.columns:\n",
    "        summary_df = summary_df.sort_values(actual_var)\n",
    "    \n",
    "    n_dates = df_s['sweep_file'].nunique()\n",
    "    \n",
    "    # Truncate model names for display\n",
    "    if actual_var == 'model_name':\n",
    "        summary_df[actual_var] = summary_df[actual_var].apply(\n",
    "            lambda x: str(x).split('/')[-1][:30] if pd.notna(x) else x\n",
    "        )\n",
    "    \n",
    "    print(f\"\\n{sweep_name} (n={len(df_s)}, {n_dates} dates, control: {actual_var})\")\n",
    "    display(style_sweep_table(summary_df, actual_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55400f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be480b65",
   "metadata": {},
   "source": [
    "## Step 3: Answer Key Questions\n",
    "\n",
    "Using controlled within-sweep comparisons where possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92385180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "KEY QUESTIONS\n",
      "================================================================================\n",
      "\n",
      "Using 272 runs with good generalization (gap < 3)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Q1: WHAT IS THE ACTUAL SYMMETRY?\n",
      "--------------------------------------------------------------------------------\n",
      "Symmetry (Value/Honesty, baseline-relative):\n",
      "  All runs: 0.496  0.291\n",
      "  Good runs (gap<3): 0.524  0.292\n",
      "\n",
      "  Interpretation: symmetry ~0.5 means one direction gets ~2x the effect\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Q2: WHICH DIRECTION IS RESISTANT?\n",
      "--------------------------------------------------------------------------------\n",
      "'honest' = resists becoming more honest (smaller effect toward +metric)\n",
      "'dishonest' = resists becoming more dishonest (smaller effect toward -metric)\n",
      "\n",
      "Value/Honesty resistance (gap<3 runs):\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'resistant_toward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'resistant_toward'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdishonest\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m = resists becoming more dishonest (smaller effect toward -metric)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mValue/Honesty resistance (gap<3 runs):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_good\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresistant_toward\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mto_string())\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# By model\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mResistance by model:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'resistant_toward'"
     ]
    }
   ],
   "source": [
    "# Step 3: Answer key questions with controlled comparisons\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"KEY QUESTIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Filter to good runs (generalize)\n",
    "df_good = df[df['loss_gap'] < 3].copy()\n",
    "print(f\"\\nUsing {len(df_good)} runs with good generalization (gap < 3)\")\n",
    "\n",
    "# Q1: What is the actual symmetry?\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Q1: WHAT IS THE ACTUAL SYMMETRY?\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"Symmetry (Value/Honesty, baseline-relative):\")\n",
    "print(f\"  All runs: {df['symmetry'].mean():.3f}  {df['symmetry'].std():.3f}\")\n",
    "print(f\"  Good runs (gap<3): {df_good['symmetry'].mean():.3f}  {df_good['symmetry'].std():.3f}\")\n",
    "print(f\"\\n  Interpretation: symmetry ~0.5 means one direction gets ~2x the effect\")\n",
    "\n",
    "# Q2: Which direction is resistant?\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Q2: WHICH DIRECTION IS RESISTANT?\")\n",
    "print(\"-\" * 80)\n",
    "print(\"'honest' = resists becoming more honest (smaller effect toward +metric)\")\n",
    "print(\"'dishonest' = resists becoming more dishonest (smaller effect toward -metric)\")\n",
    "\n",
    "print(f\"\\nValue/Honesty resistance (gap<3 runs):\")\n",
    "print(df_good['resistant_toward'].value_counts().to_string())\n",
    "\n",
    "# By model\n",
    "print(\"\\nResistance by model:\")\n",
    "for model in df_good['model_name'].dropna().unique():\n",
    "    subset = df_good[df_good['model_name'] == model]\n",
    "    if len(subset) >= 3:\n",
    "        honest_resist = (subset['resistant_toward'] == 'honest').mean()\n",
    "        dishonest_resist = (subset['resistant_toward'] == 'dishonest').mean()\n",
    "        short_name = model.split('/')[-1][:25]\n",
    "        dominant = 'honest' if honest_resist > dishonest_resist else 'dishonest'\n",
    "        print(f\"  {short_name}: resists '{dominant}' in {100*max(honest_resist, dishonest_resist):.0f}% of runs\")\n",
    "\n",
    "# Q3: Steering effect size\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Q3: STEERING EFFECT SIZE (Value/Honesty)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Compute vh_range if not present\n",
    "if 'vh_range' not in df_good.columns:\n",
    "    df_good['vh_range'] = df_good['vh_pos'] - df_good['vh_neg']\n",
    "\n",
    "df_compare = df_good[df_good['vh_range'].notna()].copy()\n",
    "print(f\"Runs with Value/Honesty data: {len(df_compare)}\")\n",
    "\n",
    "print(f\"\\nSteering range (vh_pos - vh_neg):\")\n",
    "print(f\"  Mean: {df_compare['vh_range'].mean():.2f}  {df_compare['vh_range'].std():.2f}\")\n",
    "print(f\"  Median: {df_compare['vh_range'].median():.2f}\")\n",
    "\n",
    "print(f\"\\nEffect in each direction (from baseline vh_zero):\")\n",
    "df_compare['effect_pos'] = df_compare['vh_pos'] - df_compare['vh_zero']\n",
    "df_compare['effect_neg'] = df_compare['vh_neg'] - df_compare['vh_zero']\n",
    "print(f\"  Toward honest (pos-zero):    {df_compare['effect_pos'].mean():+.2f}  {df_compare['effect_pos'].std():.2f}\")\n",
    "print(f\"  Toward dishonest (neg-zero): {df_compare['effect_neg'].mean():+.2f}  {df_compare['effect_neg'].std():.2f}\")\n",
    "\n",
    "print(\"\\nBy model:\")\n",
    "for model in df_compare['model_name'].dropna().unique():\n",
    "    subset = df_compare[df_compare['model_name'] == model]\n",
    "    if len(subset) >= 2:\n",
    "        short_name = model.split('/')[-1][:25]\n",
    "        vh_range = subset['vh_range'].mean()\n",
    "        sym = subset['symmetry'].mean()\n",
    "        print(f\"  {short_name}: range={vh_range:+.2f}, symmetry={sym:.2f} (n={len(subset)})\")\n",
    "\n",
    "# Q4: What hyperparams affect symmetry?\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Q4: WHAT HYPERPARAMS AFFECT SYMMETRY?\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for col in ['rot_u', 'scale_s', 'loss_use_V']:\n",
    "    if col in df_good.columns and df_good[col].nunique() > 1:\n",
    "        print(f\"\\n{col}:\")\n",
    "        for val in sorted(df_good[col].dropna().unique(), key=str):\n",
    "            subset = df_good[df_good[col] == val]\n",
    "            if len(subset) >= 3:\n",
    "                sym = subset['symmetry'].mean()\n",
    "                print(f\"  {val}: symmetry={sym:.3f} (n={len(subset)})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45418dc5",
   "metadata": {},
   "source": [
    "## Overall Symmetry Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9458920b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'dose_monotonic_frac'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dose_monotonic_frac'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymmetry Distribution\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_full[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msymmetry_mean\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m axes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m----> 9\u001b[0m axes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mhist(\u001b[43mdf_full\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdose_monotonic_frac\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdropna(), bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m axes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdose_monotonic_frac\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m axes[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDose-Dependence Distribution\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMean: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf_full[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdose_monotonic_frac\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/.venv/lib/python3.10/site-packages/pandas/core/frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4113\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4115\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/media/wassname/SGIronWolf/projects5/2025/llm_moral_lb_v2/repeng/.venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3815\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3816\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3817\u001b[0m     ):\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dose_monotonic_frac'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].hist(df_full['symmetry_mean'].dropna(), bins=30, edgecolor='black')\n",
    "axes[0].axvline(1.0, color='red', linestyle='--', label='Perfect symmetry')\n",
    "axes[0].set_xlabel('symmetry_mean (|neg|/|pos|)')\n",
    "axes[0].set_title(f'Symmetry Distribution\\nMean: {df_full[\"symmetry_mean\"].mean():.3f}')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(df_full['dose_monotonic_frac'].dropna(), bins=20, edgecolor='black')\n",
    "axes[1].set_xlabel('dose_monotonic_frac')\n",
    "axes[1].set_title(f'Dose-Dependence Distribution\\nMean: {df_full[\"dose_monotonic_frac\"].mean():.3f}')\n",
    "\n",
    "axes[2].hist(df_full['loss_gap'].dropna(), bins=30, edgecolor='black')\n",
    "axes[2].axvline(3, color='red', linestyle='--', label='Gap=3 threshold')\n",
    "axes[2].set_xlabel('loss_gap (val - train)')\n",
    "axes[2].set_title(f'Generalization Gap\\nMean: {df_full[\"loss_gap\"].mean():.2f}')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSymmetry stats:\")\n",
    "print(df_full['symmetry_mean'].describe())\n",
    "print(f\"\\nRuns with good generalization (gap<3): {(df_full['loss_gap'] < 3).sum()} / {len(df_full)} ({100*(df_full['loss_gap'] < 3).mean():.0f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c705081",
   "metadata": {},
   "source": [
    "## Symmetry vs Generalization\n",
    "\n",
    "Does symmetry correlate with better generalization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d784ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_good = df_full[df_full['loss_gap'] < 3]\n",
    "df_bad = df_full[df_full['loss_gap'] >= 3]\n",
    "\n",
    "print(\"=== SYMMETRY BY GENERALIZATION QUALITY ===\\n\")\n",
    "print(f\"Good generalization (loss_gap < 3): {len(df_good)} runs\")\n",
    "print(f\"  symmetry_mean: {df_good['symmetry_mean'].mean():.3f}  {df_good['symmetry_mean'].std():.3f}\")\n",
    "print(f\"  dose_monotonic: {df_good['dose_monotonic_frac'].mean():.3f}  {df_good['dose_monotonic_frac'].std():.3f}\")\n",
    "print(f\"  main_metric: {df_good['main_metric'].mean():.1f}  {df_good['main_metric'].std():.1f}\")\n",
    "\n",
    "print(f\"\\nPoor generalization (loss_gap >= 3): {len(df_bad)} runs\")\n",
    "print(f\"  symmetry_mean: {df_bad['symmetry_mean'].mean():.3f}  {df_bad['symmetry_mean'].std():.3f}\")\n",
    "print(f\"  dose_monotonic: {df_bad['dose_monotonic_frac'].mean():.3f}  {df_bad['dose_monotonic_frac'].std():.3f}\")\n",
    "print(f\"  main_metric: {df_bad['main_metric'].mean():.1f}  {df_bad['main_metric'].std():.1f}\")\n",
    "\n",
    "print(f\"\\nCorrelations:\")\n",
    "print(f\"  symmetry_mean vs loss_gap: {df_full[['symmetry_mean', 'loss_gap']].corr().iloc[0,1]:.3f}\")\n",
    "print(f\"  dose_monotonic vs loss_gap: {df_full[['dose_monotonic_frac', 'loss_gap']].corr().iloc[0,1]:.3f}\")\n",
    "print(f\"  symmetry_mean vs main_metric: {df_full[['symmetry_mean', 'main_metric']].corr().iloc[0,1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517430a",
   "metadata": {},
   "source": [
    "## Rotation Configurations (rot_u, rot_v)\n",
    "\n",
    "Do rotations achieve better symmetry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbadb56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ROTATION CONFIGURATIONS ===\\n\")\n",
    "\n",
    "# Create rotation config label (df has the merged log metrics)\n",
    "df['rot_config'] = df.apply(\n",
    "    lambda r: f\"rot_u={r['rot_u']}, rot_v={r['rot_v']}\" if pd.notna(r.get('rot_u')) else None, axis=1\n",
    ")\n",
    "\n",
    "df_rot = (\n",
    "    df[df['rot_config'].notna()]\n",
    "    .groupby('rot_config')\n",
    "    .agg(\n",
    "        n=('rot_config', 'size'),\n",
    "        symmetry_mean=('symmetry', 'mean'),\n",
    "        symmetry_std=('symmetry', 'std'),\n",
    "        loss_gap_mean=('loss_gap', 'mean'),\n",
    "        pct_gap_lt3=('loss_gap', lambda x: 100 * (x < 3).mean()),\n",
    "        metric_mean=('main_metric', 'mean'),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .query('n > 2')\n",
    ")\n",
    "print(df_rot.to_string(index=False))\n",
    "\n",
    "if len(df_rot) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    x = range(len(df_rot))\n",
    "    axes[0].bar(x, df_rot['symmetry_mean'], yerr=df_rot['symmetry_std'], capsize=5)\n",
    "    axes[0].axhline(1.0, color='red', linestyle='--', alpha=0.5, label='Perfect symmetry')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(df_rot['rot_config'], rotation=15, ha='right')\n",
    "    axes[0].set_ylabel('symmetry_mean')\n",
    "    axes[0].set_title('Symmetry by Rotation Config')\n",
    "    axes[0].legend()\n",
    "\n",
    "    axes[1].bar(x, df_rot['loss_gap_mean'], alpha=0.7)\n",
    "    axes[1].axhline(3, color='red', linestyle='--', alpha=0.5, label='Gap=3 threshold')\n",
    "    axes[1].set_xticks(x)\n",
    "    axes[1].set_xticklabels(df_rot['rot_config'], rotation=15, ha='right')\n",
    "    axes[1].set_ylabel('loss_gap (mean)')\n",
    "    axes[1].set_title('Generalization by Rotation Config')\n",
    "    axes[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough data for rotation config analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f84db0",
   "metadata": {},
   "source": [
    "## Scale_s Configurations\n",
    "\n",
    "Does multiplicative scaling (scale_s=mult) achieve symmetry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3682e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== SCALE_S CONFIGURATIONS ===\\n\")\n",
    "\n",
    "df_scale = (\n",
    "    df[df['scale_s'].notna()]\n",
    "    .groupby('scale_s')\n",
    "    .agg(\n",
    "        n=('scale_s', 'size'),\n",
    "        symmetry_mean=('symmetry', 'mean'),\n",
    "        symmetry_std=('symmetry', 'std'),\n",
    "        loss_gap_mean=('loss_gap', 'mean'),\n",
    "        pct_gap_lt3=('loss_gap', lambda x: 100 * (x < 3).mean()),\n",
    "        metric_mean=('main_metric', 'mean'),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .query('n > 2')\n",
    "    .sort_values('n', ascending=False)\n",
    ")\n",
    "print(df_scale.to_string(index=False))\n",
    "\n",
    "if len(df_scale) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "    x = range(len(df_scale))\n",
    "    axes[0].bar(x, df_scale['symmetry_mean'], yerr=df_scale['symmetry_std'], capsize=5)\n",
    "    axes[0].axhline(1.0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(df_scale['scale_s'], rotation=0)\n",
    "    axes[0].set_ylabel('symmetry_mean')\n",
    "    axes[0].set_title('Symmetry by scale_s')\n",
    "\n",
    "    axes[1].bar(x, df_scale['loss_gap_mean'], alpha=0.7)\n",
    "    axes[1].axhline(3, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[1].set_xticks(x)\n",
    "    axes[1].set_xticklabels(df_scale['scale_s'], rotation=0)\n",
    "    axes[1].set_ylabel('loss_gap (mean)')\n",
    "    axes[1].set_title('Generalization by scale_s')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough data for scale_s analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f015c6e8",
   "metadata": {},
   "source": [
    "## Combined Analysis: rot_u + scale_s\n",
    "\n",
    "Critical test: does rot_u + scale_s=mult achieve theoretical symmetry?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f672ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ROT_U + SCALE_S COMBINATIONS ===\\n\")\n",
    "\n",
    "df_combo = (\n",
    "    df[(df['rot_u'].notna()) & (df['scale_s'].notna())]\n",
    "    .groupby(['rot_u', 'scale_s'])\n",
    "    .agg(\n",
    "        n=('rot_u', 'size'),\n",
    "        symmetry_mean=('symmetry', 'mean'),\n",
    "        symmetry_std=('symmetry', 'std'),\n",
    "        loss_gap_mean=('loss_gap', 'mean'),\n",
    "        pct_gap_lt3=('loss_gap', lambda x: 100 * (x < 3).mean()),\n",
    "        metric_mean=('main_metric', 'mean'),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .query('n > 1')\n",
    ")\n",
    "df_combo['config'] = df_combo.apply(lambda r: f\"rot_u={r['rot_u']}, {r['scale_s']}\", axis=1)\n",
    "df_combo = df_combo.sort_values(['rot_u', 'scale_s'], ascending=[False, True])\n",
    "print(df_combo[['config', 'n', 'symmetry_mean', 'loss_gap_mean', 'pct_gap_lt3', 'metric_mean']].to_string(index=False))\n",
    "\n",
    "# Highlight theoretical configs\n",
    "print(\"\\n=== THEORETICAL SYMMETRY CONFIGS ===\")\n",
    "print(\"rot_u=True + scale_s=mult should achieve perfect symmetry (alpha reversal):\")\n",
    "mult_rot = df_combo[(df_combo['rot_u'] == True) & (df_combo['scale_s'] == 'mult')]\n",
    "if len(mult_rot) > 0:\n",
    "    r = mult_rot.iloc[0]\n",
    "    print(f\"  {r['n']:.0f} runs, symmetry={r['symmetry_mean']:.3f}, gap={r['loss_gap_mean']:.2f}\")\n",
    "else:\n",
    "    print(\"  No runs found!\")\n",
    "\n",
    "print(\"\\nrot_u=False + scale_s=add2 (baseline):\")\n",
    "baseline = df_combo[(df_combo['rot_u'] == False) & (df_combo['scale_s'] == 'add2')]\n",
    "if len(baseline) > 0:\n",
    "    r = baseline.iloc[0]\n",
    "    print(f\"  {r['n']:.0f} runs, symmetry={r['symmetry_mean']:.3f}, gap={r['loss_gap_mean']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c519db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8fcff722",
   "metadata": {},
   "source": [
    "## Sweep Group Analysis\n",
    "\n",
    "Examine per-sweep patterns to control for confounds (model, hyperparams, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db38d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properly aggregate sweeps: combine all runs of same sweep type across dates\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "sweep_dir = Path('../outputs/sweep_groups')\n",
    "\n",
    "def get_sweep_base(name):\n",
    "    \"\"\"Remove timestamp: 'sweep-lr-20251123-1629' -> 'sweep-lr'\"\"\"\n",
    "    return re.sub(r'-\\d{8}-\\d{4}', '', name.replace('.csv', ''))\n",
    "\n",
    "# Load and combine all sweep CSVs by base name\n",
    "sweep_files = list(sweep_dir.glob('*.csv'))\n",
    "sweep_files = [f for f in sweep_files if '_summary' not in f.name]\n",
    "\n",
    "sweep_data = {}\n",
    "for f in sweep_files:\n",
    "    base = get_sweep_base(f.name)\n",
    "    df_sweep = pd.read_csv(f)\n",
    "    if base not in sweep_data:\n",
    "        sweep_data[base] = []\n",
    "    sweep_data[base].append(df_sweep)\n",
    "\n",
    "# Combine into single dataframes per sweep type\n",
    "sweep_combined = {}\n",
    "for base, dfs in sweep_data.items():\n",
    "    sweep_combined[base] = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "print(f\"Found {len(sweep_combined)} sweep types:\")\n",
    "for name, df in sorted(sweep_combined.items(), key=lambda x: -len(x[1])):\n",
    "    print(f\"  {name}: {len(df)} runs across {len(sweep_data[name])} dates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb6dbe6",
   "metadata": {},
   "source": [
    "## Within-Sweep Controlled Comparisons\n",
    "\n",
    "The right way to analyze sweeps: look at the **controlled variable within each sweep**, not means across different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc2aff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each sweep type, identify the controlled variable and show within-sweep comparison\n",
    "\n",
    "def analyze_sweep_controlled(df, sweep_name):\n",
    "    \"\"\"Find the variable that varies within a sweep and compare outcomes using groupby.\"\"\"\n",
    "    # Identify columns that vary (categorical or few unique values)\n",
    "    exclude = {'name', 'run_id', 'url', 'run_group', 'sweep_base', 'symmetry_mean', 'loss_gap', 'main_metric', 'dose_monotonic_frac'}\n",
    "    varying_cols = [\n",
    "        (c, df[c].nunique()) \n",
    "        for c in df.columns\n",
    "        if (df[c].dtype in ['object', 'bool'] or df[c].nunique() <= 10)\n",
    "        and df[c].nunique() > 1 \n",
    "        and c not in exclude\n",
    "    ]\n",
    "    \n",
    "    if not varying_cols:\n",
    "        return None\n",
    "        \n",
    "    # Sort by number of unique values (prefer 2-5 values)\n",
    "    varying_cols.sort(key=lambda x: abs(x[1] - 3))\n",
    "    control_var = varying_cols[0][0]\n",
    "    \n",
    "    # Aggregate using groupby\n",
    "    df_result = (\n",
    "        df.groupby(control_var, dropna=False)\n",
    "        .agg(\n",
    "            n=(control_var, 'size'),\n",
    "            symmetry=('symmetry_mean', 'mean'),\n",
    "            gap=('loss_gap', 'mean'),\n",
    "            metric=('main_metric', 'mean'),\n",
    "            gap_lt3_pct=('loss_gap', lambda x: 100 * (x < 3).mean()),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    return control_var, df_result\n",
    "\n",
    "print(\"=== WITHIN-SWEEP CONTROLLED COMPARISONS ===\\n\")\n",
    "\n",
    "for sweep_name in ['ablate-constraints', 'ablate-modules', 'sweep-lr', 'sweep-rank', 'run-models', 'sweep-rotation-angle']:\n",
    "    if sweep_name in sweep_combined:\n",
    "        df = sweep_combined[sweep_name]\n",
    "        result = analyze_sweep_controlled(df, sweep_name)\n",
    "        if result:\n",
    "            control_var, df_result = result\n",
    "            print(f\"\\n{sweep_name} (n={len(df)}, controlled: {control_var}):\")\n",
    "            print(df_result.to_string(index=False, float_format=lambda x: f'{x:.2f}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c636b624",
   "metadata": {},
   "source": [
    "## Core Claim: InnerPiSSA vs Prompting (Both Directions)\n",
    "\n",
    "Key test: Can InnerPiSSA steer AGAINST learned priors where prompting fails?\n",
    "\n",
    "We need to look at coeff=-1 (against priors) AND coeff=+1 (with priors) for both methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99600701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare InnerPiSSA vs Prompting WITHIN each run (proper controlled comparison)\n",
    "# Each run has both methods evaluated on the same model - that's the fair comparison\n",
    "\n",
    "from ipissa.config import proj_root\n",
    "import re\n",
    "\n",
    "cache_dir = proj_root / \"outputs\" / \"wandb_cache\"\n",
    "\n",
    "def extract_method_scores(log_file):\n",
    "    \"\"\"Extract Value/Honesty scores for both methods at all coefficients.\"\"\"\n",
    "    if not log_file.exists():\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        logs = log_file.read_text()\n",
    "    except:\n",
    "        return {}\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # InnerPiSSA table\n",
    "    ipissa_match = re.search(\n",
    "        r'Results for method: InnerPiSSA.*?Value/Honesty\\s+([-\\d.]+)\\s+([-\\d.]+)\\s+([-\\d.]+)', \n",
    "        logs, re.DOTALL\n",
    "    )\n",
    "    if ipissa_match:\n",
    "        results['ipissa_neg'] = float(ipissa_match.group(1))\n",
    "        results['ipissa_zero'] = float(ipissa_match.group(2))\n",
    "        results['ipissa_pos'] = float(ipissa_match.group(3))\n",
    "    \n",
    "    # Prompting table\n",
    "    prompt_match = re.search(\n",
    "        r'Results for method: prompting.*?Value/Honesty\\s+([-\\d.]+)\\s+([-\\d.]+)\\s+([-\\d.]+)', \n",
    "        logs, re.DOTALL\n",
    "    )\n",
    "    if prompt_match:\n",
    "        results['prompt_neg'] = float(prompt_match.group(1))\n",
    "        results['prompt_zero'] = float(prompt_match.group(2))\n",
    "        results['prompt_pos'] = float(prompt_match.group(3))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Extract for all runs\n",
    "print(\"Extracting per-run method comparisons...\")\n",
    "method_scores = []\n",
    "for _, row in tqdm(df_full.iterrows(), total=len(df_full)):\n",
    "    log_file = cache_dir / row['run_id'] / \"output.log\"\n",
    "    scores = extract_method_scores(log_file)\n",
    "    if scores and 'ipissa_neg' in scores and 'prompt_neg' in scores:\n",
    "        # Compute PER-RUN metrics (proper within-run comparison)\n",
    "        scores['run_id'] = row['run_id']\n",
    "        scores['model_name'] = row.get('model_name', '')\n",
    "        scores['loss_gap'] = row.get('loss_gap', np.nan)\n",
    "        \n",
    "        # Steering range = pos - neg (total effect)\n",
    "        scores['ipissa_range'] = scores['ipissa_pos'] - scores['ipissa_neg']\n",
    "        scores['prompt_range'] = scores['prompt_pos'] - scores['prompt_neg']\n",
    "        \n",
    "        # Advantage ratio per run\n",
    "        if abs(scores['prompt_range']) > 0.1:\n",
    "            scores['advantage_ratio'] = scores['ipissa_range'] / scores['prompt_range']\n",
    "        else:\n",
    "            scores['advantage_ratio'] = np.nan\n",
    "        \n",
    "        method_scores.append(scores)\n",
    "\n",
    "df_methods = pd.DataFrame(method_scores)\n",
    "print(f\"Got paired comparisons for {len(df_methods)} runs\")\n",
    "\n",
    "if len(df_methods) > 0:\n",
    "    # Filter to good runs only (generalized)\n",
    "    df_good = df_methods[df_methods['loss_gap'] < 3].copy()\n",
    "    print(f\"Of which {len(df_good)} have good generalization (gap < 3)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"WITHIN-RUN COMPARISON: InnerPiSSA vs Prompting (Value/Honesty)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Show per-run statistics\n",
    "    print(f\"\\nPer-run steering range (pos - neg):\")\n",
    "    print(f\"  InnerPiSSA: {df_good['ipissa_range'].mean():.2f}  {df_good['ipissa_range'].std():.2f}\")\n",
    "    print(f\"  Prompting:  {df_good['prompt_range'].mean():.2f}  {df_good['prompt_range'].std():.2f}\")\n",
    "    \n",
    "    # The key metric: how often does InnerPiSSA beat prompting IN THE SAME RUN?\n",
    "    df_good['ipissa_wins'] = df_good['ipissa_range'].abs() > df_good['prompt_range'].abs()\n",
    "    win_rate = df_good['ipissa_wins'].mean()\n",
    "    print(f\"\\n  InnerPiSSA has larger range in {100*win_rate:.0f}% of runs\")\n",
    "    \n",
    "    # Advantage ratio distribution\n",
    "    valid_ratios = df_good['advantage_ratio'].dropna()\n",
    "    if len(valid_ratios) > 0:\n",
    "        print(f\"\\n  Advantage ratio (InnerPiSSA/Prompting): {valid_ratios.median():.2f}x median\")\n",
    "        print(f\"    25th percentile: {valid_ratios.quantile(0.25):.2f}x\")\n",
    "        print(f\"    75th percentile: {valid_ratios.quantile(0.75):.2f}x\")\n",
    "    \n",
    "    # Break down by model\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"BY MODEL (only runs with gap < 3):\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    model_stats = []\n",
    "    for model in df_good['model_name'].dropna().unique():\n",
    "        subset = df_good[df_good['model_name'] == model]\n",
    "        if len(subset) >= 2:\n",
    "            model_stats.append({\n",
    "                'model': model[:30],\n",
    "                'n': len(subset),\n",
    "                'ipissa_range': f\"{subset['ipissa_range'].mean():.1f}\",\n",
    "                'prompt_range': f\"{subset['prompt_range'].mean():.1f}\",\n",
    "                'ipissa_wins': f\"{100*subset['ipissa_wins'].mean():.0f}%\",\n",
    "                'adv_ratio': f\"{subset['advantage_ratio'].median():.2f}x\" if subset['advantage_ratio'].notna().any() else \"N/A\",\n",
    "            })\n",
    "    \n",
    "    if model_stats:\n",
    "        df_model_stats = pd.DataFrame(model_stats).sort_values('n', ascending=False)\n",
    "        print(df_model_stats.to_string(index=False))\n",
    "    \n",
    "    # What about direction? Does prompting fail in one direction?\n",
    "    print(\"\\n\" + \"-\"*70)\n",
    "    print(\"DIRECTIONAL ANALYSIS (does prompting fail in one direction?):\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    # Effect sizes relative to baseline\n",
    "    df_good['ipissa_neg_effect'] = df_good['ipissa_neg'] - df_good['ipissa_zero']\n",
    "    df_good['ipissa_pos_effect'] = df_good['ipissa_pos'] - df_good['ipissa_zero']\n",
    "    df_good['prompt_neg_effect'] = df_good['prompt_neg'] - df_good['prompt_zero']\n",
    "    df_good['prompt_pos_effect'] = df_good['prompt_pos'] - df_good['prompt_zero']\n",
    "    \n",
    "    print(f\"\\nEffect vs baseline (mean across good runs):\")\n",
    "    print(f\"  InnerPiSSA neg effect: {df_good['ipissa_neg_effect'].mean():+.2f}\")\n",
    "    print(f\"  InnerPiSSA pos effect: {df_good['ipissa_pos_effect'].mean():+.2f}\")\n",
    "    print(f\"  Prompting neg effect:  {df_good['prompt_neg_effect'].mean():+.2f}\")\n",
    "    print(f\"  Prompting pos effect:  {df_good['prompt_pos_effect'].mean():+.2f}\")\n",
    "    \n",
    "    # Which direction does InnerPiSSA help more?\n",
    "    ipissa_neg_advantage = df_good['ipissa_neg_effect'].abs().mean() - df_good['prompt_neg_effect'].abs().mean()\n",
    "    ipissa_pos_advantage = df_good['ipissa_pos_effect'].abs().mean() - df_good['prompt_pos_effect'].abs().mean()\n",
    "    \n",
    "    print(f\"\\n  InnerPiSSA advantage in neg direction: {ipissa_neg_advantage:+.2f}\")\n",
    "    print(f\"  InnerPiSSA advantage in pos direction: {ipissa_pos_advantage:+.2f}\")\n",
    "    \n",
    "    if ipissa_neg_advantage > ipissa_pos_advantage + 0.5:\n",
    "        print(f\"   InnerPiSSA helps MORE in neg direction (against typical RLHF priors)\")\n",
    "    elif ipissa_pos_advantage > ipissa_neg_advantage + 0.5:\n",
    "        print(f\"   InnerPiSSA helps MORE in pos direction\")\n",
    "    else:\n",
    "        print(f\"   InnerPiSSA helps roughly equally in both directions\")\n",
    "\n",
    "else:\n",
    "    print(\"No paired comparison data found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f000966e",
   "metadata": {},
   "source": [
    "## 2. Systematic Hyperparameter Effects\n",
    "\n",
    "For each hyperparameter, measure its effect on symmetry, gap, and metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c5999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_hyperparam(df_in, param_name, param_values=None):\n",
    "    \"\"\"Analyze effect of a hyperparameter on symmetry, gap, and metric using groupby.\"\"\"\n",
    "    if param_name not in df_in.columns:\n",
    "        return None\n",
    "    \n",
    "    df_sub = df_in[df_in[param_name].notna()]\n",
    "    if param_values is not None:\n",
    "        df_sub = df_sub[df_sub[param_name].isin(param_values)]\n",
    "    \n",
    "    df_result = (\n",
    "        df_sub.groupby(param_name)\n",
    "        .agg(\n",
    "            n_runs=(param_name, 'size'),\n",
    "            symmetry=('symmetry', 'mean'),\n",
    "            gap=('loss_gap', 'mean'),\n",
    "            pct_gap_lt3=('loss_gap', lambda x: 100 * (x < 3).mean()),\n",
    "            metric=('main_metric', 'mean'),\n",
    "        )\n",
    "        .reset_index()\n",
    "        .query('n_runs >= 3')\n",
    "        .sort_values(param_name)\n",
    "    )\n",
    "    \n",
    "    return df_result if len(df_result) > 0 else None\n",
    "\n",
    "# Key hyperparameters to analyze\n",
    "hyperparams = [\n",
    "    ('rot_u', [False, True]),\n",
    "    ('rot_v', [False, True]),\n",
    "    ('scale_s', ['add2', 'mult', 'none']),\n",
    "    ('loss_use_V', [False, True]),\n",
    "    ('data_aware_init', [False, True]),\n",
    "    ('lr', None),\n",
    "    ('r', None),\n",
    "    ('wd', None),\n",
    "]\n",
    "\n",
    "print(\"=== HYPERPARAMETER EFFECT ANALYSIS ===\\n\")\n",
    "\n",
    "hyperparam_summaries = {}\n",
    "for param_name, param_values in hyperparams:\n",
    "    df_effect = analyze_hyperparam(df, param_name, param_values)  # Use df (merged) instead of df_full\n",
    "    if df_effect is not None and len(df_effect) > 1:\n",
    "        hyperparam_summaries[param_name] = df_effect\n",
    "        print(f\"\\n{param_name}:\")\n",
    "        print(df_effect.to_string(index=False))\n",
    "        \n",
    "        # Compute effect size (difference between max and min)\n",
    "        sym_range = df_effect['symmetry'].max() - df_effect['symmetry'].min()\n",
    "        gap_range = df_effect['gap'].max() - df_effect['gap'].min()\n",
    "        metric_range = df_effect['metric'].max() - df_effect['metric'].min()\n",
    "        print(f\"  Effect sizes: symmetry ={sym_range:.3f}, gap ={gap_range:.2f}, metric ={metric_range:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14519483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top hyperparameter effects\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "plot_params = ['rot_u', 'rot_v', 'scale_s', 'loss_use_V', 'data_aware_init']\n",
    "for idx, param in enumerate(plot_params):\n",
    "    if param in hyperparam_summaries:\n",
    "        df_p = hyperparam_summaries[param]\n",
    "        x = range(len(df_p))\n",
    "        \n",
    "        ax1 = axes[idx]\n",
    "        ax1.bar(x, df_p['symmetry'], alpha=0.7, color='steelblue', label='symmetry')\n",
    "        ax1.axhline(1.0, color='red', linestyle='--', alpha=0.3)\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(df_p[param], rotation=0 if len(df_p) <= 3 else 15)\n",
    "        ax1.set_ylabel('symmetry_mean', color='steelblue')\n",
    "        ax1.tick_params(axis='y', labelcolor='steelblue')\n",
    "        ax1.set_title(f'{param}')\n",
    "        \n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.plot(x, df_p['gap'], 'o-', color='coral', linewidth=2, markersize=8, label='gap')\n",
    "        ax2.axhline(3, color='red', linestyle='--', alpha=0.3)\n",
    "        ax2.set_ylabel('loss_gap', color='coral')\n",
    "        ax2.tick_params(axis='y', labelcolor='coral')\n",
    "\n",
    "# Remove unused subplot\n",
    "axes[-1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary of which hyperparams matter most\n",
    "print(\"\\n\\n=== HYPERPARAMETER IMPORTANCE RANKING ===\")\n",
    "print(\"(by effect on symmetry)\\n\")\n",
    "importance = []\n",
    "for param, df_p in hyperparam_summaries.items():\n",
    "    sym_effect = df_p['symmetry'].max() - df_p['symmetry'].min()\n",
    "    gap_effect = df_p['gap'].max() - df_p['gap'].min()\n",
    "    metric_effect = df_p['metric'].max() - df_p['metric'].min()\n",
    "    importance.append({\n",
    "        'hyperparam': param,\n",
    "        'symmetry_': sym_effect,\n",
    "        'gap_': gap_effect,\n",
    "        'metric_': metric_effect,\n",
    "    })\n",
    "\n",
    "df_importance = pd.DataFrame(importance).sort_values('symmetry_', ascending=False)\n",
    "print(df_importance.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d193597",
   "metadata": {},
   "source": [
    "## Base Model Investigation\n",
    "\n",
    "Test whether base models (no RLHF) show different symmetry than instruct models.\n",
    "\n",
    "If asymmetry comes from RLHF resistance, base models should be more symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be4e5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify base vs instruct models (use df which has symmetry column)\n",
    "if 'model_name' in df.columns:\n",
    "    df['is_base_model'] = df['model_name'].str.contains('Base', case=False, na=False)\n",
    "    \n",
    "    print(\"=== BASE MODEL vs INSTRUCT MODEL COMPARISON ===\\n\")\n",
    "    \n",
    "    # Groupby instead of loop\n",
    "    df_models = (\n",
    "        df\n",
    "        .assign(model_type=lambda d: d['is_base_model'].map({True: 'Base (no RLHF)', False: 'Instruct (RLHF)'}))\n",
    "        .groupby('model_type')\n",
    "        .agg(\n",
    "            n_runs=('model_type', 'size'),\n",
    "            symmetry_mean=('symmetry', 'mean'),\n",
    "            symmetry_std=('symmetry', 'std'),\n",
    "            gap_mean=('loss_gap', 'mean'),\n",
    "            pct_gap_lt3=('loss_gap', lambda x: 100 * (x < 3).mean()),\n",
    "            metric_mean=('main_metric', 'mean'),\n",
    "            metric_std=('main_metric', 'std'),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    print(df_models.to_string(index=False))\n",
    "    \n",
    "    # Test hypothesis\n",
    "    base_sym = df_models.loc[df_models['model_type'].str.contains('Base'), 'symmetry_mean'].values\n",
    "    inst_sym = df_models.loc[df_models['model_type'].str.contains('Instruct'), 'symmetry_mean'].values\n",
    "    \n",
    "    if len(base_sym) > 0 and len(inst_sym) > 0:\n",
    "        print(f\"\\n\\nHYPOTHESIS TEST:\")\n",
    "        print(f\"  Predicted: Base models  symmetry  1.0 (no RLHF resistance)\")\n",
    "        print(f\"  Observed: Base={base_sym[0]:.3f}, Instruct={inst_sym[0]:.3f}\")\n",
    "        \n",
    "        if base_sym[0] > 0.9:\n",
    "            print(f\"   HYPOTHESIS CONFIRMED: Base models show near-perfect symmetry\")\n",
    "        elif base_sym[0] > inst_sym[0] + 0.05:\n",
    "            print(f\"  ~ PARTIAL SUPPORT: Base models more symmetric, but not perfect\")\n",
    "        else:\n",
    "            print(f\"   HYPOTHESIS REJECTED: Base models also asymmetric\")\n",
    "    \n",
    "    # Detailed breakdown by model using groupby\n",
    "    print(\"\\n\\n=== BY SPECIFIC MODEL ===\")\n",
    "    df_model_details = (\n",
    "        df[df['model_name'].notna()]\n",
    "        .groupby('model_name')\n",
    "        .agg(\n",
    "            n_runs=('model_name', 'size'),\n",
    "            symmetry=('symmetry', 'mean'),\n",
    "            gap=('loss_gap', 'mean'),\n",
    "            metric=('main_metric', 'mean'),\n",
    "        )\n",
    "        .reset_index()\n",
    "        .rename(columns={'model_name': 'model'})\n",
    "        .query('n_runs >= 3')\n",
    "        .sort_values('symmetry', ascending=False)\n",
    "    )\n",
    "    print(df_model_details.to_string(index=False))\n",
    "    \n",
    "    if len(df_models) > 0 and len(df_model_details) > 0:\n",
    "        # Visualize\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        # Compare base vs instruct\n",
    "        x = range(len(df_models))\n",
    "        axes[0].bar(x, df_models['symmetry_mean'], yerr=df_models['symmetry_std'], capsize=5, alpha=0.7)\n",
    "        axes[0].axhline(1.0, color='red', linestyle='--', label='Perfect symmetry')\n",
    "        axes[0].set_xticks(x)\n",
    "        axes[0].set_xticklabels(df_models['model_type'])\n",
    "        axes[0].set_ylabel('symmetry_mean')\n",
    "        axes[0].set_title('Symmetry: Base vs Instruct Models')\n",
    "        axes[0].legend()\n",
    "        \n",
    "        # Scatter: metric vs symmetry by model\n",
    "        df_model_details['is_base'] = df_model_details['model'].str.contains('base', case=False, na=False)\n",
    "        for _, row in df_model_details.iterrows():\n",
    "            color = 'orange' if row['is_base'] else 'steelblue'\n",
    "            marker = 's' if row['is_base'] else 'o'\n",
    "            axes[1].scatter(row['symmetry'], row['metric'], s=row['n_runs']*5, \n",
    "                           color=color, marker=marker, alpha=0.7, \n",
    "                           label=row['model'] if row['n_runs'] > 5 else None)\n",
    "        \n",
    "        axes[1].axvline(1.0, color='red', linestyle='--', alpha=0.3)\n",
    "        axes[1].set_xlabel('symmetry_mean')\n",
    "        axes[1].set_ylabel('main_metric')\n",
    "        axes[1].set_title('Steering Effect vs Symmetry by Model\\n(size = n_runs, square = base)')\n",
    "        axes[1].legend(fontsize=8, loc='best')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"model_name column not found - skipping base model analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d2a3a",
   "metadata": {},
   "source": [
    "### Symmetry Metric Definitions\n",
    "\n",
    "Compare old vs corrected symmetry metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ed4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== SYMMETRY METRIC DEFINITIONS ===\\n\")\n",
    "\n",
    "print(\"OLD definition (in wandb_results.csv): symmetry_mean = min(|neg|, |pos|) / max(|neg|, |pos|)\")\n",
    "print(\"  - Measures whether absolute steering magnitudes are equal\")\n",
    "print(\"  - Does NOT account for baseline shift\")\n",
    "print(\"  - Example: neg=-2, zero=+3, pos=+8  old_sym = 2/8 = 0.25\\n\")\n",
    "\n",
    "print(\"CORRECTED definition: min(|neg-zero|, |pos-zero|) / max(|neg-zero|, |pos-zero|)\")\n",
    "print(\"  - Measures distance from baseline in each direction\")\n",
    "print(\"  - Example: neg=-2, zero=+3, pos=+8  dist_neg=5, dist_pos=5  correct_sym = 1.0\\n\")\n",
    "\n",
    "print(\"The corrected metric answers: 'Does steering move equally far in both directions?'\")\n",
    "print(\"The old metric conflated baseline shift with asymmetry.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533b04c0",
   "metadata": {},
   "source": [
    "### Critical Issue: Is Baseline Actually Zero?\n",
    "\n",
    "If the unsteered model (coeff=0) has non-zero moral scores, then measuring |neg| vs |pos| is wrong!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041a7b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"=== EXAMINING BASELINE (coeff=0) VALUES ===\\n\")\n",
    "\n",
    "# # Look at one of the actual evaluation outputs to see what baseline looks like\n",
    "# # We need to parse the logs more carefully to get the actual values\n",
    "# import re\n",
    "# from ipissa.config import proj_root\n",
    "\n",
    "# # Cache directory\n",
    "# cache_dir = proj_root / \"outputs\" / \"wandb_cache\"\n",
    "\n",
    "# # Pick a representative run and check its baseline\n",
    "# example_run_id = df_full['run_id'].iloc[0]\n",
    "# log_file = cache_dir / example_run_id / \"output.log\"\n",
    "\n",
    "# if log_file.exists():\n",
    "#     logs = log_file.read_text()\n",
    "    \n",
    "#     # Find the evaluation table\n",
    "#     table_start = logs.find(\"Results for method: InnerPiSSA\")\n",
    "#     if table_start != -1:\n",
    "#         table_end = logs.find(\"\\n\\n\", table_start)\n",
    "#         if table_end == -1:\n",
    "#             table_end = table_start + 1000\n",
    "#         table_text = logs[table_start:table_end]\n",
    "        \n",
    "#         print(\"Example evaluation table:\")\n",
    "#         print(table_text[:500])\n",
    "        \n",
    "#         # Extract coeff row to see actual values\n",
    "#         coeff_match = re.search(r'coeff\\s+([-\\d.]+)\\s+([-\\d.]+)\\s+([-\\d.]+)', table_text)\n",
    "#         if coeff_match:\n",
    "#             print(f\"\\n\\nCoeff values: {coeff_match.groups()}\")\n",
    "        \n",
    "#         # Extract a few dimension rows\n",
    "#         print(\"\\nSample moral dimension values:\")\n",
    "#         rows = re.findall(r'([\\w/]+)\\s+([-\\d.]+)\\s+([-\\d.]+)\\s+([-\\d.]+)', table_text)\n",
    "#         for dim, neg, zero, pos in rows[1:5]:  # Skip header, show first few\n",
    "#             print(f\"  {dim:20s}  neg={neg:>7s}  zero={zero:>7s}  pos={pos:>7s}\")\n",
    "            \n",
    "#             # Check if zero is actually near 0\n",
    "#             zero_val = float(zero)\n",
    "#             if abs(zero_val) > 0.5:\n",
    "#                 print(f\"      Baseline NOT zero! (|{zero_val:.2f}| > 0.5)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb85d5a",
   "metadata": {},
   "source": [
    "### Recompute Symmetry Correctly\n",
    "\n",
    "Fix the metric to account for baseline shift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f4766",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== RECOMPUTING SYMMETRY WITH BASELINE-RELATIVE DISTANCES ===\\n\")\n",
    "\n",
    "# Define cache directory\n",
    "from ipissa.config import proj_root\n",
    "import re\n",
    "cache_dir = proj_root / \"outputs\" / \"wandb_cache\"\n",
    "\n",
    "def extract_correct_symmetry_from_logs(log_file):\n",
    "    \"\"\"Parse logs and compute symmetry as distance from baseline, not absolute values.\"\"\"\n",
    "    if not log_file or not Path(log_file).exists():\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        logs = Path(log_file).read_text()\n",
    "    except:\n",
    "        return {}\n",
    "    \n",
    "    # Find evaluation table\n",
    "    table_start = logs.find(\"Results for method: InnerPiSSA\")\n",
    "    if table_start == -1:\n",
    "        return {}\n",
    "    \n",
    "    table_end = logs.find(\"\\n\\n\", table_start)\n",
    "    if table_end == -1:\n",
    "        table_end = len(logs)\n",
    "    table_text = logs[table_start:table_end]\n",
    "    \n",
    "    # Parse rows\n",
    "    rows = re.findall(r'([\\w/]+)\\s+([-\\d.]+)\\s+([-\\d.]+)\\s+([-\\d.]+)', table_text)\n",
    "    \n",
    "    if len(rows) < 2:\n",
    "        return {}\n",
    "    \n",
    "    symmetry_ratios_correct = []\n",
    "    baseline_magnitudes = []\n",
    "    \n",
    "    for dimension, neg_val, zero_val, pos_val in rows[1:]:\n",
    "        try:\n",
    "            neg, zero, pos = float(neg_val), float(zero_val), float(pos_val)\n",
    "            \n",
    "            # CORRECT: distance from baseline\n",
    "            dist_neg = abs(neg - zero)\n",
    "            dist_pos = abs(pos - zero)\n",
    "            \n",
    "            baseline_magnitudes.append(abs(zero))\n",
    "            \n",
    "            if max(dist_neg, dist_pos) > 0.01:\n",
    "                symmetry_correct = min(dist_neg, dist_pos) / max(dist_neg, dist_pos)\n",
    "                symmetry_ratios_correct.append(symmetry_correct)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to parse values for dimension {dimension}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    metrics = {}\n",
    "    if symmetry_ratios_correct:\n",
    "        metrics['symmetry_correct'] = np.mean(symmetry_ratios_correct)\n",
    "        metrics['baseline_magnitude'] = np.mean(baseline_magnitudes)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Recompute for all runs\n",
    "print(\"Recomputing symmetry metrics...\")\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "correct_symmetries = []\n",
    "for _, row in tqdm(df_full.iterrows(), total=len(df_full)):\n",
    "    run_id = row['run_id']\n",
    "    output_log = cache_dir / run_id / \"output.log\"\n",
    "    \n",
    "    metrics = extract_correct_symmetry_from_logs(output_log if output_log.exists() else None)\n",
    "    \n",
    "    correct_symmetries.append({\n",
    "        'run_id': run_id,\n",
    "        'symmetry_old': row['symmetry_mean'],\n",
    "        'symmetry_correct': metrics.get('symmetry_correct'),\n",
    "        'baseline_magnitude': metrics.get('baseline_magnitude'),\n",
    "    })\n",
    "\n",
    "df_symmetry_fix = pd.DataFrame(correct_symmetries)\n",
    "df_full_fixed = df_full.merge(df_symmetry_fix[['run_id', 'symmetry_correct', 'baseline_magnitude']], on='run_id', how='left')\n",
    "\n",
    "print(f\"\\nCompleted! {df_full_fixed['symmetry_correct'].notna().sum()} runs with corrected symmetry\")\n",
    "\n",
    "# Compare old vs new\n",
    "print(\"\\n=== OLD vs CORRECTED SYMMETRY ===\")\n",
    "comparison = df_full_fixed[df_full_fixed['symmetry_correct'].notna()][['symmetry_mean', 'symmetry_correct', 'baseline_magnitude']].describe()\n",
    "print(comparison)\n",
    "\n",
    "print(f\"\\nMean baseline magnitude: {df_full_fixed['baseline_magnitude'].mean():.3f}\")\n",
    "print(f\"Baseline often non-zero: {100 * (df_full_fixed['baseline_magnitude'] > 0.5).mean():.0f}% of runs\")\n",
    "\n",
    "print(\"\\n=== CORRECTED SYMMETRY BY MODEL TYPE ===\")\n",
    "for is_base in [True, False]:\n",
    "    subset = df_full_fixed[df_full_fixed['is_base_model'] == is_base]\n",
    "    if len(subset) > 0:\n",
    "        model_type = 'Base (no RLHF)' if is_base else 'Instruct (RLHF)'\n",
    "        print(f\"\\n{model_type}:\")\n",
    "        print(f\"  Old symmetry: {subset['symmetry_mean'].mean():.3f}\")\n",
    "        print(f\"  Corrected symmetry: {subset['symmetry_correct'].mean():.3f}\")\n",
    "        print(f\"  Baseline magnitude: {subset['baseline_magnitude'].mean():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a96bd8",
   "metadata": {},
   "source": [
    "## 4. Weird Runs Investigation\n",
    "\n",
    "Find outliers and anomalies to understand edge cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca9bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== OUTLIER ANALYSIS ===\\n\")\n",
    "\n",
    "# 1. Unusually high symmetry (closest to 1.0)\n",
    "print(\"TOP 10 MOST SYMMETRIC RUNS:\")\n",
    "df_symmetric = df_full.nlargest(10, 'symmetry_mean')[['name', 'symmetry_mean', 'loss_gap', 'main_metric', 'model_name', 'rot_u', 'scale_s', 'url']]\n",
    "print(df_symmetric.to_string(index=False))\n",
    "\n",
    "# 2. Unusually low symmetry\n",
    "print(\"\\n\\nTOP 10 LEAST SYMMETRIC RUNS:\")\n",
    "df_asymmetric = df_full.nsmallest(10, 'symmetry_mean')[['name', 'symmetry_mean', 'loss_gap', 'main_metric', 'model_name', 'rot_u', 'scale_s', 'url']]\n",
    "print(df_asymmetric.to_string(index=False))\n",
    "\n",
    "# 3. Perfect dose-dependence\n",
    "print(\"\\n\\nPERFECT DOSE-DEPENDENCE (all dimensions monotonic):\")\n",
    "df_perfect_dose = df_full[df_full['dose_monotonic_frac'] > 0.8].sort_values('dose_monotonic_frac', ascending=False).head(10)\n",
    "print(df_perfect_dose[['name', 'dose_monotonic_frac', 'symmetry_mean', 'loss_gap', 'main_metric', 'url']].to_string(index=False))\n",
    "\n",
    "# 4. Catastrophic overfitting (gap > 10)\n",
    "print(\"\\n\\nCATASTROPHIC OVERFITTING (gap > 10):\")\n",
    "df_overfit = df_full[df_full['loss_gap'] > 10].sort_values('loss_gap', ascending=False).head(10)\n",
    "if len(df_overfit) > 0:\n",
    "    print(df_overfit[['name', 'loss_gap', 'symmetry_mean', 'main_metric', 'rot_u', 'scale_s', 'lr', 'url']].to_string(index=False))\n",
    "else:\n",
    "    print(\"  No runs with gap > 10\")\n",
    "\n",
    "# 5. Very high steering but poor generalization\n",
    "print(\"\\n\\nHIGH STEERING + POOR GENERALIZATION (metric > 500, gap > 5):\")\n",
    "df_weird = df_full[(df_full['main_metric'] > 500) & (df_full['loss_gap'] > 5)].sort_values('main_metric', ascending=False)\n",
    "if len(df_weird) > 0:\n",
    "    print(df_weird[['name', 'main_metric', 'loss_gap', 'symmetry_mean', 'rot_u', 'scale_s', 'url']].to_string(index=False))\n",
    "else:\n",
    "    print(\"  No such runs\")\n",
    "\n",
    "# 6. Anomaly: Good generalization + high steering (the sweet spot)\n",
    "print(\"\\n\\nSWEET SPOT (metric > 400, gap < 2):\")\n",
    "df_sweet = df_full[(df_full['main_metric'] > 400) & (df_full['loss_gap'] < 2)].sort_values('main_metric', ascending=False)\n",
    "if len(df_sweet) > 0:\n",
    "    print(df_sweet[['name', 'main_metric', 'loss_gap', 'symmetry_mean', 'model_name', 'loss_use_V', 'data_aware_init', 'url']].to_string(index=False))\n",
    "    \n",
    "    # What makes these special?\n",
    "    print(f\"\\n  Common patterns in sweet spot runs:\")\n",
    "    for col in ['loss_use_V', 'data_aware_init', 'rot_u', 'scale_s']:\n",
    "        if col in df_sweet.columns:\n",
    "            mode_val = df_sweet[col].mode()\n",
    "            if len(mode_val) > 0:\n",
    "                pct = 100 * (df_sweet[col] == mode_val.iloc[0]).mean()\n",
    "                print(f\"    {col}={mode_val.iloc[0]}: {pct:.0f}% of sweet spot runs\")\n",
    "else:\n",
    "    print(\"  No such runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5d8bec",
   "metadata": {},
   "source": [
    "## Summary of Key Findings\n",
    "\n",
    "Actionable insights from all analyses above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dedaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug: show a few actual examples to verify parsing\n",
    "print(\"Sample parsed values vs prompting baseline:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "sample = df_good.head(10)\n",
    "for _, row in sample.iterrows():\n",
    "    print(f\"Run: {row['run_id'][:8]}... Model: {str(row['model_name'])[:25]}\")\n",
    "    print(f\"  InnerPiSSA: neg={row['ipissa_neg']:.1f}, zero={row['ipissa_zero']:.1f}, pos={row['ipissa_pos']:.1f} -> range={row['ipissa_range']:.1f}\")\n",
    "    print(f\"  Prompting:  neg={row['prompt_neg']:.1f}, zero={row['prompt_zero']:.1f}, pos={row['prompt_pos']:.1f} -> range={row['prompt_range']:.1f}\")\n",
    "    print(f\"  Winner: {'InnerPiSSA' if abs(row['ipissa_range']) > abs(row['prompt_range']) else 'Prompting'}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea6745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"KEY FINDINGS FROM SYMMETRY ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Symmetry metrics\n",
    "sym_mean = df_full['symmetry_mean'].mean()\n",
    "dose_mean = df_full['dose_monotonic_frac'].mean()\n",
    "max_sym = df_full['symmetry_mean'].max()\n",
    "print(\"\\n1. SYMMETRY METRICS:\")\n",
    "print(f\"   - Mean symmetry across all runs: {sym_mean:.3f}\")\n",
    "print(f\"   - Max symmetry achieved: {max_sym:.3f}\")\n",
    "print(f\"   - Dose-dependence: {dose_mean:.1%} of dimensions monotonic\")\n",
    "\n",
    "# 2. Generalization\n",
    "gap_pct = 100*(df_full['loss_gap'] < 3).mean()\n",
    "sym_gap_corr = df_full[['symmetry_mean', 'loss_gap']].corr().iloc[0,1]\n",
    "print(\"\\n2. GENERALIZATION:\")\n",
    "print(f\"   - {gap_pct:.0f}% of runs generalize well (gap < 3)\")\n",
    "print(f\"   - Symmetry vs generalization correlation: r={sym_gap_corr:.3f}\")\n",
    "\n",
    "# 3. Core claim: InnerPiSSA vs prompting (MODEL-SPECIFIC)\n",
    "if 'df_good' in dir() and len(df_good) > 0:\n",
    "    print(\"\\n3. CORE CLAIM (InnerPiSSA vs Prompting) - BY MODEL:\")\n",
    "    print(\"   (Only runs with gap < 3, comparing within-run)\")\n",
    "    \n",
    "    for model in df_good['model_name'].dropna().unique():\n",
    "        subset = df_good[df_good['model_name'] == model]\n",
    "        if len(subset) >= 2:\n",
    "            ipissa_mean = subset['ipissa_range'].mean()\n",
    "            prompt_mean = subset['prompt_range'].mean()\n",
    "            win_rate = subset['ipissa_wins'].mean()\n",
    "            \n",
    "            short_name = model.split('/')[-1][:25]\n",
    "            winner = \"InnerPiSSA\" if win_rate > 0.5 else \"Prompting\"\n",
    "            print(f\"   - {short_name}: InnerPiSSA wins {100*win_rate:.0f}% (range {ipissa_mean:.1f} vs {prompt_mean:.1f})\")\n",
    "\n",
    "# 4. Hyperparameter effects\n",
    "print(\"\\n4. HYPERPARAMETER EFFECTS ON SYMMETRY:\")\n",
    "for col, vals in [('rot_u', [False, True]), ('scale_s', ['add2', 'mult']), ('loss_use_V', [False, True])]:\n",
    "    if col in df_full.columns:\n",
    "        effects = []\n",
    "        for v in vals:\n",
    "            subset = df_full[df_full[col] == v]\n",
    "            if len(subset) >= 3:\n",
    "                effects.append((v, subset['symmetry_mean'].mean(), len(subset)))\n",
    "        if len(effects) >= 2:\n",
    "            delta = abs(effects[1][1] - effects[0][1])\n",
    "            print(f\"   - {col}: {effects[0][0]}={effects[0][1]:.3f} (n={effects[0][2]}) vs {effects[1][0]}={effects[1][1]:.3f} (n={effects[1][2]}), ={delta:.3f}\")\n",
    "\n",
    "# 5. Model comparison\n",
    "if 'is_base_model' in df_full.columns:\n",
    "    base_runs = df_full[df_full['is_base_model'] == True]\n",
    "    inst_runs = df_full[df_full['is_base_model'] == False]\n",
    "    if len(base_runs) >= 3 and len(inst_runs) >= 3:\n",
    "        base_sym = base_runs['symmetry_mean'].mean()\n",
    "        inst_sym = inst_runs['symmetry_mean'].mean()\n",
    "        print(\"\\n5. BASE vs INSTRUCT MODELS:\")\n",
    "        print(f\"   - Base models: symmetry = {base_sym:.3f} (n={len(base_runs)})\")\n",
    "        print(f\"   - Instruct models: symmetry = {inst_sym:.3f} (n={len(inst_runs)})\")\n",
    "\n",
    "# 6. Data-driven conclusions\n",
    "print(\"\\n6. DATA-DRIVEN CONCLUSIONS:\")\n",
    "if sym_mean < 0.7:\n",
    "    print(f\"   - Steering is asymmetric (mean={sym_mean:.2f})\")\n",
    "if abs(sym_gap_corr) < 0.2:\n",
    "    print(f\"   - Symmetry does NOT predict generalization (r={sym_gap_corr:.2f})\")\n",
    "\n",
    "# Key finding from model comparison\n",
    "if 'df_good' in dir() and len(df_good) > 0:\n",
    "    # Find models where InnerPiSSA wins\n",
    "    winners = []\n",
    "    for model in df_good['model_name'].dropna().unique():\n",
    "        subset = df_good[df_good['model_name'] == model]\n",
    "        if len(subset) >= 2 and subset['ipissa_wins'].mean() > 0.5:\n",
    "            winners.append(model.split('/')[-1][:20])\n",
    "    \n",
    "    if winners:\n",
    "        print(f\"   - InnerPiSSA beats prompting on: {', '.join(winners)}\")\n",
    "    \n",
    "    # Find where prompting wins\n",
    "    losers = []\n",
    "    for model in df_good['model_name'].dropna().unique():\n",
    "        subset = df_good[df_good['model_name'] == model]\n",
    "        if len(subset) >= 2 and subset['ipissa_wins'].mean() <= 0.5:\n",
    "            losers.append(model.split('/')[-1][:20])\n",
    "    \n",
    "    if losers:\n",
    "        print(f\"   - Prompting beats InnerPiSSA on: {', '.join(losers)}\")\n",
    "    \n",
    "    print(f\"   - Implication: InnerPiSSA helps where prompting fails (Llama, base, small models)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8196142e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repeng (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

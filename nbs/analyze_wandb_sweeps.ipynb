{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8a129dc",
   "metadata": {},
   "source": [
    "# InnerPiSSA  Analyse sweeps and ablations\n",
    "## Analysis Principles\n",
    "\n",
    "**Main metric**: `ipissa_vh_range` = T_test / nll_degradation\n",
    "- T_test = slope of logprob vs coefficient (steering effect)\n",
    "- nll_degradation = coherence loss (model quality preservation)\n",
    "- This is the primary metric for comparing methods\n",
    "\n",
    "**Auxiliary metrics**:\n",
    "- `symmetry`: min(|neg-zero|, |pos-zero|) / max(...) - how symmetric is bidirectional steering\n",
    "- `loss_gap`: val_loss - train_loss - overfitting indicator\n",
    "\n",
    "**Comparison principles**:\n",
    "1. **Best vs mean baseline**: Use mean of baseline runs (not best) - best is sensitive to n_runs\n",
    "2. **Within-sweep comparisons**: Control for model/hyperparams when analyzing sweep variables\n",
    "3. **Exclude intentionally-broken runs**: lr=1.0, lr=1e-6 are ablation failures, not fair comparisons\n",
    "4. **Resistance by metric sign**: \"honest\" vs \"dishonest\" direction, not arbitrary coefficient sign\n",
    "\n",
    "**Color conventions**:\n",
    "- Red = toward honest (positive ipissa_range)\n",
    "- Blue = toward dishonest (negative ipissa_range)\n",
    "- Green = low gap (good coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cd0ed544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "from ipissa.config import proj_root\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce6cec7",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4ac6abbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs: 736\n",
      "Runs with prompting baseline: 555\n",
      "\n",
      "Baseline scores by model:\n",
      "  wassname/qwen-14B-codefourchan: prompting=339.7, repeng=171.5\n",
      "  unsloth/Llama-3.1-8B-Instruct: prompting=207.7, repeng=996.0\n",
      "  google/gemma-3-4b-it: prompting=277.2, repeng=1.9\n",
      "  google/gemma-3-270m-it: prompting=117.9, repeng=nan\n",
      "  google/gemma-3-1b-it: prompting=87.2, repeng=nan\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>created_at</th>\n",
       "      <th>url</th>\n",
       "      <th>log_file</th>\n",
       "      <th>args</th>\n",
       "      <th>run_group</th>\n",
       "      <th>git_commit</th>\n",
       "      <th>gpu</th>\n",
       "      <th>layer_num</th>\n",
       "      <th>main_metric</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vh_neg</th>\n",
       "      <th>vh_zero</th>\n",
       "      <th>vh_pos</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>resistant_toward</th>\n",
       "      <th>baseline_effect_InnerPiSSA</th>\n",
       "      <th>baseline_effect_s_steer</th>\n",
       "      <th>baseline_effect_pca</th>\n",
       "      <th>baseline_effect_prompting</th>\n",
       "      <th>baseline_effect_repeng</th>\n",
       "      <th>val_loss_total</th>\n",
       "      <th>val_loss_proj</th>\n",
       "      <th>val_loss_coh</th>\n",
       "      <th>val_loss_monotonic</th>\n",
       "      <th>val_proj_diff</th>\n",
       "      <th>val_logp_degradation</th>\n",
       "      <th>train_loss_total</th>\n",
       "      <th>train_loss_proj</th>\n",
       "      <th>train_loss_coh</th>\n",
       "      <th>train_loss_monotonic</th>\n",
       "      <th>train_proj_diff</th>\n",
       "      <th>train_logp_degradation</th>\n",
       "      <th>_runtime</th>\n",
       "      <th>_step</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>_wandb</th>\n",
       "      <th>coh_deg</th>\n",
       "      <th>cw</th>\n",
       "      <th>delta_logp_change</th>\n",
       "      <th>eval/baseline_InnerPiSSA (ours)</th>\n",
       "      <th>eval/baseline_prompting</th>\n",
       "      <th>eval/baseline_repeng</th>\n",
       "      <th>eval/coherence_metrics</th>\n",
       "      <th>eval/effect_sizes_CI95</th>\n",
       "      <th>eval/effect_sizes_Pearson</th>\n",
       "      <th>eval/effect_sizes_Slope</th>\n",
       "      <th>eval/effect_sizes_Slope*(1-p)</th>\n",
       "      <th>eval/effect_sizes_Spearman</th>\n",
       "      <th>eval/effect_sizes_T-stat</th>\n",
       "      <th>eval/main_metric</th>\n",
       "      <th>eval/transfer_summary</th>\n",
       "      <th>eval/value_scores</th>\n",
       "      <th>flip_ema</th>\n",
       "      <th>loss_coh</th>\n",
       "      <th>loss_monotonic</th>\n",
       "      <th>loss_proj</th>\n",
       "      <th>loss_proj_flipped</th>\n",
       "      <th>loss_total</th>\n",
       "      <th>lr</th>\n",
       "      <th>module</th>\n",
       "      <th>mono_direction</th>\n",
       "      <th>mono_ema</th>\n",
       "      <th>mono_frac_violated</th>\n",
       "      <th>mono_violation</th>\n",
       "      <th>prob_ratio</th>\n",
       "      <th>proj_diff</th>\n",
       "      <th>proj_pi</th>\n",
       "      <th>proj_ref</th>\n",
       "      <th>separation_norm</th>\n",
       "      <th>train/by_coef/coh_deg_coef+1_0</th>\n",
       "      <th>train/by_coef/coh_deg_coef-1_0</th>\n",
       "      <th>train/by_coef/cw_coef+1_0</th>\n",
       "      <th>train/by_coef/cw_coef-1_0</th>\n",
       "      <th>train/by_coef/delta_logp_change_coef+1_0</th>\n",
       "      <th>train/by_coef/delta_logp_change_coef-1_0</th>\n",
       "      <th>train/by_coef/flip_ema_coef+1_0</th>\n",
       "      <th>train/by_coef/flip_ema_coef-1_0</th>\n",
       "      <th>train/by_coef/loss_coh_coef+1_0</th>\n",
       "      <th>train/by_coef/loss_coh_coef-1_0</th>\n",
       "      <th>train/by_coef/loss_monotonic_coef+1_0</th>\n",
       "      <th>train/by_coef/loss_monotonic_coef-1_0</th>\n",
       "      <th>train/by_coef/loss_proj_coef+1_0</th>\n",
       "      <th>train/by_coef/loss_proj_coef-1_0</th>\n",
       "      <th>train/by_coef/loss_proj_flipped_coef+1_0</th>\n",
       "      <th>train/by_coef/loss_proj_flipped_coef-1_0</th>\n",
       "      <th>train/by_coef/loss_total_coef+1_0</th>\n",
       "      <th>train/by_coef/loss_total_coef-1_0</th>\n",
       "      <th>train/by_coef/lr_coef+1_0</th>\n",
       "      <th>train/by_coef/lr_coef-1_0</th>\n",
       "      <th>train/by_coef/mono_direction_coef+1_0</th>\n",
       "      <th>train/by_coef/mono_direction_coef-1_0</th>\n",
       "      <th>train/by_coef/mono_ema_coef+1_0</th>\n",
       "      <th>train/by_coef/mono_ema_coef-1_0</th>\n",
       "      <th>train/by_coef/mono_frac_violated_coef+1_0</th>\n",
       "      <th>train/by_coef/mono_frac_violated_coef-1_0</th>\n",
       "      <th>train/by_coef/mono_violation_coef+1_0</th>\n",
       "      <th>train/by_coef/mono_violation_coef-1_0</th>\n",
       "      <th>train/by_coef/prob_ratio_coef+1_0</th>\n",
       "      <th>train/by_coef/prob_ratio_coef-1_0</th>\n",
       "      <th>train/by_coef/proj_diff_coef+1_0</th>\n",
       "      <th>train/by_coef/proj_diff_coef-1_0</th>\n",
       "      <th>train/by_coef/proj_pi_coef+1_0</th>\n",
       "      <th>train/by_coef/proj_pi_coef-1_0</th>\n",
       "      <th>train/by_coef/proj_ref_coef+1_0</th>\n",
       "      <th>train/by_coef/proj_ref_coef-1_0</th>\n",
       "      <th>train/by_coef/separation_norm_coef+1_0</th>\n",
       "      <th>train/by_coef/separation_norm_coef-1_0</th>\n",
       "      <th>val/by_coef/coh_deg_coef+1_0</th>\n",
       "      <th>val/by_coef/coh_deg_coef-1_0</th>\n",
       "      <th>val/by_coef/cw_coef+1_0</th>\n",
       "      <th>val/by_coef/cw_coef-1_0</th>\n",
       "      <th>val/by_coef/delta_logp_change_coef+1_0</th>\n",
       "      <th>val/by_coef/delta_logp_change_coef-1_0</th>\n",
       "      <th>val/by_coef/loss_coh_coef+1_0</th>\n",
       "      <th>val/by_coef/loss_coh_coef-1_0</th>\n",
       "      <th>val/by_coef/loss_monotonic_coef+1_0</th>\n",
       "      <th>val/by_coef/loss_monotonic_coef-1_0</th>\n",
       "      <th>val/by_coef/loss_proj_coef+1_0</th>\n",
       "      <th>val/by_coef/loss_proj_coef-1_0</th>\n",
       "      <th>val/by_coef/loss_proj_flipped_coef+1_0</th>\n",
       "      <th>val/by_coef/loss_proj_flipped_coef-1_0</th>\n",
       "      <th>val/by_coef/loss_total_coef+1_0</th>\n",
       "      <th>val/by_coef/loss_total_coef-1_0</th>\n",
       "      <th>val/by_coef/mono_direction_coef+1_0</th>\n",
       "      <th>val/by_coef/mono_direction_coef-1_0</th>\n",
       "      <th>val/by_coef/mono_frac_violated_coef+1_0</th>\n",
       "      <th>val/by_coef/mono_frac_violated_coef-1_0</th>\n",
       "      <th>val/by_coef/mono_violation_coef+1_0</th>\n",
       "      <th>val/by_coef/mono_violation_coef-1_0</th>\n",
       "      <th>val/by_coef/prob_ratio_coef+1_0</th>\n",
       "      <th>val/by_coef/prob_ratio_coef-1_0</th>\n",
       "      <th>val/by_coef/proj_diff_coef+1_0</th>\n",
       "      <th>val/by_coef/proj_diff_coef-1_0</th>\n",
       "      <th>val/by_coef/proj_pi_coef+1_0</th>\n",
       "      <th>val/by_coef/proj_pi_coef-1_0</th>\n",
       "      <th>val/by_coef/proj_ref_coef+1_0</th>\n",
       "      <th>val/by_coef/proj_ref_coef-1_0</th>\n",
       "      <th>val/by_coef/separation_norm_coef+1_0</th>\n",
       "      <th>val/by_coef/separation_norm_coef-1_0</th>\n",
       "      <th>val/coh_deg</th>\n",
       "      <th>val/cw</th>\n",
       "      <th>val/delta_logp_change</th>\n",
       "      <th>val/loss_coh</th>\n",
       "      <th>val/loss_monotonic</th>\n",
       "      <th>val/loss_proj</th>\n",
       "      <th>val/loss_proj_flipped</th>\n",
       "      <th>val/loss_total</th>\n",
       "      <th>val/mono_direction</th>\n",
       "      <th>val/mono_frac_violated</th>\n",
       "      <th>val/mono_violation</th>\n",
       "      <th>val/prob_ratio</th>\n",
       "      <th>val/proj_diff</th>\n",
       "      <th>val/proj_pi</th>\n",
       "      <th>val/proj_ref</th>\n",
       "      <th>val/separation_norm</th>\n",
       "      <th>r</th>\n",
       "      <th>bs</th>\n",
       "      <th>wd</th>\n",
       "      <th>coh</th>\n",
       "      <th>mono</th>\n",
       "      <th>quick</th>\n",
       "      <th>rot_u</th>\n",
       "      <th>rot_v</th>\n",
       "      <th>PROMPT</th>\n",
       "      <th>n_logs</th>\n",
       "      <th>modules</th>\n",
       "      <th>scale_s</th>\n",
       "      <th>verbose</th>\n",
       "      <th>PERSONAS</th>\n",
       "      <th>coh_temp</th>\n",
       "      <th>n_depths</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>depth_end</th>\n",
       "      <th>loss_type</th>\n",
       "      <th>use_wandb</th>\n",
       "      <th>val_split</th>\n",
       "      <th>coh_thresh</th>\n",
       "      <th>coh_weight</th>\n",
       "      <th>loss_use_V</th>\n",
       "      <th>model_name</th>\n",
       "      <th>output_dir</th>\n",
       "      <th>wandb_tags</th>\n",
       "      <th>depth_start</th>\n",
       "      <th>loss_depths</th>\n",
       "      <th>max_samples</th>\n",
       "      <th>mono_margin</th>\n",
       "      <th>mono_weight</th>\n",
       "      <th>adapter_type</th>\n",
       "      <th>coh_adaptive</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>effective_bs</th>\n",
       "      <th>loss_modules</th>\n",
       "      <th>n_last_tokens</th>\n",
       "      <th>wandb_project</th>\n",
       "      <th>data_aware_init</th>\n",
       "      <th>eval_max_tokens</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>save_checkpoints</th>\n",
       "      <th>eval_max_dilemmas</th>\n",
       "      <th>quantization_type</th>\n",
       "      <th>max_rotation_angle</th>\n",
       "      <th>early_stop_patience</th>\n",
       "      <th>loss_snorm</th>\n",
       "      <th>pref_dir_k</th>\n",
       "      <th>pref_dir_method</th>\n",
       "      <th>val_every_n_samples</th>\n",
       "      <th>eval/baseline_S-space steer</th>\n",
       "      <th>eval/baseline_pca (wassname)</th>\n",
       "      <th>s_selection_mode</th>\n",
       "      <th>loss_gap</th>\n",
       "      <th>prompting_score</th>\n",
       "      <th>repeng_score</th>\n",
       "      <th>gain_vs_prompting</th>\n",
       "      <th>gain_vs_repeng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qwtkm93m</td>\n",
       "      <td>q14b-c4c-raw-r128</td>\n",
       "      <td>finished</td>\n",
       "      <td>2025-11-27T08:17:03Z</td>\n",
       "      <td>https://wandb.ai/wassname/InnerPiSSA/runs/qwtk...</td>\n",
       "      <td>/media/wassname/SGIronWolf/projects5/2025/llm_...</td>\n",
       "      <td>q14b-80gb --model_name=wassname/qwen-14B-codef...</td>\n",
       "      <td>ablation-20251127-0813</td>\n",
       "      <td>7ec1d8d80bec4b43396bde3b546e2a5b4f508d33</td>\n",
       "      <td>NVIDIA A100-SXM4-80GB</td>\n",
       "      <td>36</td>\n",
       "      <td>419.813115</td>\n",
       "      <td>1483</td>\n",
       "      <td>-0.8108</td>\n",
       "      <td>-0.6733</td>\n",
       "      <td>-0.4864</td>\n",
       "      <td>0.735688</td>\n",
       "      <td>dishonest</td>\n",
       "      <td>-0.673339</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>-0.390598</td>\n",
       "      <td>-0.680650</td>\n",
       "      <td>-11.302973</td>\n",
       "      <td>-6.914284</td>\n",
       "      <td>0.285055</td>\n",
       "      <td>1.955485</td>\n",
       "      <td>-6.914284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.359199</td>\n",
       "      <td>-6.679599</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.679599</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1483</td>\n",
       "      <td>708</td>\n",
       "      <td>1.764233e+09</td>\n",
       "      <td>{'runtime': 1483}</td>\n",
       "      <td>-0.024508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.018907</td>\n",
       "      <td>-0.673339</td>\n",
       "      <td>-0.390598</td>\n",
       "      <td>-0.680650</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>419.813115</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>13.922856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.679599</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.359199</td>\n",
       "      <td>0.004</td>\n",
       "      <td>base_model.model.model.layers.36.mlp.up_proj</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975806</td>\n",
       "      <td>-6.679599</td>\n",
       "      <td>-51.683073</td>\n",
       "      <td>18.932087</td>\n",
       "      <td>115.063175</td>\n",
       "      <td>-0.018746</td>\n",
       "      <td>-0.030271</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.265730</td>\n",
       "      <td>0.227916</td>\n",
       "      <td>13.922856</td>\n",
       "      <td>13.922856</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.429043</td>\n",
       "      <td>-6.930156</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.359199</td>\n",
       "      <td>-13.359199</td>\n",
       "      <td>1.804220e-07</td>\n",
       "      <td>1.804220e-07</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>0.970183</td>\n",
       "      <td>-6.429043</td>\n",
       "      <td>-6.930156</td>\n",
       "      <td>-38.252064</td>\n",
       "      <td>-65.114082</td>\n",
       "      <td>18.932087</td>\n",
       "      <td>18.932087</td>\n",
       "      <td>127.344666</td>\n",
       "      <td>102.781685</td>\n",
       "      <td>-0.009998</td>\n",
       "      <td>-0.051022</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.262232</td>\n",
       "      <td>0.180793</td>\n",
       "      <td>0.213706</td>\n",
       "      <td>0.356404</td>\n",
       "      <td>1.955485</td>\n",
       "      <td>1.955485</td>\n",
       "      <td>-6.649959</td>\n",
       "      <td>-7.178610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-11.302973</td>\n",
       "      <td>-11.302973</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.010042</td>\n",
       "      <td>0.009513</td>\n",
       "      <td>0.990951</td>\n",
       "      <td>0.951747</td>\n",
       "      <td>-6.649959</td>\n",
       "      <td>-7.178610</td>\n",
       "      <td>-38.645227</td>\n",
       "      <td>-66.330235</td>\n",
       "      <td>22.946876</td>\n",
       "      <td>22.946876</td>\n",
       "      <td>118.654505</td>\n",
       "      <td>97.633345</td>\n",
       "      <td>-0.030510</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.040720</td>\n",
       "      <td>0.285055</td>\n",
       "      <td>1.955485</td>\n",
       "      <td>-6.914284</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-11.302973</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009777</td>\n",
       "      <td>0.971349</td>\n",
       "      <td>-6.914284</td>\n",
       "      <td>-52.487731</td>\n",
       "      <td>22.946876</td>\n",
       "      <td>108.143925</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Pretend you're an {persona} person making stat...</td>\n",
       "      <td>20</td>\n",
       "      <td>['o_proj', 'down_proj']</td>\n",
       "      <td>add2</td>\n",
       "      <td>1</td>\n",
       "      <td>[['an honest'], ['a dishonest']]</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>-3</td>\n",
       "      <td>raw</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>True</td>\n",
       "      <td>wassname/qwen-14B-codefourchan</td>\n",
       "      <td>/workspace/InnerPiSSA_private/outputs/adapters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[0.75]</td>\n",
       "      <td>800</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>innerpissa</td>\n",
       "      <td>False</td>\n",
       "      <td>honest</td>\n",
       "      <td>32</td>\n",
       "      <td>['up_proj']</td>\n",
       "      <td>8</td>\n",
       "      <td>InnerPiSSA</td>\n",
       "      <td>True</td>\n",
       "      <td>288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.056226</td>\n",
       "      <td>339.738163</td>\n",
       "      <td>171.546768</td>\n",
       "      <td>23.569608</td>\n",
       "      <td>144.722253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4c1jbdpe</td>\n",
       "      <td>q14b-c4c-raw-r128</td>\n",
       "      <td>finished</td>\n",
       "      <td>2025-11-27T01:43:26Z</td>\n",
       "      <td>https://wandb.ai/wassname/InnerPiSSA/runs/4c1j...</td>\n",
       "      <td>/media/wassname/SGIronWolf/projects5/2025/llm_...</td>\n",
       "      <td>q14b-80gb --model_name=wassname/qwen-14B-codef...</td>\n",
       "      <td>run-models-20251127-0143</td>\n",
       "      <td>7ec1d8d80bec4b43396bde3b546e2a5b4f508d33</td>\n",
       "      <td>NVIDIA A100-SXM4-80GB</td>\n",
       "      <td>36</td>\n",
       "      <td>599.477174</td>\n",
       "      <td>1473</td>\n",
       "      <td>-0.8743</td>\n",
       "      <td>-0.6733</td>\n",
       "      <td>-0.4125</td>\n",
       "      <td>0.770706</td>\n",
       "      <td>dishonest</td>\n",
       "      <td>-0.673339</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>-0.390598</td>\n",
       "      <td>-0.680650</td>\n",
       "      <td>-10.793957</td>\n",
       "      <td>-6.933430</td>\n",
       "      <td>0.304454</td>\n",
       "      <td>2.463995</td>\n",
       "      <td>-6.933430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-13.343777</td>\n",
       "      <td>-6.721316</td>\n",
       "      <td>0.049427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.721316</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1473</td>\n",
       "      <td>708</td>\n",
       "      <td>1.764209e+09</td>\n",
       "      <td>{'runtime': 1473}</td>\n",
       "      <td>-0.021908</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.030372</td>\n",
       "      <td>-0.673339</td>\n",
       "      <td>-0.390598</td>\n",
       "      <td>-0.680650</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>599.477174</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>13.982160</td>\n",
       "      <td>0.049427</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.721316</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.343777</td>\n",
       "      <td>0.004</td>\n",
       "      <td>base_model.model.model.layers.36.mlp.up_proj</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.978334</td>\n",
       "      <td>-6.721316</td>\n",
       "      <td>-53.256214</td>\n",
       "      <td>18.932087</td>\n",
       "      <td>113.221088</td>\n",
       "      <td>-0.019070</td>\n",
       "      <td>-0.024746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.278593</td>\n",
       "      <td>0.217849</td>\n",
       "      <td>13.982160</td>\n",
       "      <td>13.982160</td>\n",
       "      <td>0.098854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6.511371</td>\n",
       "      <td>-6.931261</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-13.343777</td>\n",
       "      <td>-13.343777</td>\n",
       "      <td>1.804220e-07</td>\n",
       "      <td>1.804220e-07</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.981111</td>\n",
       "      <td>0.975558</td>\n",
       "      <td>-6.511371</td>\n",
       "      <td>-6.931261</td>\n",
       "      <td>-41.605873</td>\n",
       "      <td>-64.906555</td>\n",
       "      <td>18.932087</td>\n",
       "      <td>18.932087</td>\n",
       "      <td>124.114227</td>\n",
       "      <td>102.327950</td>\n",
       "      <td>-0.034225</td>\n",
       "      <td>-0.046033</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.280428</td>\n",
       "      <td>0.170445</td>\n",
       "      <td>0.318401</td>\n",
       "      <td>0.290507</td>\n",
       "      <td>2.463995</td>\n",
       "      <td>2.463995</td>\n",
       "      <td>-6.715493</td>\n",
       "      <td>-7.151367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.793957</td>\n",
       "      <td>-10.793957</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.014669</td>\n",
       "      <td>0.009971</td>\n",
       "      <td>0.967808</td>\n",
       "      <td>0.956092</td>\n",
       "      <td>-6.715493</td>\n",
       "      <td>-7.151367</td>\n",
       "      <td>-41.253011</td>\n",
       "      <td>-64.648491</td>\n",
       "      <td>22.946876</td>\n",
       "      <td>22.946876</td>\n",
       "      <td>117.418013</td>\n",
       "      <td>96.575298</td>\n",
       "      <td>-0.040129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.054992</td>\n",
       "      <td>0.304454</td>\n",
       "      <td>2.463995</td>\n",
       "      <td>-6.933430</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10.793957</td>\n",
       "      <td>-0.846154</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.012320</td>\n",
       "      <td>0.961950</td>\n",
       "      <td>-6.933430</td>\n",
       "      <td>-52.950751</td>\n",
       "      <td>22.946876</td>\n",
       "      <td>106.996656</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Pretend you're an {persona} person making stat...</td>\n",
       "      <td>20</td>\n",
       "      <td>['o_proj', 'down_proj']</td>\n",
       "      <td>add2</td>\n",
       "      <td>1</td>\n",
       "      <td>[['an honest'], ['a dishonest']]</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>-3</td>\n",
       "      <td>raw</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>True</td>\n",
       "      <td>wassname/qwen-14B-codefourchan</td>\n",
       "      <td>/workspace/InnerPiSSA_private/outputs/adapters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[0.75]</td>\n",
       "      <td>800</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>innerpissa</td>\n",
       "      <td>False</td>\n",
       "      <td>honest</td>\n",
       "      <td>32</td>\n",
       "      <td>['up_proj']</td>\n",
       "      <td>8</td>\n",
       "      <td>InnerPiSSA</td>\n",
       "      <td>True</td>\n",
       "      <td>288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>-0.680004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.549820</td>\n",
       "      <td>339.738163</td>\n",
       "      <td>171.546768</td>\n",
       "      <td>76.452703</td>\n",
       "      <td>249.454077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0d6cm3hs</td>\n",
       "      <td>q14b-c4c-raw-r128</td>\n",
       "      <td>finished</td>\n",
       "      <td>2025-11-26T08:55:03Z</td>\n",
       "      <td>https://wandb.ai/wassname/InnerPiSSA/runs/0d6c...</td>\n",
       "      <td>/media/wassname/SGIronWolf/projects5/2025/llm_...</td>\n",
       "      <td>q14b-80gb --model_name=wassname/qwen-14B-codef...</td>\n",
       "      <td>ablation-20251126-0737</td>\n",
       "      <td>513a6a74c624d2e51061bc4766df8097c2ae9c1a</td>\n",
       "      <td>NVIDIA H100 NVL</td>\n",
       "      <td>36</td>\n",
       "      <td>148.876314</td>\n",
       "      <td>751</td>\n",
       "      <td>-0.7702</td>\n",
       "      <td>-0.6743</td>\n",
       "      <td>-0.6630</td>\n",
       "      <td>0.117831</td>\n",
       "      <td>honest</td>\n",
       "      <td>-0.674304</td>\n",
       "      <td>-0.681328</td>\n",
       "      <td>-0.681328</td>\n",
       "      <td>-0.415435</td>\n",
       "      <td>-0.678656</td>\n",
       "      <td>-12.779671</td>\n",
       "      <td>-7.298034</td>\n",
       "      <td>0.326655</td>\n",
       "      <td>1.163087</td>\n",
       "      <td>-7.298034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-15.369578</td>\n",
       "      <td>-7.684789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.684789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>751</td>\n",
       "      <td>708</td>\n",
       "      <td>1.764148e+09</td>\n",
       "      <td>{'runtime': 751}</td>\n",
       "      <td>0.007522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.008474</td>\n",
       "      <td>-0.674304</td>\n",
       "      <td>-0.415435</td>\n",
       "      <td>-0.678656</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>148.876314</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>{'_latest_artifact_path': 'wandb-client-artifa...</td>\n",
       "      <td>14.612954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.684789</td>\n",
       "      <td>1</td>\n",
       "      <td>-15.369578</td>\n",
       "      <td>0.004</td>\n",
       "      <td>base_model.model.model.layers.36.mlp.up_proj</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.009617</td>\n",
       "      <td>-7.684789</td>\n",
       "      <td>-85.011421</td>\n",
       "      <td>25.845478</td>\n",
       "      <td>145.215172</td>\n",
       "      <td>0.071565</td>\n",
       "      <td>-0.056522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.511352</td>\n",
       "      <td>0.528300</td>\n",
       "      <td>14.612954</td>\n",
       "      <td>14.612954</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.516451</td>\n",
       "      <td>-7.853127</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-15.369578</td>\n",
       "      <td>-15.369578</td>\n",
       "      <td>1.804220e-07</td>\n",
       "      <td>1.804220e-07</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.074188</td>\n",
       "      <td>0.945046</td>\n",
       "      <td>-7.516451</td>\n",
       "      <td>-7.853127</td>\n",
       "      <td>-71.019257</td>\n",
       "      <td>-99.003586</td>\n",
       "      <td>25.845478</td>\n",
       "      <td>25.845478</td>\n",
       "      <td>161.128311</td>\n",
       "      <td>129.302032</td>\n",
       "      <td>0.019156</td>\n",
       "      <td>-0.018695</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.358451</td>\n",
       "      <td>0.265727</td>\n",
       "      <td>0.245149</td>\n",
       "      <td>0.408160</td>\n",
       "      <td>1.163087</td>\n",
       "      <td>1.163087</td>\n",
       "      <td>-7.122340</td>\n",
       "      <td>-7.473728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-12.779671</td>\n",
       "      <td>-12.779671</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.005761</td>\n",
       "      <td>0.005870</td>\n",
       "      <td>1.021291</td>\n",
       "      <td>0.983516</td>\n",
       "      <td>-7.122340</td>\n",
       "      <td>-7.473728</td>\n",
       "      <td>-63.462010</td>\n",
       "      <td>-90.563447</td>\n",
       "      <td>22.065051</td>\n",
       "      <td>22.065051</td>\n",
       "      <td>152.760236</td>\n",
       "      <td>122.186175</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.046362</td>\n",
       "      <td>0.326655</td>\n",
       "      <td>1.163087</td>\n",
       "      <td>-7.298034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-12.779671</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.005815</td>\n",
       "      <td>1.002404</td>\n",
       "      <td>-7.298034</td>\n",
       "      <td>-77.012728</td>\n",
       "      <td>22.065051</td>\n",
       "      <td>137.473206</td>\n",
       "      <td>128</td>\n",
       "      <td>16</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>Pretend you're an {persona} person making stat...</td>\n",
       "      <td>20</td>\n",
       "      <td>['o_proj', 'down_proj']</td>\n",
       "      <td>add2</td>\n",
       "      <td>1</td>\n",
       "      <td>[['an honest'], ['a dishonest']]</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>-3</td>\n",
       "      <td>raw</td>\n",
       "      <td>True</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>True</td>\n",
       "      <td>wassname/qwen-14B-codefourchan</td>\n",
       "      <td>/workspace/InnerPiSSA_private/outputs/adapters</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>[0.75]</td>\n",
       "      <td>800</td>\n",
       "      <td>0.05</td>\n",
       "      <td>100</td>\n",
       "      <td>innerpissa</td>\n",
       "      <td>False</td>\n",
       "      <td>honest</td>\n",
       "      <td>32</td>\n",
       "      <td>['up_proj']</td>\n",
       "      <td>8</td>\n",
       "      <td>InnerPiSSA</td>\n",
       "      <td>True</td>\n",
       "      <td>288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.0</td>\n",
       "      <td>-0.681328</td>\n",
       "      <td>-0.681328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.589907</td>\n",
       "      <td>339.738163</td>\n",
       "      <td>171.546768</td>\n",
       "      <td>-56.179102</td>\n",
       "      <td>-13.215320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     run_id               name     state            created_at                                                url  \\\n",
       "0  qwtkm93m  q14b-c4c-raw-r128  finished  2025-11-27T08:17:03Z  https://wandb.ai/wassname/InnerPiSSA/runs/qwtk...   \n",
       "1  4c1jbdpe  q14b-c4c-raw-r128  finished  2025-11-27T01:43:26Z  https://wandb.ai/wassname/InnerPiSSA/runs/4c1j...   \n",
       "2  0d6cm3hs  q14b-c4c-raw-r128  finished  2025-11-26T08:55:03Z  https://wandb.ai/wassname/InnerPiSSA/runs/0d6c...   \n",
       "\n",
       "                                            log_file                                               args  \\\n",
       "0  /media/wassname/SGIronWolf/projects5/2025/llm_...  q14b-80gb --model_name=wassname/qwen-14B-codef...   \n",
       "1  /media/wassname/SGIronWolf/projects5/2025/llm_...  q14b-80gb --model_name=wassname/qwen-14B-codef...   \n",
       "2  /media/wassname/SGIronWolf/projects5/2025/llm_...  q14b-80gb --model_name=wassname/qwen-14B-codef...   \n",
       "\n",
       "                  run_group                                git_commit                    gpu  layer_num  main_metric  \\\n",
       "0    ablation-20251127-0813  7ec1d8d80bec4b43396bde3b546e2a5b4f508d33  NVIDIA A100-SXM4-80GB         36   419.813115   \n",
       "1  run-models-20251127-0143  7ec1d8d80bec4b43396bde3b546e2a5b4f508d33  NVIDIA A100-SXM4-80GB         36   599.477174   \n",
       "2    ablation-20251126-0737  513a6a74c624d2e51061bc4766df8097c2ae9c1a        NVIDIA H100 NVL         36   148.876314   \n",
       "\n",
       "   runtime  vh_neg  vh_zero  vh_pos  symmetry_mean resistant_toward  baseline_effect_InnerPiSSA  \\\n",
       "0     1483 -0.8108  -0.6733 -0.4864       0.735688        dishonest                   -0.673339   \n",
       "1     1473 -0.8743  -0.6733 -0.4125       0.770706        dishonest                   -0.673339   \n",
       "2      751 -0.7702  -0.6743 -0.6630       0.117831           honest                   -0.674304   \n",
       "\n",
       "   baseline_effect_s_steer  baseline_effect_pca  baseline_effect_prompting  baseline_effect_repeng  val_loss_total  \\\n",
       "0                -0.680004            -0.680004                  -0.390598               -0.680650      -11.302973   \n",
       "1                -0.680004            -0.680004                  -0.390598               -0.680650      -10.793957   \n",
       "2                -0.681328            -0.681328                  -0.415435               -0.678656      -12.779671   \n",
       "\n",
       "   val_loss_proj  val_loss_coh  val_loss_monotonic  val_proj_diff  val_logp_degradation  train_loss_total  \\\n",
       "0      -6.914284      0.285055            1.955485      -6.914284                   NaN        -13.359199   \n",
       "1      -6.933430      0.304454            2.463995      -6.933430                   NaN        -13.343777   \n",
       "2      -7.298034      0.326655            1.163087      -7.298034                   NaN        -15.369578   \n",
       "\n",
       "   train_loss_proj  train_loss_coh  train_loss_monotonic  train_proj_diff  train_logp_degradation  _runtime  _step  \\\n",
       "0        -6.679599        0.000000                   0.0        -6.679599                     NaN      1483    708   \n",
       "1        -6.721316        0.049427                   0.0        -6.721316                     NaN      1473    708   \n",
       "2        -7.684789        0.000000                   0.0        -7.684789                     NaN       751    708   \n",
       "\n",
       "     _timestamp             _wandb   coh_deg   cw  delta_logp_change  eval/baseline_InnerPiSSA (ours)  \\\n",
       "0  1.764233e+09  {'runtime': 1483} -0.024508  1.0          -0.018907                        -0.673339   \n",
       "1  1.764209e+09  {'runtime': 1473} -0.021908  1.0          -0.030372                        -0.673339   \n",
       "2  1.764148e+09   {'runtime': 751}  0.007522  1.0           0.008474                        -0.674304   \n",
       "\n",
       "   eval/baseline_prompting  eval/baseline_repeng                             eval/coherence_metrics  \\\n",
       "0                -0.390598             -0.680650  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "1                -0.390598             -0.680650  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "2                -0.415435             -0.678656  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "\n",
       "                              eval/effect_sizes_CI95                          eval/effect_sizes_Pearson  \\\n",
       "0  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "1  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "2  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "\n",
       "                             eval/effect_sizes_Slope                      eval/effect_sizes_Slope*(1-p)  \\\n",
       "0  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "1  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "2  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "\n",
       "                          eval/effect_sizes_Spearman                           eval/effect_sizes_T-stat  \\\n",
       "0  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "1  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "2  {'_latest_artifact_path': 'wandb-client-artifa...  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "\n",
       "   eval/main_metric                              eval/transfer_summary  \\\n",
       "0        419.813115  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "1        599.477174  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "2        148.876314  {'_latest_artifact_path': 'wandb-client-artifa...   \n",
       "\n",
       "                                   eval/value_scores   flip_ema  loss_coh  loss_monotonic  loss_proj  \\\n",
       "0  {'_latest_artifact_path': 'wandb-client-artifa...  13.922856  0.000000             0.0  -6.679599   \n",
       "1  {'_latest_artifact_path': 'wandb-client-artifa...  13.982160  0.049427             0.0  -6.721316   \n",
       "2  {'_latest_artifact_path': 'wandb-client-artifa...  14.612954  0.000000             0.0  -7.684789   \n",
       "\n",
       "   loss_proj_flipped  loss_total     lr                                        module  mono_direction  mono_ema  \\\n",
       "0                  1  -13.359199  0.004  base_model.model.model.layers.36.mlp.up_proj            -1.0      -1.0   \n",
       "1                  1  -13.343777  0.004  base_model.model.model.layers.36.mlp.up_proj            -1.0      -1.0   \n",
       "2                  1  -15.369578  0.004  base_model.model.model.layers.36.mlp.up_proj            -1.0      -1.0   \n",
       "\n",
       "   mono_frac_violated  mono_violation  prob_ratio  proj_diff    proj_pi   proj_ref  separation_norm  \\\n",
       "0                 0.0             0.0    0.975806  -6.679599 -51.683073  18.932087       115.063175   \n",
       "1                 0.0             0.0    0.978334  -6.721316 -53.256214  18.932087       113.221088   \n",
       "2                 0.0             0.0    1.009617  -7.684789 -85.011421  25.845478       145.215172   \n",
       "\n",
       "   train/by_coef/coh_deg_coef+1_0  train/by_coef/coh_deg_coef-1_0  train/by_coef/cw_coef+1_0  \\\n",
       "0                       -0.018746                       -0.030271                        1.0   \n",
       "1                       -0.019070                       -0.024746                        1.0   \n",
       "2                        0.071565                       -0.056522                        1.0   \n",
       "\n",
       "   train/by_coef/cw_coef-1_0  train/by_coef/delta_logp_change_coef+1_0  train/by_coef/delta_logp_change_coef-1_0  \\\n",
       "0                        1.0                                 -0.265730                                  0.227916   \n",
       "1                        1.0                                 -0.278593                                  0.217849   \n",
       "2                        1.0                                 -0.511352                                  0.528300   \n",
       "\n",
       "   train/by_coef/flip_ema_coef+1_0  train/by_coef/flip_ema_coef-1_0  train/by_coef/loss_coh_coef+1_0  \\\n",
       "0                        13.922856                        13.922856                         0.000000   \n",
       "1                        13.982160                        13.982160                         0.098854   \n",
       "2                        14.612954                        14.612954                         0.000000   \n",
       "\n",
       "   train/by_coef/loss_coh_coef-1_0  train/by_coef/loss_monotonic_coef+1_0  train/by_coef/loss_monotonic_coef-1_0  \\\n",
       "0                              0.0                                    0.0                                    0.0   \n",
       "1                              0.0                                    0.0                                    0.0   \n",
       "2                              0.0                                    0.0                                    0.0   \n",
       "\n",
       "   train/by_coef/loss_proj_coef+1_0  train/by_coef/loss_proj_coef-1_0  train/by_coef/loss_proj_flipped_coef+1_0  \\\n",
       "0                         -6.429043                         -6.930156                                         1   \n",
       "1                         -6.511371                         -6.931261                                         1   \n",
       "2                         -7.516451                         -7.853127                                         1   \n",
       "\n",
       "   train/by_coef/loss_proj_flipped_coef-1_0  train/by_coef/loss_total_coef+1_0  train/by_coef/loss_total_coef-1_0  \\\n",
       "0                                         1                         -13.359199                         -13.359199   \n",
       "1                                         1                         -13.343777                         -13.343777   \n",
       "2                                         1                         -15.369578                         -15.369578   \n",
       "\n",
       "   train/by_coef/lr_coef+1_0  train/by_coef/lr_coef-1_0  train/by_coef/mono_direction_coef+1_0  \\\n",
       "0               1.804220e-07               1.804220e-07                                   -1.0   \n",
       "1               1.804220e-07               1.804220e-07                                   -1.0   \n",
       "2               1.804220e-07               1.804220e-07                                   -1.0   \n",
       "\n",
       "   train/by_coef/mono_direction_coef-1_0  train/by_coef/mono_ema_coef+1_0  train/by_coef/mono_ema_coef-1_0  \\\n",
       "0                                   -1.0                             -1.0                             -1.0   \n",
       "1                                   -1.0                             -1.0                             -1.0   \n",
       "2                                   -1.0                             -1.0                             -1.0   \n",
       "\n",
       "   train/by_coef/mono_frac_violated_coef+1_0  train/by_coef/mono_frac_violated_coef-1_0  \\\n",
       "0                                        0.0                                        0.0   \n",
       "1                                        0.0                                        0.0   \n",
       "2                                        0.0                                        0.0   \n",
       "\n",
       "   train/by_coef/mono_violation_coef+1_0  train/by_coef/mono_violation_coef-1_0  train/by_coef/prob_ratio_coef+1_0  \\\n",
       "0                                    0.0                                    0.0                           0.981429   \n",
       "1                                    0.0                                    0.0                           0.981111   \n",
       "2                                    0.0                                    0.0                           1.074188   \n",
       "\n",
       "   train/by_coef/prob_ratio_coef-1_0  train/by_coef/proj_diff_coef+1_0  train/by_coef/proj_diff_coef-1_0  \\\n",
       "0                           0.970183                         -6.429043                         -6.930156   \n",
       "1                           0.975558                         -6.511371                         -6.931261   \n",
       "2                           0.945046                         -7.516451                         -7.853127   \n",
       "\n",
       "   train/by_coef/proj_pi_coef+1_0  train/by_coef/proj_pi_coef-1_0  train/by_coef/proj_ref_coef+1_0  \\\n",
       "0                      -38.252064                      -65.114082                        18.932087   \n",
       "1                      -41.605873                      -64.906555                        18.932087   \n",
       "2                      -71.019257                      -99.003586                        25.845478   \n",
       "\n",
       "   train/by_coef/proj_ref_coef-1_0  train/by_coef/separation_norm_coef+1_0  train/by_coef/separation_norm_coef-1_0  \\\n",
       "0                        18.932087                              127.344666                              102.781685   \n",
       "1                        18.932087                              124.114227                              102.327950   \n",
       "2                        25.845478                              161.128311                              129.302032   \n",
       "\n",
       "   val/by_coef/coh_deg_coef+1_0  val/by_coef/coh_deg_coef-1_0  val/by_coef/cw_coef+1_0  val/by_coef/cw_coef-1_0  \\\n",
       "0                     -0.009998                     -0.051022                      1.0                      1.0   \n",
       "1                     -0.034225                     -0.046033                      1.0                      1.0   \n",
       "2                      0.019156                     -0.018695                      1.0                      1.0   \n",
       "\n",
       "   val/by_coef/delta_logp_change_coef+1_0  val/by_coef/delta_logp_change_coef-1_0  val/by_coef/loss_coh_coef+1_0  \\\n",
       "0                               -0.262232                                0.180793                       0.213706   \n",
       "1                               -0.280428                                0.170445                       0.318401   \n",
       "2                               -0.358451                                0.265727                       0.245149   \n",
       "\n",
       "   val/by_coef/loss_coh_coef-1_0  val/by_coef/loss_monotonic_coef+1_0  val/by_coef/loss_monotonic_coef-1_0  \\\n",
       "0                       0.356404                             1.955485                             1.955485   \n",
       "1                       0.290507                             2.463995                             2.463995   \n",
       "2                       0.408160                             1.163087                             1.163087   \n",
       "\n",
       "   val/by_coef/loss_proj_coef+1_0  val/by_coef/loss_proj_coef-1_0  val/by_coef/loss_proj_flipped_coef+1_0  \\\n",
       "0                       -6.649959                       -7.178610                                     1.0   \n",
       "1                       -6.715493                       -7.151367                                     1.0   \n",
       "2                       -7.122340                       -7.473728                                     1.0   \n",
       "\n",
       "   val/by_coef/loss_proj_flipped_coef-1_0  val/by_coef/loss_total_coef+1_0  val/by_coef/loss_total_coef-1_0  \\\n",
       "0                                     1.0                       -11.302973                       -11.302973   \n",
       "1                                     1.0                       -10.793957                       -10.793957   \n",
       "2                                     1.0                       -12.779671                       -12.779671   \n",
       "\n",
       "   val/by_coef/mono_direction_coef+1_0  val/by_coef/mono_direction_coef-1_0  val/by_coef/mono_frac_violated_coef+1_0  \\\n",
       "0                            -0.846154                            -0.846154                                 0.250000   \n",
       "1                            -0.846154                            -0.846154                                 0.230769   \n",
       "2                            -1.000000                            -1.000000                                 0.125000   \n",
       "\n",
       "   val/by_coef/mono_frac_violated_coef-1_0  val/by_coef/mono_violation_coef+1_0  val/by_coef/mono_violation_coef-1_0  \\\n",
       "0                                 0.250000                             0.010042                             0.009513   \n",
       "1                                 0.230769                             0.014669                             0.009971   \n",
       "2                                 0.125000                             0.005761                             0.005870   \n",
       "\n",
       "   val/by_coef/prob_ratio_coef+1_0  val/by_coef/prob_ratio_coef-1_0  val/by_coef/proj_diff_coef+1_0  \\\n",
       "0                         0.990951                         0.951747                       -6.649959   \n",
       "1                         0.967808                         0.956092                       -6.715493   \n",
       "2                         1.021291                         0.983516                       -7.122340   \n",
       "\n",
       "   val/by_coef/proj_diff_coef-1_0  val/by_coef/proj_pi_coef+1_0  val/by_coef/proj_pi_coef-1_0  \\\n",
       "0                       -7.178610                    -38.645227                    -66.330235   \n",
       "1                       -7.151367                    -41.253011                    -64.648491   \n",
       "2                       -7.473728                    -63.462010                    -90.563447   \n",
       "\n",
       "   val/by_coef/proj_ref_coef+1_0  val/by_coef/proj_ref_coef-1_0  val/by_coef/separation_norm_coef+1_0  \\\n",
       "0                      22.946876                      22.946876                            118.654505   \n",
       "1                      22.946876                      22.946876                            117.418013   \n",
       "2                      22.065051                      22.065051                            152.760236   \n",
       "\n",
       "   val/by_coef/separation_norm_coef-1_0  val/coh_deg  val/cw  val/delta_logp_change  val/loss_coh  val/loss_monotonic  \\\n",
       "0                             97.633345    -0.030510     1.0              -0.040720      0.285055            1.955485   \n",
       "1                             96.575298    -0.040129     1.0              -0.054992      0.304454            2.463995   \n",
       "2                            122.186175     0.000231     1.0              -0.046362      0.326655            1.163087   \n",
       "\n",
       "   val/loss_proj  val/loss_proj_flipped  val/loss_total  val/mono_direction  val/mono_frac_violated  \\\n",
       "0      -6.914284                    1.0      -11.302973           -0.846154                0.250000   \n",
       "1      -6.933430                    1.0      -10.793957           -0.846154                0.230769   \n",
       "2      -7.298034                    1.0      -12.779671           -1.000000                0.125000   \n",
       "\n",
       "   val/mono_violation  val/prob_ratio  val/proj_diff  val/proj_pi  val/proj_ref  val/separation_norm    r  bs  \\\n",
       "0            0.009777        0.971349      -6.914284   -52.487731     22.946876           108.143925  128  16   \n",
       "1            0.012320        0.961950      -6.933430   -52.950751     22.946876           106.996656  128  16   \n",
       "2            0.005815        1.002404      -7.298034   -77.012728     22.065051           137.473206  128  16   \n",
       "\n",
       "        wd   coh  mono  quick  rot_u  rot_v                                             PROMPT  n_logs  \\\n",
       "0  0.00001  True  True  False  False   True  Pretend you're an {persona} person making stat...      20   \n",
       "1  0.00001  True  True  False  False   True  Pretend you're an {persona} person making stat...      20   \n",
       "2  0.00001  True  True  False  False   True  Pretend you're an {persona} person making stat...      20   \n",
       "\n",
       "                   modules scale_s verbose                          PERSONAS  coh_temp  n_depths  n_epochs  depth_end  \\\n",
       "0  ['o_proj', 'down_proj']    add2       1  [['an honest'], ['a dishonest']]         4        14        10         -3   \n",
       "1  ['o_proj', 'down_proj']    add2       1  [['an honest'], ['a dishonest']]         4        14        10         -3   \n",
       "2  ['o_proj', 'down_proj']    add2       1  [['an honest'], ['a dishonest']]         4        14        10         -3   \n",
       "\n",
       "  loss_type  use_wandb  val_split  coh_thresh  coh_weight  loss_use_V                      model_name  \\\n",
       "0       raw       True       0.15         0.5        40.0        True  wassname/qwen-14B-codefourchan   \n",
       "1       raw       True       0.15         0.5        40.0        True  wassname/qwen-14B-codefourchan   \n",
       "2       raw       True       0.15         0.5        40.0        True  wassname/qwen-14B-codefourchan   \n",
       "\n",
       "                                       output_dir  wandb_tags  depth_start loss_depths  max_samples  mono_margin  \\\n",
       "0  /workspace/InnerPiSSA_private/outputs/adapters         NaN          0.3      [0.75]          800         0.05   \n",
       "1  /workspace/InnerPiSSA_private/outputs/adapters         NaN          0.3      [0.75]          800         0.05   \n",
       "2  /workspace/InnerPiSSA_private/outputs/adapters         NaN          0.3      [0.75]          800         0.05   \n",
       "\n",
       "   mono_weight adapter_type  coh_adaptive dataset_name  effective_bs loss_modules  n_last_tokens wandb_project  \\\n",
       "0          100   innerpissa         False       honest            32  ['up_proj']              8    InnerPiSSA   \n",
       "1          100   innerpissa         False       honest            32  ['up_proj']              8    InnerPiSSA   \n",
       "2          100   innerpissa         False       honest            32  ['up_proj']              8    InnerPiSSA   \n",
       "\n",
       "   data_aware_init  eval_max_tokens experiment_name  save_checkpoints  eval_max_dilemmas quantization_type  \\\n",
       "0             True              288             NaN             False                NaN              none   \n",
       "1             True              288             NaN             False                NaN              none   \n",
       "2             True              288             NaN             False                NaN              none   \n",
       "\n",
       "   max_rotation_angle  early_stop_patience loss_snorm  pref_dir_k pref_dir_method  val_every_n_samples  \\\n",
       "0                 0.3                    4        NaN         NaN             NaN                256.0   \n",
       "1                 0.3                    4        NaN         NaN             NaN                256.0   \n",
       "2                 0.3                    4        NaN         NaN             NaN                256.0   \n",
       "\n",
       "   eval/baseline_S-space steer  eval/baseline_pca (wassname) s_selection_mode  loss_gap  prompting_score  \\\n",
       "0                    -0.680004                     -0.680004              NaN  2.056226       339.738163   \n",
       "1                    -0.680004                     -0.680004              NaN  2.549820       339.738163   \n",
       "2                    -0.681328                     -0.681328              NaN  2.589907       339.738163   \n",
       "\n",
       "   repeng_score  gain_vs_prompting  gain_vs_repeng  \n",
       "0    171.546768          23.569608      144.722253  \n",
       "1    171.546768          76.452703      249.454077  \n",
       "2    171.546768         -56.179102      -13.215320  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv('../outputs/wandb_results.csv')\n",
    "df_summary = pd.read_csv('../outputs/wandb_summary.csv')\n",
    "\n",
    "# Compute loss_gap (overfitting metric: val - train)\n",
    "df_full['loss_gap'] = df_full['val_loss_total'] - df_full['train_loss_total']\n",
    "\n",
    "# Load baseline results for comparison\n",
    "df_prompting = pd.read_csv('../outputs/prompting_results.csv')\n",
    "df_repeng = pd.read_csv('../outputs/repeng_results.csv')\n",
    "\n",
    "# Create lookup dicts for baseline scores by model\n",
    "prompting_baseline = df_prompting.groupby('model_name')['main_score'].mean().to_dict()\n",
    "repeng_baseline = df_repeng.groupby('model_name')['main_score'].mean().to_dict()\n",
    "\n",
    "# Add baseline scores to df_full based on model_name\n",
    "df_full['prompting_score'] = df_full['model_name'].map(prompting_baseline)\n",
    "df_full['repeng_score'] = df_full['model_name'].map(repeng_baseline)\n",
    "\n",
    "# Compute gain % vs prompting: (innerpissa - prompting) / prompting * 100\n",
    "df_full['gain_vs_prompting'] = (df_full['main_metric'] - df_full['prompting_score']) / df_full['prompting_score'].abs() * 100\n",
    "df_full['gain_vs_repeng'] = (df_full['main_metric'] - df_full['repeng_score']) / df_full['repeng_score'].abs() * 100\n",
    "\n",
    "print(f\"Total runs: {len(df_full)}\")\n",
    "print(f\"Runs with prompting baseline: {df_full['prompting_score'].notna().sum()}\")\n",
    "\n",
    "print(f\"\\nBaseline scores by model:\")\n",
    "for model in df_full['model_name'].dropna().unique()[:5]:\n",
    "    p = prompting_baseline.get(model, np.nan)\n",
    "    r = repeng_baseline.get(model, np.nan)\n",
    "    print(f\"  {model[:40]}: prompting={p:.1f}, repeng={r:.1f}\")\n",
    "\n",
    "df_full.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69b3e80",
   "metadata": {},
   "source": [
    "## Step 1: Recalculate Symmetry from Logs\n",
    "\n",
    "Parse each run's output.log to get:\n",
    "- Baseline-relative symmetry: `min(|neg-zero|, |pos-zero|) / max(...)`\n",
    "- Resistant direction: which side (neg or pos) moved LESS from baseline\n",
    "- Raw scores for both InnerPiSSA and prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "21d8cc94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing logs for Value/Honesty...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3b21aaf55b47cf9b8c8976af33a415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing log for run mdc8ewki: could not convert string to float: '...'\n",
      "Error parsing log for run kx7aauqa: could not convert string to float: '...'\n",
      "Error parsing log for run mtod05cs: could not convert string to float: '...'\n",
      "Parsed 723 runs with valid Value/Honesty\n",
      "\n",
      "=== Value/Honesty Summary ===\n",
      "symmetry: 0.50  0.29\n",
      "\n",
      "=== Resistant Direction ===\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Parse logs to extract Value/Honesty at coeff=-1,0,+1\n",
    "from ipissa.config import proj_root\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "cache_dir = proj_root / \"outputs\" / \"wandb_cache\"\n",
    "\n",
    "def parse_value_honesty_from_log(log_file: Path) -> dict:\n",
    "    \"\"\"Extract Value/Honesty scores at coeff=-1, 0, +1 from InnerPiSSA results table.\n",
    "    \n",
    "    Returns: {vh_neg, vh_zero, vh_pos, symmetry, resistant_toward}\n",
    "    \"\"\"\n",
    "    if not log_file.exists():\n",
    "        print(f\"Log file does not exist: {log_file}\")\n",
    "        return {}\n",
    "    \n",
    "    try:\n",
    "        logs = log_file.read_text()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {log_file}: {e}\")\n",
    "        return {}\n",
    "    \n",
    "    # Find InnerPiSSA results table\n",
    "    pattern = r'Results for method: InnerPiSSA.*?(?=Results for method:|$)'\n",
    "    match = re.search(pattern, logs, re.DOTALL)\n",
    "    if not match:\n",
    "        return {}\n",
    "    \n",
    "    table_text = match.group(0)\n",
    "    \n",
    "    # Parse Value/Honesty row: \"Value/Honesty   -3.0767  -3.1215  -3.1828\"\n",
    "    vh_pattern = r'Value/Honesty\\s+([-\\d.]+)\\s+([-\\d.]+)\\s+([-\\d.]+)'\n",
    "    vh_match = re.search(vh_pattern, table_text)\n",
    "    if not vh_match:\n",
    "        return {}\n",
    "    \n",
    "    neg, zero, pos = float(vh_match.group(1)), float(vh_match.group(2)), float(vh_match.group(3))\n",
    "    \n",
    "    # Compute symmetry: min(|neg-zero|, |pos-zero|) / max(...)\n",
    "    dist_neg = abs(neg - zero)\n",
    "    dist_pos = abs(pos - zero)\n",
    "    \n",
    "    metrics = {\n",
    "        'vh_neg': neg,\n",
    "        'vh_zero': zero, \n",
    "        'vh_pos': pos,\n",
    "    }\n",
    "    \n",
    "    if max(dist_neg, dist_pos) > 0.01:\n",
    "        metrics['symmetry'] = min(dist_neg, dist_pos) / max(dist_neg, dist_pos)\n",
    "        # Resistant direction: which way has smaller effect?\n",
    "        metrics['resistant_toward'] = 'honest' if dist_pos < dist_neg else 'dishonest'\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Process all runs\n",
    "print(\"Parsing logs for Value/Honesty...\")\n",
    "run_metrics = []\n",
    "\n",
    "for _, row in tqdm(df_full.iterrows(), total=len(df_full)):\n",
    "    run_id = row['run_id']\n",
    "    log_file = cache_dir / run_id / \"output.log\"\n",
    "    try:\n",
    "        m = parse_value_honesty_from_log(log_file)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error parsing log for run {run_id}: {e}\")\n",
    "        continue\n",
    "    m['run_id'] = run_id\n",
    "    run_metrics.append(m)\n",
    "\n",
    "df_metrics = pd.DataFrame(run_metrics)\n",
    "print(f\"Parsed {df_metrics['symmetry'].notna().sum()} runs with valid Value/Honesty\")\n",
    "\n",
    "# Merge with original data\n",
    "df = df_full.merge(df_metrics, on='run_id', how='left')\n",
    "\n",
    "# Summary\n",
    "valid = df[df['symmetry'].notna()]\n",
    "print(f\"\\n=== Value/Honesty Summary ===\")\n",
    "# print(f\"vh_neg:  {valid['vh_neg'].mean():.2f}  {valid['vh_neg'].std():.2f}\")\n",
    "# print(f\"vh_zero: {valid['vh_zero'].mean():.2f}  {valid['vh_zero'].std():.2f}\")  \n",
    "# print(f\"vh_pos:  {valid['vh_pos'].mean():.2f}  {valid['vh_pos'].std():.2f}\")\n",
    "print(f\"symmetry: {valid['symmetry'].mean():.2f}  {valid['symmetry'].std():.2f}\")\n",
    "\n",
    "print(f\"\\n=== Resistant Direction ===\")\n",
    "# print(df['resistant_toward'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b5509",
   "metadata": {},
   "source": [
    "## Step 2: Combine Sweeps by Type\n",
    "\n",
    "Load all sweep CSVs, combine by base name (ignoring date stamps).\n",
    "For controlled comparisons, we'll look at within-sweep relative differences rather than absolute values across sweeps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e4d05957",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define control variable and baseline value for each sweep\n",
    "# Use 'argv' for ALL sweeps to avoid config confounders\n",
    "# When sweeps are combined or have hidden varying params, argv shows the complete picture\n",
    "SWEEP_CONFIG = {\n",
    "    'sweep-lr': {'var': 'argv', 'baseline': None},\n",
    "    'sweep-rank': {'var': 'argv', 'baseline': None},\n",
    "    'sweep-rotation-angle': {'var': 'argv', 'baseline': None},\n",
    "    'run-models': {'var': 'argv', 'baseline': None},\n",
    "    'ablate-constraints': {'var': 'argv', 'baseline': None},\n",
    "    'ablate-modules': {'var': 'argv', 'baseline': None},\n",
    "    'ablate-wd': {'var': 'argv', 'baseline': None},\n",
    "    'data-efficiency': {'var': 'argv', 'baseline': None},\n",
    "    'sweep-layers': {'var': 'argv', 'baseline': None},\n",
    "    'sweep-long-training': {'var': 'argv', 'baseline': None},\n",
    "    'sweep-layers-V': {'var': 'argv', 'baseline': None},\n",
    "    'sweep-scale': {'var': 'argv', 'baseline': None},\n",
    "    'sweep-snorm': {'var': 'argv', 'baseline': None},\n",
    "    'sweep-pref-dir': {'var': 'argv', 'baseline': None},\n",
    "    'sweep-training-stages': {'var': 'argv', 'baseline': None},\n",
    "    'sweep-loss-modules': {'var': 'argv', 'baseline': None},\n",
    "    'ablation': {'var': 'argv', 'baseline': None},\n",
    "}\n",
    "\n",
    "# Add control_var to SWEEP_CONFIG for easier access\n",
    "for sweep_name in SWEEP_CONFIG:\n",
    "    if sweep_name == 'sweep-lr':\n",
    "        SWEEP_CONFIG[sweep_name]['control_var'] = 'lr'\n",
    "    elif sweep_name == 'sweep-rank':\n",
    "        SWEEP_CONFIG[sweep_name]['control_var'] = 'r'\n",
    "    elif sweep_name == 'sweep-rotation-angle':\n",
    "        SWEEP_CONFIG[sweep_name]['control_var'] = 'ipissa_rotation_max_angle'\n",
    "    elif sweep_name == 'run-models':\n",
    "        SWEEP_CONFIG[sweep_name]['control_var'] = 'model_name'\n",
    "    elif sweep_name == 'sweep-layers':\n",
    "        SWEEP_CONFIG[sweep_name]['control_var'] = 'depth'\n",
    "    elif sweep_name == 'sweep-layers-V':\n",
    "        SWEEP_CONFIG[sweep_name]['control_var'] = 'depth'\n",
    "    elif sweep_name == 'sweep-scale':\n",
    "        SWEEP_CONFIG[sweep_name]['control_var'] = 'ipissa_scale_mode'\n",
    "    elif sweep_name == 'sweep-snorm':\n",
    "        SWEEP_CONFIG[sweep_name]['control_var'] = 'loss_snorm'\n",
    "    elif sweep_name == 'sweep-pref-dir':\n",
    "        SWEEP_CONFIG[sweep_name]['control_var'] = 'pref_dir'\n",
    "    elif sweep_name == 'sweep-long-training':\n",
    "        SWEEP_CONFIG[sweep_name]['control_var'] = 'sampled_n'\n",
    "    elif sweep_name == 'data-efficiency':\n",
    "        SWEEP_CONFIG[sweep_name]['control_var'] = 'sampled_n'\n",
    "    elif sweep_name == 'sweep-training-stages':\n",
    "        SWEEP_CONFIG[sweep_name]['control_var'] = 'training_stage'\n",
    "    elif sweep_name == 'sweep-loss-modules':\n",
    "        SWEEP_CONFIG[sweep_name]['control_var'] = 'loss_module_types'\n",
    "    else:\n",
    "        SWEEP_CONFIG[sweep_name]['control_var'] = 'argv'  # fallback\n",
    "\n",
    "# Group files by sweep base name, optionally taking only latest N per group\n",
    "N_LATEST_SWEEPS = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3cc17727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 17 sweep types (latest 5 each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load sweep CSVs from outputs/sweep_groups/*.csv\n",
    "# Filename format: <sweep-base>-YYYYMMDD-HHMM.csv\n",
    "sweep_dir = proj_root / 'outputs' / 'sweep_groups'\n",
    "sweep_files = sorted([f for f in sweep_dir.glob('*.csv') if '_summary' not in f.name])\n",
    "\n",
    "\n",
    "def get_sweep_base(filename):\n",
    "    \"\"\"Extract sweep base name (e.g., 'sweep-lr' from 'sweep-lr-20251123-1629.csv').\"\"\"\n",
    "    return '-'.join(filename.split('-')[:-2])\n",
    "\n",
    "def get_sweep_timestamp(filename):\n",
    "    \"\"\"Extract timestamp for sorting (YYYYMMDD-HHMM).\"\"\"\n",
    "    parts = filename.rstrip('.csv').split('-')\n",
    "    return '-'.join(parts[-2:])\n",
    "\n",
    "sweep_by_base = {}\n",
    "for f in sweep_files:\n",
    "    base = get_sweep_base(f.name)\n",
    "    if base not in sweep_by_base:\n",
    "        sweep_by_base[base] = []\n",
    "    sweep_by_base[base].append(f)\n",
    "\n",
    "# Sort each group by timestamp (descending) and optionally take only latest N\n",
    "for base in sweep_by_base:\n",
    "    sweep_by_base[base] = sorted(sweep_by_base[base], key=lambda f: get_sweep_timestamp(f.name), reverse=True)\n",
    "    if N_LATEST_SWEEPS is not None:\n",
    "        sweep_by_base[base] = sweep_by_base[base][:N_LATEST_SWEEPS]\n",
    "\n",
    "# Load selected files\n",
    "sweeps = {}\n",
    "for base, files in sweep_by_base.items():\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        df_sweep = pd.read_csv(f)\n",
    "        df_sweep['sweep_file'] = f.name\n",
    "        df_sweep['sweep_base'] = base\n",
    "        dfs.append(df_sweep)\n",
    "    \n",
    "    combined = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Merge with parsed log metrics (symmetry, resistant_toward) \n",
    "    merge_cols = ['run_id', 'symmetry', 'resistant_toward']\n",
    "    available_cols = [c for c in merge_cols if c in df_metrics.columns]\n",
    "    combined = combined.merge(df_metrics[available_cols], on='run_id', how='left')\n",
    "    \n",
    "    # Add prompting/repeng baseline via model_name (run_id merge has 0 overlap with sweep CSVs)\n",
    "    if 'model_name' in combined.columns:\n",
    "        combined['prompting_score'] = combined['model_name'].map(prompting_baseline)\n",
    "        combined['repeng_score'] = combined['model_name'].map(repeng_baseline)\n",
    "        combined['gain_vs_prompting'] = (combined['main_metric'] - combined['prompting_score']) / combined['prompting_score'].abs() * 100\n",
    "        combined['gain_vs_repeng'] = (combined['main_metric'] - combined['repeng_score']) / combined['repeng_score'].abs() * 100\n",
    "    \n",
    "    sweeps[base] = combined\n",
    "\n",
    "print(f\"Loaded {len(sweeps)} sweep types\" + (f\" (latest {N_LATEST_SWEEPS} each)\" if N_LATEST_SWEEPS else \"\") + \"\\n\")\n",
    "\n",
    "def summarize_sweep_mean(df_s, var, baseline_val):\n",
    "    \"\"\"Summarize sweep using groupby. main_metric is the t-stat steering effect.\n",
    "    \n",
    "    If var='argv', extracts the varying part by removing common prefix.\n",
    "    \"\"\"\n",
    "    if var not in df_s.columns:\n",
    "        for alt in [var.replace('_', ''), var + 's']:\n",
    "            if alt in df_s.columns:\n",
    "                var = alt\n",
    "                break\n",
    "        else:\n",
    "            return None, var\n",
    "    \n",
    "    # Special handling for argv: extract varying part\n",
    "    if var == 'argv':\n",
    "        # Find common prefix across all argv values\n",
    "        argvs = df_s['argv'].dropna().unique()\n",
    "        if len(argvs) > 1:\n",
    "            # Find longest common prefix\n",
    "            common_prefix = argvs[0]\n",
    "            for argv in argvs[1:]:\n",
    "                # Find where they diverge\n",
    "                i = 0\n",
    "                while i < len(common_prefix) and i < len(argv) and common_prefix[i] == argv[i]:\n",
    "                    i += 1\n",
    "                common_prefix = common_prefix[:i]\n",
    "            \n",
    "            # Backtrack to last delimiter (space, -, /) to avoid cutting mid-word\n",
    "            # Note: underscore NOT included - want to preserve param names like loss_modules\n",
    "            if common_prefix:\n",
    "                delimiters = [' ', '-', '/']\n",
    "                last_delim_pos = max([common_prefix.rfind(d) for d in delimiters] + [0])\n",
    "                if last_delim_pos > 0:\n",
    "                    common_prefix = common_prefix[:last_delim_pos + 1]  # Keep delimiter\n",
    "            \n",
    "            # Remove common prefix and create a new column\n",
    "            df_s = df_s.copy()\n",
    "            df_s['argv_varying'] = df_s['argv'].apply(\n",
    "                lambda x: x[len(common_prefix):].strip() if pd.notna(x) else x\n",
    "            )\n",
    "            var = 'argv_varying'\n",
    "    \n",
    "    # Define columns to aggregate\n",
    "    agg_cols = {\n",
    "        'main_metric': 'mean',\n",
    "        'prompting_score': 'mean', \n",
    "        'gain_vs_prompting': 'mean',\n",
    "        'loss_gap': 'mean',\n",
    "        'symmetry': 'mean',\n",
    "    }\n",
    "    agg_cols = {k: v for k, v in agg_cols.items() if k in df_s.columns}\n",
    "    \n",
    "    df_result = (\n",
    "        df_s.groupby(var, dropna=False)\n",
    "        .agg(**{k: (k, v) for k, v in agg_cols.items()}, n=(var, 'size'))\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_result['is_baseline'] = df_result[var].apply(lambda x: '' if baseline_val is not None and x == baseline_val else '')\n",
    "    \n",
    "    # Sort: baseline first, then by main metric descending\n",
    "    if 'main_metric' in df_result.columns:\n",
    "        df_result = df_result.sort_values(['is_baseline', 'main_metric'], ascending=[False, False])\n",
    "    \n",
    "    return df_result, var\n",
    "\n",
    "def style_sweep_table(df, var_col):\n",
    "    \"\"\"Style a sweep summary table with color gradients and formatting.\"\"\"\n",
    "    styled = df.style\n",
    "    \n",
    "    # Format numeric columns\n",
    "    format_dict = {\n",
    "        'main_metric': '{:.1f}',\n",
    "        'prompting_score': '{:.1f}',\n",
    "        'gain_vs_prompting': '{:+.0f}',\n",
    "        'loss_gap': '{:.2f}',\n",
    "        'symmetry': '{:.2f}',\n",
    "        'n': '{:.0f}',\n",
    "    }\n",
    "    format_dict = {k: v for k, v in format_dict.items() if k in df.columns}\n",
    "    styled = styled.format(format_dict, na_rep='-')\n",
    "    \n",
    "    # Color gradients (higher is better for most)\n",
    "    if 'main_metric' in df.columns:\n",
    "        styled = styled.background_gradient(subset=['main_metric'], cmap='Greens')\n",
    "    if 'gain_vs_prompting' in df.columns:\n",
    "        styled = styled.background_gradient(subset=['gain_vs_prompting'], cmap='RdYlGn', vmin=-100, vmax=100)\n",
    "    if 'symmetry' in df.columns:\n",
    "        styled = styled.background_gradient(subset=['symmetry'], cmap='Blues')\n",
    "    if 'loss_gap' in df.columns:\n",
    "        styled = styled.background_gradient(subset=['loss_gap'], cmap='Reds_r')\n",
    "    \n",
    "    return styled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "7a915f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Sweep: sweep-lr (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 32\n",
      "     argv_varying  main_metric  prompting_score  gain_vs_prompting    loss_gap  symmetry  n is_baseline\n",
      "v1-80gb --lr=1e-2   748.050000              NaN                NaN   25.410000  0.095259  2            \n",
      "v1-80gb --lr=1e-3   638.300000              NaN                NaN    7.034500  0.179605  2            \n",
      "  -80gb --lr=1e-2   372.956667       613.221816         -39.180790    3.745267  0.460597  3            \n",
      "  -80gb --lr=1e-1   192.766667       613.221816         -68.564937   13.024667  0.313057  3            \n",
      "  -80gb --lr=1e-3   170.700000       613.221816         -72.163417    7.190000  0.897404  3            \n",
      "v1-80gb --lr=1e-4   106.965000              NaN                NaN    5.789000  0.323692  2            \n",
      "v1-80gb --lr=1e-5    92.980000              NaN                NaN   -0.178850  0.471192  2            \n",
      "v1-80gb --lr=1e-1    86.645000              NaN                NaN   21.070000  0.765943  2            \n",
      "v1-80gb --lr=1e-0    57.790000              NaN                NaN   15.425000  0.712962  2            \n",
      "v1-80gb --lr=1e-6    45.870000              NaN                NaN    1.205500  0.450599  2            \n",
      "  -80gb --lr=1e-5    40.270000       613.221816         -93.433045   -7.551667  0.776293  3            \n",
      "  -80gb --lr=1e-4    27.660000       613.221816         -95.489397    8.467700  0.455080  3            \n",
      "  -80gb --lr=1e-0    21.292767       613.221816         -96.527722 -100.971333  0.500220  3            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Sweep: sweep-rank (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 31\n",
      "    argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      " v1-80gb --r=128   752.250000              NaN                NaN  8.344000  0.167235  2            \n",
      " v1-80gb --r=256   630.500000              NaN                NaN 15.895000  0.383129  2            \n",
      " v1-80gb --r=512   335.915000              NaN                NaN 17.770000  0.640165  2            \n",
      "  v1-80gb --r=32   284.400000              NaN                NaN  4.463000  0.326606  2            \n",
      "   -80gb --r=256   231.866667       613.221816         -62.188777  1.580333  0.317129  3            \n",
      "   -80gb --r=512   208.703333       613.221816         -65.966094  9.455333  0.406363  3            \n",
      "   v1-80gb --r=8   186.150000              NaN                NaN  1.196300  0.698849  2            \n",
      "  v1-80gb --r=16   136.650000              NaN                NaN  2.051000  0.201847  2            \n",
      "    -80gb --r=64   131.600000       613.221816         -78.539576  2.059467  0.409058  3            \n",
      "   -80gb --r=128   120.869000       613.221816         -80.289514  2.722500  0.696460  3            \n",
      "    -80gb --r=32   113.593333       613.221816         -81.475980  1.286933  0.568001  3            \n",
      "  v1-80gb --r=64   112.417500              NaN                NaN 10.414500  0.665189  2            \n",
      "v1-80gb --r=1024    69.306500              NaN                NaN 21.235000  0.748919  2            \n",
      "\n",
      "======================================================================\n",
      "Sweep: sweep-rotation-angle (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 32\n",
      "                                            argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "                                  max_rotation_angle=1.0   553.133333       613.221816          -9.798817  4.573933  0.583722  3            \n",
      "                                  max_rotation_angle=0.5   516.446667       613.221816         -15.781426  2.501800  0.565090  3            \n",
      "                max_rotation_angle=0.3 --data_aware_init   507.933333       613.221816         -17.169722  2.928567  0.363390  3            \n",
      "max_rotation_angle=inf --scale_s=none --rot_v --no_rot_u   463.000000       613.221816         -24.497141  1.438500  0.745722  3            \n",
      "max_rotation_angle=inf --scale_s=none --rot_u --no_rot_v   414.866667       613.221816         -32.346395  4.451033  0.524802  3            \n",
      "                                  max_rotation_angle=inf   407.180000       613.221816         -33.599884  3.768867  0.406800  3            \n",
      "                                  max_rotation_angle=0.3   377.550000       613.221816         -38.431740  4.357500  0.509181  3            \n",
      "                max_rotation_angle=inf --data_aware_init   367.490000       613.221816         -40.072256  3.410767  0.789829  3            \n",
      "                                  max_rotation_angle=0.1   288.100000       613.221816         -53.018632  6.012000  0.535905  2            \n",
      "   max_rotation_angle=inf --scale_s=none --rot_u --rot_v   278.066667       613.221816         -54.654799  3.484700  0.474163  3            \n",
      "                                  max_rotation_angle=0.2   230.453333       613.221816         -62.419254  0.713167  0.464587  3            \n",
      "\n",
      "======================================================================\n",
      "Sweep: run-models (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 32\n",
      "                                         argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "                                           q4bv1-80gb  1207.866667              NaN                NaN 12.508667  0.406548  3            \n",
      "           q4bv1-80gb --model_name=Qwen/Qwen3-4B-Base   856.833333        15.417014        5457.712731  5.432667  0.242903  3            \n",
      "q14b-80gb --model_name=wassname/qwen-14B-codefourchan   599.500000       339.738163          76.459422  2.550000  0.770706  1            \n",
      "                                       gemma270m-80gb   585.440000       117.928288         396.437294 23.338000  0.575886  4            \n",
      "                                         gemma1b-80gb   534.475000        87.227084         512.739732 26.391275  0.635720  4            \n",
      "                                             q4b-80gb   500.300000       613.221816         -18.414514 30.730000  0.090683  1            \n",
      "                                            q06b-24gb   385.605000       179.763790         114.506493 15.356000  0.459564  5            \n",
      "                                        gemma12b-80gb   374.450000       470.055076         -20.339122 19.455500  0.403618  2            \n",
      "                                         gemma4b-80gb   317.288500       277.151945          14.481787 12.431825  0.386732  4            \n",
      "                                             l8b-80gb   204.735000       207.718962          -1.436538  4.505750  0.484905  4            \n",
      "                                            q14b-80gb    42.920000       113.744275         -62.266233  4.117000  0.709543  1            \n",
      "\n",
      "======================================================================\n",
      "Sweep: ablate-constraints (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 46\n",
      "                                                             argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "                                                    -80gb --mono --no_coh   819.100000       613.221816          33.573200 -0.482900  0.241136  1            \n",
      "                                                v1-80gb --no_coh_adaptive   799.250000              NaN                NaN 25.190000  0.062554  2            \n",
      "                                                  v1-80gb --no_mono --coh   543.900000              NaN                NaN  8.736500  0.256762  2            \n",
      "                                               v1-80gb --rot_u --no_rot_v   491.833333              NaN                NaN 14.442667  0.525578  3            \n",
      "                                                     -80gb --scale_s=none   441.000000       613.221816         -28.084750  2.580450  0.515293  2            \n",
      "v1-80gb --no_loss_use_V --loss_depths=0.5 --loss_modules o_proj down_proj   400.906667              NaN                NaN  9.366667  0.396087  3            \n",
      "                              v1-80gb --loss_use_V --loss_modules up_proj   304.633333              NaN                NaN 14.653333  0.547584  3            \n",
      "                                                    -80gb --no_mono --coh   301.600000       613.221816         -50.817144  0.344300  0.009132  1            \n",
      "                                                   v1-80gb --scale_s=none   273.696667              NaN                NaN  8.577667  0.347276  3            \n",
      "                                                  -80gb --no_coh_adaptive   256.200000       613.221816         -58.220664  2.741600  0.511494  2            \n",
      "                                             v1-80gb --no_data_aware_init   244.933333              NaN                NaN 30.010000  0.778943  3            \n",
      "                                                  -80gb --data_aware_init   230.370000       613.221816         -62.432843  3.734000  0.652024  2            \n",
      "                                                                  v1-80gb   206.063333              NaN                NaN 13.256333  0.450770  3            \n",
      "                                                                    -80gb   183.900000       613.221816         -70.010852  5.305000  0.742286  1            \n",
      "                                                 -80gb --no_mono --no_coh   165.900000       613.221816         -72.946168 -0.432700  0.925724  1            \n",
      "                                                  v1-80gb --mono --no_coh   139.370000              NaN                NaN  0.721890  0.588212  3            \n",
      "                                               v1-80gb --no_mono --no_coh   133.923333              NaN                NaN  0.390893  0.524687  3            \n",
      "                                            v1-80gb --no_rot_u --no_rot_v    82.220000              NaN                NaN  0.616133  0.813924  3            \n",
      "              -80gb --loss_use_V --loss_depths=0.8 --loss_modules up_proj    43.910000       613.221816         -92.839459  0.863300  0.741984  1            \n",
      "  -80gb --no_loss_use_V --loss_depths=0.5 --loss_modules o_proj down_proj    31.440000       613.221816         -94.872981  0.703290  0.779026  2            \n",
      "                                              -80gb --no_rot_u --no_rot_v    14.700000       613.221816         -97.602825 -1.280000  0.865072  1            \n",
      "                                -80gb --loss_use_V --loss_modules up_proj    10.100000       613.221816         -98.352961  4.929000  0.640951  1            \n",
      "\n",
      "======================================================================\n",
      "Sweep: ablate-modules (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 29\n",
      "                                                                                                 argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "v1-80gb --modules q_proj k_proj v_proj o_proj gate_proj up_proj down_proj --r=8 --experiment_name=all --bs=16   785.533333              NaN                NaN  4.623667  0.635158  3            \n",
      "                                     v1-80gb --modules o_proj down_proj --experiment_name=layers residual out   784.800000              NaN                NaN 15.975667  0.539457  3            \n",
      "                               -80gb --modules gate_proj up_proj down_proj --experiment_name=attn.down mlp.up   716.550000       613.221816          16.850050  2.273000  0.499876  2            \n",
      "                              v1-80gb --modules gate_proj up_proj --experiment_name=mlp up largest output dim   631.900000              NaN                NaN 14.600000       NaN  2            \n",
      "                                          -80gb --modules q_proj k_proj v_proj --experiment_name=attention up   530.900000       613.221816         -13.424476  6.633500  0.523954  2            \n",
      "                                       -80gb --modules o_proj down_proj --experiment_name=layers residual out   455.650000       613.221816         -25.695729  0.356600  0.619400  2            \n",
      "                                -80gb --modules gate_proj up_proj --experiment_name=mlp up largest output dim   355.800000       613.221816         -41.978581  4.279200  0.410298  2            \n",
      "                                        v1-80gb --modules q_proj k_proj v_proj --experiment_name=attention up   332.466667              NaN                NaN 15.372333  0.696294  3            \n",
      "                                                       v1-80gb --modules v_proj --experiment_name=attention v   181.610000              NaN                NaN  7.889000  0.691660  3            \n",
      "                                                         -80gb --modules v_proj --experiment_name=attention v   175.935000       613.221816         -71.309729  2.329000  0.607167  2            \n",
      "  -80gb --modules q_proj k_proj v_proj o_proj gate_proj up_proj down_proj --r=8 --experiment_name=all --bs=16   123.750000       613.221816         -79.819700  1.861000  0.672580  2            \n",
      "                             v1-80gb --modules gate_proj up_proj down_proj --experiment_name=attn.down mlp.up    36.850000              NaN                NaN 19.980000  0.836889  3            \n",
      "\n",
      "======================================================================\n",
      "Sweep: ablate-wd (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 38\n",
      "     argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "v1-80gb --wd=1e-2   892.250000              NaN                NaN 16.349500  0.472273  2            \n",
      "v1-80gb --wd=1e-6   888.736667              NaN                NaN 12.803667  0.527130  3            \n",
      "v1-80gb --wd=1e-5   886.300000              NaN                NaN  7.801000  0.609513  2            \n",
      "v1-80gb --wd=1e-3   824.250000              NaN                NaN  6.983500  0.509164  2            \n",
      "v1-80gb --wd=1e-1   669.900000              NaN                NaN 11.153000  0.421100  4            \n",
      "v1-80gb --wd=1e-4   647.500000              NaN                NaN  8.675333  0.292721  3            \n",
      "v1-80gb --wd=1e-0   584.900000              NaN                NaN  4.266000  0.544211  2            \n",
      "   v1-80gb --wd=0   574.213333              NaN                NaN 16.609000  0.187732  3            \n",
      "v1-80gb --wd=1e-7   440.333333              NaN                NaN  6.062000  0.327355  3            \n",
      " -80gb --wd=0.001   431.550000       613.221816         -29.625791  5.687700  0.346338  2            \n",
      "  -80gb --wd=0.01   380.900000       613.221816         -37.885445  6.282500  0.592841  2            \n",
      "     -80gb --wd=0   323.150000       613.221816         -47.302919  3.092000  0.341044  2            \n",
      "   -80gb --wd=1.0   233.750000       613.221816         -61.881656  0.768000  0.122255  2            \n",
      "  -80gb --wd=10.0   216.010000       613.221816         -64.774573 -0.381850  0.570633  2            \n",
      "   -80gb --wd=0.1   165.730000       613.221816         -72.973890  1.674000  0.636797  2            \n",
      " -80gb --wd=100.0    31.830000       613.221816         -94.809382  2.422200  0.764262  2            \n",
      "\n",
      "======================================================================\n",
      "Sweep: data-efficiency (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 20\n",
      "                                          argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "    -80gb --max_samples=800 --experiment_name=data_800      984.900       613.221816          60.610724    0.7556  0.845972  1            \n",
      "  v1-80gb --max_samples=100 --experiment_name=data_100      544.985              NaN                NaN   71.9600  0.525860  2            \n",
      "  -80gb --max_samples=2000 --experiment_name=data_2000      508.800       613.221816         -17.028392    3.7930  0.337451  1            \n",
      "    v1-80gb --max_samples=50 --experiment_name=data_50      467.105              NaN                NaN   27.4900  0.645490  2            \n",
      "  v1-80gb --max_samples=400 --experiment_name=data_400      427.700              NaN                NaN   20.5370  0.351905  2            \n",
      "    -80gb --max_samples=100 --experiment_name=data_100      416.000       613.221816         -32.161579    2.3180  0.757371  1            \n",
      "  v1-80gb --max_samples=200 --experiment_name=data_200      347.010              NaN                NaN   12.1330  0.503166  2            \n",
      "      -80gb --max_samples=50 --experiment_name=data_50      284.450       613.221816         -53.613849    0.1425  0.694382  2            \n",
      "v1-80gb --max_samples=2000 --experiment_name=data_2000      214.835              NaN                NaN    5.5185  0.483647  2            \n",
      "  v1-80gb --max_samples=800 --experiment_name=data_800      202.400              NaN                NaN    8.8855  0.584060  2            \n",
      "    -80gb --max_samples=200 --experiment_name=data_200       91.980       613.221816         -85.000534    3.0825  0.750776  2            \n",
      "    -80gb --max_samples=400 --experiment_name=data_400       24.070       613.221816         -96.074830   -0.1255  0.518034  1            \n",
      "\n",
      "======================================================================\n",
      "Sweep: sweep-layers (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 48\n",
      "                                                              argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "               -80gb --loss_depths=0.8 --loss_use_V --loss_modules up_proj      837.000       613.221816          36.492209  6.688000  0.800346  1            \n",
      "              -80gb --loss_depths=0.01 --loss_use_V --loss_modules up_proj      809.600       613.221816          32.024005  5.730000  0.975825  1            \n",
      " v1-80gb --loss_depths=0.9 --no_loss_use_V --loss_modules o_proj down_proj      739.650              NaN                NaN 19.315000  0.356550  2            \n",
      " v1-80gb --loss_depths=0.6 --no_loss_use_V --loss_modules o_proj down_proj      713.850              NaN                NaN  8.792500  0.437413  2            \n",
      "               -80gb --loss_depths=0.2 --loss_use_V --loss_modules up_proj      643.600       613.221816           4.953866  0.005517  0.710873  1            \n",
      "   -80gb --loss_depths=0.8 --no_loss_use_V --loss_modules o_proj down_proj      625.200       613.221816           1.953320  3.773000  0.954460  1            \n",
      "   -80gb --loss_depths=0.1 --no_loss_use_V --loss_modules o_proj down_proj      579.050       613.221816          -5.572505  3.891200  0.519212  2            \n",
      " v1-80gb --loss_depths=0.7 --no_loss_use_V --loss_modules o_proj down_proj      539.650              NaN                NaN 12.073500  0.200161  2            \n",
      " v1-80gb --loss_depths=0.4 --no_loss_use_V --loss_modules o_proj down_proj      518.750              NaN                NaN 19.365000  0.494039  2            \n",
      " v1-80gb --loss_depths=0.8 --no_loss_use_V --loss_modules o_proj down_proj      514.350              NaN                NaN 15.525000  0.302130  2            \n",
      " v1-80gb --loss_depths=0.5 --no_loss_use_V --loss_modules o_proj down_proj      475.450              NaN                NaN 12.885500  0.359584  2            \n",
      " v1-80gb --loss_depths=0.2 --no_loss_use_V --loss_modules o_proj down_proj      472.800              NaN                NaN 10.599500  0.288365  2            \n",
      "               -80gb --loss_depths=0.3 --loss_use_V --loss_modules up_proj      446.200       613.221816         -27.236770  8.566000  0.920138  1            \n",
      "v1-80gb --loss_depths=0.99 --no_loss_use_V --loss_modules o_proj down_proj      444.500              NaN                NaN 15.007000  0.139745  2            \n",
      "  -80gb --loss_depths=0.99 --no_loss_use_V --loss_modules o_proj down_proj      437.000       613.221816         -28.737043 -0.079840  0.571709  1            \n",
      "   -80gb --loss_depths=0.2 --no_loss_use_V --loss_modules o_proj down_proj      431.100       613.221816         -29.699174  4.140500  0.695597  2            \n",
      "v1-80gb --loss_depths=0.01 --no_loss_use_V --loss_modules o_proj down_proj      409.200              NaN                NaN 17.590000  0.534384  2            \n",
      "               -80gb --loss_depths=0.7 --loss_use_V --loss_modules up_proj      395.600       613.221816         -35.488270  1.095000  0.288669  1            \n",
      "   -80gb --loss_depths=0.9 --no_loss_use_V --loss_modules o_proj down_proj      360.300       613.221816         -41.244752  2.975000  0.325191  1            \n",
      "               -80gb --loss_depths=0.5 --loss_use_V --loss_modules up_proj      357.400       613.221816         -41.717664  1.668000  0.159039  1            \n",
      "   -80gb --loss_depths=0.6 --no_loss_use_V --loss_modules o_proj down_proj      347.600       613.221816         -43.315781  1.428000  0.304653  1            \n",
      "               -80gb --loss_depths=0.4 --loss_use_V --loss_modules up_proj      344.100       613.221816         -43.886536  5.147000  0.843387  1            \n",
      " v1-80gb --loss_depths=0.3 --no_loss_use_V --loss_modules o_proj down_proj      292.865              NaN                NaN  6.496500  0.256621  2            \n",
      "               -80gb --loss_depths=0.6 --loss_use_V --loss_modules up_proj      283.800       613.221816         -53.719846  1.629000  0.143442  1            \n",
      "              -80gb --loss_depths=0.99 --loss_use_V --loss_modules up_proj      273.100       613.221816         -55.464729  0.800700  0.045059  1            \n",
      "               -80gb --loss_depths=0.9 --loss_use_V --loss_modules up_proj      213.800       613.221816         -65.134965  5.634000  0.246571  1            \n",
      "  -80gb --loss_depths=0.01 --no_loss_use_V --loss_modules o_proj down_proj      191.750       613.221816         -68.730728  4.103150  0.421719  2            \n",
      "   -80gb --loss_depths=0.7 --no_loss_use_V --loss_modules o_proj down_proj      153.400       613.221816         -74.984582  5.564000  0.256554  1            \n",
      " v1-80gb --loss_depths=0.1 --no_loss_use_V --loss_modules o_proj down_proj      134.400              NaN                NaN  6.161500  0.802744  2            \n",
      "   -80gb --loss_depths=0.3 --no_loss_use_V --loss_modules o_proj down_proj      134.395       613.221816         -78.083787  3.350100  0.124857  2            \n",
      "               -80gb --loss_depths=0.1 --loss_use_V --loss_modules up_proj      108.600       613.221816         -82.290258  0.972400  0.142747  1            \n",
      "   -80gb --loss_depths=0.4 --no_loss_use_V --loss_modules o_proj down_proj       83.610       613.221816         -86.365456  0.635500  0.100791  1            \n",
      "   -80gb --loss_depths=0.5 --no_loss_use_V --loss_modules o_proj down_proj       83.010       613.221816         -86.463300  0.529900  0.292521  1            \n",
      "\n",
      "======================================================================\n",
      "Sweep: sweep-long-training (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 7\n",
      "         argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "lr=1e-4 --n_epochs=60        56.76       613.221816         -90.743969  0.254100  0.639216  1            \n",
      "lr=3e-4 --n_epochs=40        51.51       613.221816         -91.600103  0.675100  0.590538  1            \n",
      "lr=1e-4 --n_epochs=40        47.23       613.221816         -92.298056  0.121300  0.588878  1            \n",
      "lr=3e-4 --n_epochs=60        46.88       613.221816         -92.355132  0.555600  0.706513  1            \n",
      "lr=3e-4 --n_epochs=20        40.22       613.221816         -93.441199  0.750800  0.765043  1            \n",
      "lr=1e-4 --n_epochs=20        40.07       613.221816         -93.465660 -0.009514  0.636196  1            \n",
      "lr=1e-3 --n_epochs=20        13.73       613.221816         -97.761006  0.884900  0.145275  1            \n",
      "\n",
      "======================================================================\n",
      "Sweep: sweep-layers-V (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 31\n",
      "                                        argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      " loss_depths=0.2 --loss_use_V --loss_modules up_proj   824.233333              NaN                NaN 11.270000  0.614382  3            \n",
      " loss_depths=0.7 --loss_use_V --loss_modules up_proj   755.000000              NaN                NaN 12.502667  0.348001  3            \n",
      " loss_depths=0.6 --loss_use_V --loss_modules up_proj   543.366667              NaN                NaN 17.311000  0.452544  3            \n",
      " loss_depths=0.4 --loss_use_V --loss_modules up_proj   416.966667              NaN                NaN  9.869333  0.409642  3            \n",
      " loss_depths=0.8 --loss_use_V --loss_modules up_proj   404.233333              NaN                NaN 16.618667  0.470013  3            \n",
      " loss_depths=0.1 --loss_use_V --loss_modules up_proj   387.900000              NaN                NaN 14.189667  0.455222  3            \n",
      "loss_depths=0.01 --loss_use_V --loss_modules up_proj   315.550000              NaN                NaN  7.912333  0.490216  3            \n",
      " loss_depths=0.3 --loss_use_V --loss_modules up_proj   295.775000              NaN                NaN 13.933500  0.501562  2            \n",
      " loss_depths=0.5 --loss_use_V --loss_modules up_proj   286.066667              NaN                NaN 18.162667  0.577469  3            \n",
      " loss_depths=0.9 --loss_use_V --loss_modules up_proj   241.366667              NaN                NaN 12.850667  0.602603  3            \n",
      "loss_depths=0.99 --loss_use_V --loss_modules up_proj   121.480000              NaN                NaN 18.231500  0.486210  2            \n",
      "\n",
      "======================================================================\n",
      "Sweep: sweep-scale (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 7\n",
      "    argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "scale_s=add_tanh   426.966667              NaN                NaN  9.428333  0.598256  3            \n",
      "    scale_s=add2   179.536667              NaN                NaN  9.205000  0.640090  3            \n",
      "    scale_s=none    95.120000              NaN                NaN  5.547000  0.386004  1            \n",
      "\n",
      "======================================================================\n",
      "Sweep: sweep-snorm (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 29\n",
      "                                                        argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "  80gb --loss_snorm --pref_dir_method=top_diff_snorm --pref_dir_k=32   822.550000       613.221816          34.135802 14.796000  0.652666  2            \n",
      "                                                   80gb --loss_snorm   804.333333       613.221816          31.165153 12.110333  0.373608  3            \n",
      "            24gb --loss_snorm --pref_dir_method=mean --pref_dir_k=32   794.350000       613.221816          29.537140       NaN  0.524688  2            \n",
      "           80gb --loss_snorm --pref_dir_method=top_s --pref_dir_k=32   788.600000       613.221816          28.599469 26.315000  0.348417  2            \n",
      "            80gb --loss_snorm --pref_dir_method=mean --pref_dir_k=32   751.600000       613.221816          22.565763 23.670000  0.423518  2            \n",
      "                                                80gb --no_loss_snorm   710.800000       613.221816          15.912380 16.579000  0.750051  2            \n",
      "                                                   24gb --loss_snorm   662.250000       613.221816           7.995179       NaN  0.560965  2            \n",
      "            24gb --loss_snorm --pref_dir_method=pca2 --pref_dir_k=32   537.950000       613.221816         -12.274810       NaN  0.160952  2            \n",
      "            80gb --loss_snorm --pref_dir_method=pca2 --pref_dir_k=32   454.250000       613.221816         -25.924031  4.214500  0.373845  2            \n",
      "80gb --loss_snorm --pref_dir_method=adapter_dims_raw --pref_dir_k=32   320.800000       613.221816         -47.686140 13.799000  0.033643  2            \n",
      "           24gb --loss_snorm --pref_dir_method=top_s --pref_dir_k=32   318.320000       613.221816         -48.090562       NaN  0.467681  2            \n",
      "        80gb --loss_snorm --pref_dir_method=top_diff --pref_dir_k=32   234.900000       613.221816         -61.694122  5.861500  0.671619  2            \n",
      "                                                24gb --no_loss_snorm   164.800000       613.221816         -73.125548       NaN  0.201527  2            \n",
      "        24gb --loss_snorm --pref_dir_method=top_diff --pref_dir_k=32   133.760000       613.221816         -78.187338       NaN  0.370331  2            \n",
      "\n",
      "======================================================================\n",
      "Sweep: sweep-pref-dir (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 36\n",
      "                                           argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "           80gb --pref_dir_method=top_s --pref_dir_k=32       876.90       613.221816          42.998826   32.4200  0.213272  1            \n",
      "             80gb --pref_dir_method=pca2 --pref_dir_k=8       821.90       613.221816          34.029804    5.4610  0.802889  1            \n",
      "            80gb --pref_dir_method=pca2 --pref_dir_k=32       821.20       613.221816          33.915653    7.2140  0.481681  1            \n",
      "80gb --pref_dir_method=adapter_dims_raw --pref_dir_k=64       731.70       613.221816          19.320608   15.6300  0.209425  1            \n",
      "    24gb --pref_dir_method=adapter_dims --pref_dir_k=32       697.50       613.221816          13.743507       NaN  0.943226  1            \n",
      "    80gb --pref_dir_method=adapter_dims --pref_dir_k=16       658.50       613.221816           7.383655   22.1600  0.453611  1            \n",
      "     24gb --pref_dir_method=adapter_dims --pref_dir_k=8       649.10       613.221816           5.850768       NaN  0.628398  1            \n",
      " 24gb --pref_dir_method=adapter_dims_raw --pref_dir_k=8       645.20       613.221816           5.214783       NaN  0.173364  1            \n",
      "        80gb --pref_dir_method=top_diff --pref_dir_k=64       583.30       613.221816          -4.879444   25.1700  0.434667  1            \n",
      "  80gb --pref_dir_method=top_diff_snorm --pref_dir_k=32       569.30       613.221816          -7.162468    5.8680  0.259368  1            \n",
      "        80gb --pref_dir_method=top_diff --pref_dir_k=16       542.20       613.221816         -11.581750   22.1400  0.664444  1            \n",
      "    80gb --pref_dir_method=adapter_dims --pref_dir_k=32       531.70       613.221816         -13.294018    3.7600  0.502560  1            \n",
      "            80gb --pref_dir_method=pca4 --pref_dir_k=16       528.70       613.221816         -13.783237   31.3400  0.142708  1            \n",
      "     80gb --pref_dir_method=adapter_dims --pref_dir_k=8       512.60       613.221816         -16.408714    4.7040  0.261557  1            \n",
      "  80gb --pref_dir_method=top_diff_snorm --pref_dir_k=16       431.60       613.221816         -29.617638    4.5140  0.474699  1            \n",
      "    80gb --pref_dir_method=adapter_dims --pref_dir_k=64       417.70       613.221816         -31.884354   36.4200  0.204449  1            \n",
      "           80gb --pref_dir_method=top_s --pref_dir_k=16       375.70       613.221816         -38.733426   22.4300  0.358697  1            \n",
      "80gb --pref_dir_method=adapter_dims_raw --pref_dir_k=16       371.40       613.221816         -39.434640   19.2600  0.973652  1            \n",
      "            80gb --pref_dir_method=pca4 --pref_dir_k=32       319.80       613.221816         -47.849213    6.6920  0.365310  1            \n",
      "            80gb --pref_dir_method=pca2 --pref_dir_k=16       299.90       613.221816         -51.094369    6.3870  0.743884  1            \n",
      "                            24gb --pref_dir_method=mean       299.50       613.221816         -51.159598    2.9465  0.628601  2            \n",
      "   80gb --pref_dir_method=top_diff_snorm --pref_dir_k=8       292.20       613.221816         -52.350032   21.9800  0.622503  1            \n",
      "             80gb --pref_dir_method=pca4 --pref_dir_k=8       291.10       613.221816         -52.529412    6.4790  0.981584  1            \n",
      "            24gb --pref_dir_method=pca2 --pref_dir_k=16       277.00       613.221816         -54.828743    1.2680  0.902999  1            \n",
      "           80gb --pref_dir_method=top_s --pref_dir_k=64       229.20       613.221816         -62.623639    5.6720  0.347656  1            \n",
      " 80gb --pref_dir_method=adapter_dims_raw --pref_dir_k=8       226.00       613.221816         -63.145473    5.4280  0.228459  1            \n",
      "         24gb --pref_dir_method=top_diff --pref_dir_k=8       223.00       613.221816         -63.634692       NaN  0.294090  1            \n",
      "            80gb --pref_dir_method=top_s --pref_dir_k=8       210.60       613.221816         -65.656799    7.3520  0.322451  1            \n",
      "        80gb --pref_dir_method=top_diff --pref_dir_k=32        83.37       613.221816         -86.404593   29.6300  0.708134  1            \n",
      "                            24gb --pref_dir_method=pca1        80.72       613.221816         -86.836737    2.2920  0.129841  2            \n",
      "         80gb --pref_dir_method=top_diff --pref_dir_k=8        60.23       613.221816         -90.178105   16.1200  0.048814  1            \n",
      "            24gb --pref_dir_method=pca2 --pref_dir_k=32        47.42       613.221816         -92.267072    3.0050  0.985375  1            \n",
      "            24gb --pref_dir_method=top_s --pref_dir_k=8        35.12       613.221816         -94.272872    1.0800  0.798812  1            \n",
      "           24gb --pref_dir_method=top_s --pref_dir_k=16        12.24       613.221816         -98.003985    0.1374  0.792364  1            \n",
      "\n",
      "======================================================================\n",
      "Sweep: sweep-training-stages (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 40\n",
      "   argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "        1025-7B     796.1400        86.765476         817.576942   3.01058  0.469488  5            \n",
      "   7B-Think-SFT     435.2520       363.276961          19.812718   3.02552  0.250623  5            \n",
      "   7B-Think-DPO     392.0520       428.024712          -8.404354   4.08764  0.096931  5            \n",
      "7B-Instruct-SFT     352.2300       524.281534         -32.816631   6.35200  0.493652  5            \n",
      "       7B-Think     248.3900       428.090700         -41.977249   4.59408  0.428029  5            \n",
      "7B-Instruct-DPO     205.6860       531.920017         -61.331404   4.59480  0.591776  5            \n",
      "    7B-Instruct     184.8986       466.533489         -60.367561   8.53620  0.723979  5            \n",
      " 7B-RL-Zero-Mix     161.0240       154.791595           4.026320   3.79422  0.555920  5            \n",
      "\n",
      "======================================================================\n",
      "Sweep: sweep-loss-modules (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 8\n",
      "                             argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "        loss_modules q_proj k_proj v_proj        864.4       613.221816          40.960412    6.1350  0.706579  1            \n",
      "                      loss_modules=v_proj        538.8       613.221816         -12.136198   16.7785  0.245446  2            \n",
      "                     loss_modules=up_proj        452.0       613.221816         -26.290946   27.6950  0.194990  2            \n",
      "                     loss_modules up_proj        318.2       613.221816         -48.110130   20.3400  0.076307  1            \n",
      "                      loss_modules v_proj        234.5       613.221816         -61.759351    4.0750  0.666228  1            \n",
      "loss_modules q_proj k_proj v_proj up_proj        128.8       613.221816         -78.996181    3.3080  0.631998  1            \n",
      "\n",
      "======================================================================\n",
      "Sweep: ablation (control: argv_varying)\n",
      "======================================================================\n",
      "Runs: 54\n",
      "                                                                                                                                                           argv_varying  main_metric  prompting_score  gain_vs_prompting  loss_gap  symmetry  n is_baseline\n",
      "                                                                                                                             4b-80gb --mono_weight=1000 --coh_weight=.1  1650.000000       613.221816         169.070662 -0.258800  0.531245  1            \n",
      "                                                       4b-80gb --model_name=Qwen/Qwen3-4B-Base --rot_u --scale_s=mult --lr=2e-3 --n_epochs=20 --max_rotation_angle=0.15  1476.000000        15.417014        9473.838542  3.522000  0.147511  1            \n",
      "                                                                                                        4b-80gb --model_name=Qwen/Qwen3-4B-Base --lr=2e-3 --n_epochs=10  1333.000000        15.417014        8546.291854  0.591300  0.761134  1            \n",
      "                                                                                                                                 4b-80gb --lr=1e-2 --n_epochs=10 --wd=1  1049.633333       613.221816          71.166992  5.466333  0.789572  3            \n",
      "                                                                                                                4b-80gb --scale_s=add2 --rot_u --max_rotation_angle=0.2   992.900000       613.221816          61.915309  0.725500  0.667095  1            \n",
      "                                                                                                                                              4b-80gb --depth_start=0.1   987.900000       613.221816          61.099944  8.873000  0.304136  1            \n",
      "                                                                                                      4b-80gb --scale_s=mult --max_rotation_angle=0.1 --lr=1e-2 --rot_u   978.700000       613.221816          59.599671  9.834000  0.540504  1            \n",
      "                                                                                                   4b-80gb --scale_s=mult --max_rotation_angle=0.4 --lr=1e-2 --no_rot_u   972.800000       613.221816          58.637539  1.594000  0.875572  1            \n",
      "                                                                                                      4b-80gb --scale_s=add2 --max_rotation_angle=0.1 --lr=1e-2 --rot_u   951.500000       613.221816          55.164082  1.357000  0.954885  1            \n",
      "                                                                                                                                                  4b-80gb --n_depths=12   833.100000       613.221816          35.856223  3.185000  0.756893  1            \n",
      "                                                                                                                     4b-80gb --lr=1e-2 --loss_depths=0.8 --scale_s=add2   782.500000       613.221816          27.604723  1.128000  0.324780  1            \n",
      "                                                                                       4b-80gb --scale_s=mult --rot_u --lr=2e-3 --n_epochs=20 --max_rotation_angle=0.15   716.100000       613.221816          16.776667  9.466000  0.621793  1            \n",
      "                                                                                                                            4b-80gb --val_every_n_samples=512 --lr=4e-3   691.900000       613.221816          12.830298  5.661000  0.916482  1            \n",
      "                                                                                                                        4b-80gb --scale_s=none --max_rotation_angle=1.0   626.200000       613.221816           2.116393  8.682000  0.502113  1            \n",
      "                                                                                                       4b-80gb --rot_u --lr=2e-3 --n_epochs=20 --max_rotation_angle=0.2   610.500000       613.221816          -0.443855  8.194000  0.719714  1            \n",
      "                                                                                                                                                   4b-80gb --n_depths=8   587.300000       613.221816          -4.227152  3.619000  0.731518  1            \n",
      "                                                                                                        4b-80gb --model_name=Qwen/Qwen3-4B-Base --lr=3e-3 --n_epochs=10   566.700000        15.417014        3575.809148  1.006000  0.070151  1            \n",
      "                                                                                                                            4b-80gb --val_every_n_samples=128 --lr=4e-3   558.800000       613.221816          -8.874736  7.087000  0.397669  1            \n",
      "                                                                                                   4b-80gb --scale_s=add2 --max_rotation_angle=0.4 --lr=2e-3 --no_rot_u   553.900000       613.221816          -9.673794  4.169000  0.779910  1            \n",
      "4b-80gb --model_name=Qwen/Qwen3-4B-Base --rot_u --modules q_proj k_proj v_proj o_proj gate_proj up_proj down_proj --r=8 --lr=3e-3 --n_epochs=30 --wd=0.001 --loss_use_V   543.100000        15.417014        3422.731512  4.295000  0.695557  1            \n",
      "                                                                                                                                                 4b-80gb --scale_s=mult   534.300000       613.221816         -12.870027  8.418000  0.368498  1            \n",
      "                                                                                                                                              4b-80gb --depth_start=0.3   497.100000       613.221816         -18.936348  4.796000  0.325567  1            \n",
      "                                                                                                                         4b-80gb --scale_s=mult --lr=2e-3 --n_epochs=10   479.700000       613.221816         -21.773820  1.528000  0.611895  1            \n",
      "                                                                                                                     4b-80gb --lr=8e-3 --loss_depths=0.8 --scale_s=add2   448.500000       613.221816         -26.861702  7.429000  0.263626  1            \n",
      "                                                                                                                                                 4b-80gb --depth_end=-5   442.600000       613.221816         -27.823833  0.054160  0.099570  1            \n",
      "                                                                                                                                                   4b-80gb --n_depths=5   351.800000       613.221816         -42.630873  0.822600  0.482931  1            \n",
      "                                                                                                      4b-80gb --scale_s=add2 --max_rotation_angle=0.6 --lr=2e-2 --rot_u   349.100000       613.221816         -43.071171  9.650000  0.120482  1            \n",
      "                                                                                                                                             4b-80gb --no_coh --no_mono   338.500000       613.221816         -44.799746  0.004406  0.059318  1            \n",
      "                                                                                                4b-80gb --rot_u --r=64 --lr=2e-3 --n_epochs=20 --max_rotation_angle=0.1   326.600000       613.221816         -46.740316  9.227000  0.587037  1            \n",
      "                                                                                                                                                       4b-80gb --no_coh   326.100000       613.221816         -46.821853  0.109900  0.451132  1            \n",
      "                                                                                                                   14b-80gb --model_name=wassname/qwen-14B-codefourchan   284.350000       339.738163         -16.303191  2.323000  0.426759  2            \n",
      "                                                                                                                                                   4b-80gb --n_depths=3   264.900000       613.221816         -56.801928  1.525000  0.793594  1            \n",
      "                                                                                                                                                      4b-80gb --no_mono   213.700000       613.221816         -65.151272  0.893800  0.588507  1            \n",
      "                                                                                    4b-80gb --no-loss_use_V --loss_depths=0.6 --loss_modules o_proj down_proj --lr=3e-3   207.300000       613.221816         -66.194940  0.906500  0.007919  1            \n",
      "                                                                                                      4b-80gb --scale_s=add2 --max_rotation_angle=0.2 --lr=2e-3 --rot_u   175.200000       613.221816         -71.429588  0.881900  0.317522  1            \n",
      "                                 4b-80gb --rot_u --modules q_proj k_proj v_proj o_proj gate_proj up_proj down_proj --r=8 --no-loss_use_V --lr=3e-4 --n_epochs=60 --wd=1   144.820000       613.221816         -76.383750  0.177533  0.862059  3            \n",
      "                                                                                                      4b-80gb --scale_s=add2 --max_rotation_angle=0.6 --lr=2e-4 --rot_u   127.900000       613.221816         -79.142947  0.766600  0.853234  1            \n",
      "                                    4b-80gb --rot_u --modules q_proj k_proj v_proj o_proj gate_proj up_proj down_proj --r=8 --loss_use_V --lr=3e-4 --n_epochs=60 --wd=1   125.585000       613.221816         -79.520461 -0.161130  0.856036  2            \n",
      "                                                                                                                                              4b-80gb --depth_start=0.5   104.200000       613.221816         -83.007780  1.297000  0.565363  1            \n",
      "                                                                                                                           4b-80gb --mono_weight=1000 --coh_weight=1000    88.910000       613.221816         -85.501168 31.010000  0.032370  1            \n",
      "                                                                                    4b-80gb --no-loss_use_V --loss_depths=0.5 --loss_modules o_proj down_proj --lr=3e-3    88.100000       613.221816         -85.633257  0.329100  0.522578  1            \n",
      "                                                                                                                                                   4b-80gb --n_depths=1    83.680000       613.221816         -86.354041 -0.386100  0.144202  1            \n",
      "                                                      4b-80gb --modules v_proj o_proj gate_proj up_proj down_proj --r=16 --no-loss_use_V --lr=3e-4 --n_epochs=60 --wd=1    72.935000       613.221816         -88.106261  0.797885  0.873465  2            \n",
      "                                                                                                                     4b-80gb --lr=2e-3 --loss_depths=0.8 --scale_s=add2    69.590000       613.221816         -88.651741  0.612800  0.130836  1            \n",
      "                                                                                                                                                 4b-80gb --depth_end=-1    21.740000       613.221816         -96.454790  0.965700  0.886145  1            \n",
      "                                                          4b-80gb --modules v_proj o_proj gate_proj up_proj down_proj --r=8 --loss_use_V --lr=3e-4 --n_epochs=60 --wd=1    21.400000       613.221816         -96.510235 -1.154000  0.487945  1            \n",
      "                                                                                                                                                       4b-80gb --wd=100     4.102000       613.221816         -99.331074 -0.642000  0.054054  1            \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Show each sweep\n",
    "for sweep_name, config in SWEEP_CONFIG.items():\n",
    "    if sweep_name not in sweeps:\n",
    "        continue\n",
    "    \n",
    "    df_s = sweeps[sweep_name]\n",
    "    control_var = config['var']\n",
    "    \n",
    "    summary_df, actual_var = summarize_sweep_mean(df_s, control_var, config['baseline'])\n",
    "    \n",
    "    if summary_df is not None:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Sweep: {sweep_name} (control: {actual_var})\")\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"Runs: {len(df_s)}\")\n",
    "        print(summary_df.to_string(index=False))\n",
    "    else:\n",
    "        print(f\"\\n{sweep_name}: Could not find '{control_var}' column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55400f24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "948e6822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cross-run ranking (latest 5 runs of each sweep type) ===\n",
      "\n",
      "\n",
      "ablate-constraints (merged 5 runs, control=argv):\n",
      "                                                                 control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      "                                                    q4b-80gb --mono --no_coh      1.000000       NaN       1  819.100000\n",
      "                                                q4bv1-80gb --no_coh_adaptive      0.954545  0.064282       2  799.250000\n",
      "                                                     q4b-80gb --scale_s=none      0.850000  0.070711       2  441.000000\n",
      "                                                  q4b-80gb --no_coh_adaptive      0.850000  0.212132       2  256.200000\n",
      "                                               q4bv1-80gb --rot_u --no_rot_v      0.809091  0.086722       3  491.833333\n",
      "                                                  q4bv1-80gb --no_mono --coh      0.768182  0.186419       2  543.900000\n",
      "                                                  q4b-80gb --data_aware_init      0.700000  0.141421       2  230.370000\n",
      "                              q4bv1-80gb --loss_use_V --loss_modules up_proj      0.606061  0.209157       3  304.633333\n",
      "                                                    q4b-80gb --no_mono --coh      0.600000       NaN       1  301.600000\n",
      "q4bv1-80gb --no_loss_use_V --loss_depths=0.5 --loss_modules o_proj down_proj      0.600000  0.458258       3  400.906667\n",
      "                                             q4bv1-80gb --no_data_aware_init      0.515152  0.026243       3  244.933333\n",
      "                                                                    q4b-80gb      0.500000       NaN       1  183.900000\n",
      "                                                                  q4bv1-80gb      0.430303  0.355515       3  206.063333\n",
      "                                                   q4bv1-80gb --scale_s=none      0.427273  0.497681       3  273.696667\n",
      "                                               q4bv1-80gb --no_mono --no_coh      0.421212  0.254924       3  133.923333\n",
      "              q4b-80gb --loss_use_V --loss_depths=0.8 --loss_modules up_proj      0.400000       NaN       1   43.910000\n",
      "                                                 q4b-80gb --no_mono --no_coh      0.400000       NaN       1  165.900000\n",
      "                                                  q4bv1-80gb --mono --no_coh      0.357576  0.213071       3  139.370000\n",
      "                                            q4bv1-80gb --no_rot_u --no_rot_v      0.351515  0.089227       3   82.220000\n",
      "  q4b-80gb --no_loss_use_V --loss_depths=0.5 --loss_modules o_proj down_proj      0.250000  0.070711       2   31.440000\n",
      "                                              q4b-80gb --no_rot_u --no_rot_v      0.200000       NaN       1   14.700000\n",
      "                                q4b-80gb --loss_use_V --loss_modules up_proj      0.100000       NaN       1   10.100000\n",
      "   Avg rank std: 0.196 (lower = more reproducible)\n",
      "\n",
      "ablate-modules (merged 5 runs, control=argv):\n",
      "                                                                                                     control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      "q4bv1-80gb --modules q_proj k_proj v_proj o_proj gate_proj up_proj down_proj --r=8 --experiment_name=all --bs=16      0.888889  0.192450       3  785.533333\n",
      "                                          q4b-80gb --modules q_proj k_proj v_proj --experiment_name=attention up      0.833333  0.000000       2  530.900000\n",
      "                               q4b-80gb --modules gate_proj up_proj down_proj --experiment_name=attn.down mlp.up      0.833333  0.235702       2  716.550000\n",
      "                                     q4bv1-80gb --modules o_proj down_proj --experiment_name=layers residual out      0.811111  0.200924       3  784.800000\n",
      "                                       q4b-80gb --modules o_proj down_proj --experiment_name=layers residual out      0.750000  0.353553       2  455.650000\n",
      "                              q4bv1-80gb --modules gate_proj up_proj --experiment_name=mlp up largest output dim      0.666667  0.235702       2  631.900000\n",
      "                                        q4bv1-80gb --modules q_proj k_proj v_proj --experiment_name=attention up      0.600000  0.240370       3  332.466667\n",
      "                                q4b-80gb --modules gate_proj up_proj --experiment_name=mlp up largest output dim      0.416667  0.353553       2  355.800000\n",
      "                                                       q4bv1-80gb --modules v_proj --experiment_name=attention v      0.411111  0.083887       3  181.610000\n",
      "  q4b-80gb --modules q_proj k_proj v_proj o_proj gate_proj up_proj down_proj --r=8 --experiment_name=all --bs=16      0.333333  0.000000       2  123.750000\n",
      "                                                         q4b-80gb --modules v_proj --experiment_name=attention v      0.333333  0.235702       2  175.935000\n",
      "                             q4bv1-80gb --modules gate_proj up_proj down_proj --experiment_name=attn.down mlp.up      0.177778  0.019245       3   36.850000\n",
      "   Avg rank std: 0.179 (lower = more reproducible)\n",
      "\n",
      "ablate-wd (merged 5 runs, control=argv):\n",
      "         control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      " q4b-80gb --wd=0.001      0.928571  0.101015       2  431.550000\n",
      "q4bv1-80gb --wd=1e-2      0.850000  0.212132       2  892.250000\n",
      "  q4b-80gb --wd=0.01      0.785714  0.303046       2  380.900000\n",
      "     q4b-80gb --wd=0      0.785714  0.101015       2  323.150000\n",
      "q4bv1-80gb --wd=1e-5      0.700000  0.141421       2  886.300000\n",
      "q4bv1-80gb --wd=1e-3      0.650000  0.353553       2  824.250000\n",
      "   q4bv1-80gb --wd=0      0.633333  0.472582       3  574.213333\n",
      "q4bv1-80gb --wd=1e-4      0.616667  0.368556       3  647.500000\n",
      "q4bv1-80gb --wd=1e-6      0.533333  0.450925       3  888.736667\n",
      "   q4b-80gb --wd=0.1      0.500000  0.303046       2  165.730000\n",
      "   q4b-80gb --wd=1.0      0.500000  0.101015       2  233.750000\n",
      "q4bv1-80gb --wd=1e-1      0.425000  0.095743       4  669.900000\n",
      "q4bv1-80gb --wd=1e-7      0.416667  0.246644       3  440.333333\n",
      "q4bv1-80gb --wd=1e-0      0.400000  0.282843       2  584.900000\n",
      "  q4b-80gb --wd=10.0      0.357143  0.101015       2  216.010000\n",
      " q4b-80gb --wd=100.0      0.142857  0.000000       2   31.830000\n",
      "   Avg rank std: 0.227 (lower = more reproducible)\n",
      "\n",
      "ablation (merged 5 runs, control=argv):\n",
      "                                                                                                                                                             control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      "                                                       q4b-80gb --model_name=Qwen/Qwen3-4B-Base --rot_u --scale_s=mult --lr=2e-3 --n_epochs=20 --max_rotation_angle=0.15      1.000000       NaN       1 1476.000000\n",
      "                                                                                                                             q4b-80gb --mono_weight=1000 --coh_weight=.1      1.000000       NaN       1 1650.000000\n",
      "                                                                                                        q4b-80gb --model_name=Qwen/Qwen3-4B-Base --lr=2e-3 --n_epochs=10      0.964286       NaN       1 1333.000000\n",
      "                                                                                                                                 q4b-80gb --lr=1e-2 --n_epochs=10 --wd=1      0.947368  0.091161       3 1049.633333\n",
      "                                                                                                                                              q4b-80gb --depth_start=0.1      0.947368       NaN       1  987.900000\n",
      "                                                                                                                q4b-80gb --scale_s=add2 --rot_u --max_rotation_angle=0.2      0.928571       NaN       1  992.900000\n",
      "                                                                                                                                                  q4b-80gb --n_depths=12      0.894737       NaN       1  833.100000\n",
      "                                                                                                      q4b-80gb --scale_s=mult --max_rotation_angle=0.1 --lr=1e-2 --rot_u      0.892857       NaN       1  978.700000\n",
      "                                                                                                   q4b-80gb --scale_s=mult --max_rotation_angle=0.4 --lr=1e-2 --no_rot_u      0.857143       NaN       1  972.800000\n",
      "                                                                                                      q4b-80gb --scale_s=add2 --max_rotation_angle=0.1 --lr=1e-2 --rot_u      0.821429       NaN       1  951.500000\n",
      "                                                                                                                                                   q4b-80gb --n_depths=8      0.789474       NaN       1  587.300000\n",
      "                                                                                                                     q4b-80gb --lr=1e-2 --loss_depths=0.8 --scale_s=add2      0.785714       NaN       1  782.500000\n",
      "                                                                                                                   q14b-80gb --model_name=wassname/qwen-14B-codefourchan      0.763158  0.334945       2  284.350000\n",
      "                                                                                       q4b-80gb --scale_s=mult --rot_u --lr=2e-3 --n_epochs=20 --max_rotation_angle=0.15      0.750000       NaN       1  716.100000\n",
      "                                                                                                                                              q4b-80gb --depth_start=0.3      0.736842       NaN       1  497.100000\n",
      "                                                                                                                            q4b-80gb --val_every_n_samples=512 --lr=4e-3      0.714286       NaN       1  691.900000\n",
      "                                                                                                                                                 q4b-80gb --depth_end=-5      0.684211       NaN       1  442.600000\n",
      "                                                                                                                        q4b-80gb --scale_s=none --max_rotation_angle=1.0      0.678571       NaN       1  626.200000\n",
      "                                                                                                       q4b-80gb --rot_u --lr=2e-3 --n_epochs=20 --max_rotation_angle=0.2      0.642857       NaN       1  610.500000\n",
      "                                                                                                                                                   q4b-80gb --n_depths=5      0.631579       NaN       1  351.800000\n",
      "                                                                                                        q4b-80gb --model_name=Qwen/Qwen3-4B-Base --lr=3e-3 --n_epochs=10      0.607143       NaN       1  566.700000\n",
      "                                                                                                                                                   q4b-80gb --n_depths=3      0.578947       NaN       1  264.900000\n",
      "                                                                                                                            q4b-80gb --val_every_n_samples=128 --lr=4e-3      0.571429       NaN       1  558.800000\n",
      "                                    q4b-80gb --rot_u --modules q_proj k_proj v_proj o_proj gate_proj up_proj down_proj --r=8 --loss_use_V --lr=3e-4 --n_epochs=60 --wd=1      0.559211  0.269817       2  125.585000\n",
      "                                                                                                   q4b-80gb --scale_s=add2 --max_rotation_angle=0.4 --lr=2e-3 --no_rot_u      0.535714       NaN       1  553.900000\n",
      "q4b-80gb --model_name=Qwen/Qwen3-4B-Base --rot_u --modules q_proj k_proj v_proj o_proj gate_proj up_proj down_proj --r=8 --lr=3e-3 --n_epochs=30 --wd=0.001 --loss_use_V      0.500000       NaN       1  543.100000\n",
      "                                                                                                                                              q4b-80gb --depth_start=0.5      0.473684       NaN       1  104.200000\n",
      "                                                                                                                                                 q4b-80gb --scale_s=mult      0.464286       NaN       1  534.300000\n",
      "                                                                                                                         q4b-80gb --scale_s=mult --lr=2e-3 --n_epochs=10      0.428571       NaN       1  479.700000\n",
      "                                                                                                                           q4b-80gb --mono_weight=1000 --coh_weight=1000      0.421053       NaN       1   88.910000\n",
      "                                 q4b-80gb --rot_u --modules q_proj k_proj v_proj o_proj gate_proj up_proj down_proj --r=8 --no-loss_use_V --lr=3e-4 --n_epochs=60 --wd=1      0.403509  0.167128       3  144.820000\n",
      "                                                                                                                     q4b-80gb --lr=8e-3 --loss_depths=0.8 --scale_s=add2      0.392857       NaN       1  448.500000\n",
      "                                                                                                      q4b-80gb --scale_s=add2 --max_rotation_angle=0.6 --lr=2e-2 --rot_u      0.357143       NaN       1  349.100000\n",
      "                                                                                                                                             q4b-80gb --no_coh --no_mono      0.321429       NaN       1  338.500000\n",
      "                                                                                                                                                   q4b-80gb --n_depths=1      0.315789       NaN       1   83.680000\n",
      "                                                                                                q4b-80gb --rot_u --r=64 --lr=2e-3 --n_epochs=20 --max_rotation_angle=0.1      0.285714       NaN       1  326.600000\n",
      "                                                      q4b-80gb --modules v_proj o_proj gate_proj up_proj down_proj --r=16 --no-loss_use_V --lr=3e-4 --n_epochs=60 --wd=1      0.256579  0.009304       2   72.935000\n",
      "                                                                                                                                                       q4b-80gb --no_coh      0.250000       NaN       1  326.100000\n",
      "                                                                                                                                                      q4b-80gb --no_mono      0.214286       NaN       1  213.700000\n",
      "                                                                                    q4b-80gb --no-loss_use_V --loss_depths=0.6 --loss_modules o_proj down_proj --lr=3e-3      0.178571       NaN       1  207.300000\n",
      "                                                                                                                                                 q4b-80gb --depth_end=-1      0.157895       NaN       1   21.740000\n",
      "                                                                                                      q4b-80gb --scale_s=add2 --max_rotation_angle=0.2 --lr=2e-3 --rot_u      0.142857       NaN       1  175.200000\n",
      "                                                                                                      q4b-80gb --scale_s=add2 --max_rotation_angle=0.6 --lr=2e-4 --rot_u      0.107143       NaN       1  127.900000\n",
      "                                                          q4b-80gb --modules v_proj o_proj gate_proj up_proj down_proj --r=8 --loss_use_V --lr=3e-4 --n_epochs=60 --wd=1      0.105263       NaN       1   21.400000\n",
      "                                                                                    q4b-80gb --no-loss_use_V --loss_depths=0.5 --loss_modules o_proj down_proj --lr=3e-3      0.071429       NaN       1   88.100000\n",
      "                                                                                                                                                       q4b-80gb --wd=100      0.052632       NaN       1    4.102000\n",
      "                                                                                                                     q4b-80gb --lr=2e-3 --loss_depths=0.8 --scale_s=add2      0.035714       NaN       1   69.590000\n",
      "   Avg rank std: 0.174 (lower = more reproducible)\n",
      "\n",
      "data-efficiency (merged 5 runs, control=sampled_n):\n",
      "control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      "    unknown         0.625   0.30529      20     354.735\n",
      "   Avg rank std: 0.305 (lower = more reproducible)\n",
      "\n",
      "run-models (merged 5 runs, control=model_name):\n",
      "                   control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      "wassname/qwen-14B-codefourchan      0.875000       NaN       1  599.500000\n",
      "                 Qwen/Qwen3-4B      0.833333  0.190941       3 1207.866667\n",
      "            Qwen/Qwen3-4B-Base      0.736111  0.323644       3  856.833333\n",
      "          google/gemma-3-1b-it      0.625000  0.228218       4  534.475000\n",
      "        google/gemma-3-270m-it      0.614583  0.283364       4  585.440000\n",
      "               Qwen/Qwen3-0.6B      0.583333  0.399653       5  385.605000\n",
      "         google/gemma-3-12b-it      0.500000  0.176777       2  374.450000\n",
      "   Qwen/Qwen3-4B-Instruct-2507      0.500000       NaN       1  500.300000\n",
      "          google/gemma-3-4b-it      0.447917  0.306894       4  317.288500\n",
      " unsloth/Llama-3.1-8B-Instruct      0.406250  0.277169       4  204.735000\n",
      "                Qwen/Qwen3-14B      0.125000       NaN       1   42.920000\n",
      "   Avg rank std: 0.273 (lower = more reproducible)\n",
      "\n",
      "sweep-layers (merged 5 runs, control=depth):\n",
      "control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      "    unknown      0.552083  0.290709      48  416.384167\n",
      "   Avg rank std: 0.291 (lower = more reproducible)\n",
      "\n",
      "sweep-layers-V (merged 3 runs, control=depth):\n",
      "control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      "    unknown      0.548387  0.292075      31   430.92129\n",
      "   Avg rank std: 0.292 (lower = more reproducible)\n",
      "\n",
      "sweep-loss-modules (merged 3 runs, control=loss_module_types):\n",
      "control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      "    unknown        0.6875  0.291241       8    440.9375\n",
      "   Avg rank std: 0.291 (lower = more reproducible)\n",
      "\n",
      "sweep-lr (merged 5 runs, control=lr):\n",
      "control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      "      0.001      0.838095  0.118331       5   357.74000\n",
      "       0.01      0.838095  0.204402       5   522.99400\n",
      "        0.1      0.761905  0.220800       5   150.31800\n",
      "      1e-05      0.466667  0.237260       5    61.35400\n",
      "     0.0001      0.433333  0.176897       5    59.38200\n",
      "        1.0      0.304762  0.131923       5    35.89166\n",
      "      1e-06      0.142857  0.000000       2    45.87000\n",
      "   Avg rank std: 0.156 (lower = more reproducible)\n",
      "\n",
      "sweep-pref-dir (merged 4 runs, control=pref_dir):\n",
      "control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      "    unknown      0.555556  0.294055      36  392.606111\n",
      "   Avg rank std: 0.294 (lower = more reproducible)\n",
      "\n",
      "sweep-rank (merged 5 runs, control=r):\n",
      "control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      "        256        0.8700  0.185742       5    391.3200\n",
      "        128        0.6150  0.385519       5    373.4214\n",
      "        512        0.6000  0.353995       5    259.5880\n",
      "          8        0.5625  0.088388       2    186.1500\n",
      "         64        0.5350  0.213307       5    123.9270\n",
      "         32        0.5050  0.258844       5    181.9160\n",
      "         16        0.3750  0.176777       2    136.6500\n",
      "       1024        0.2500  0.176777       2     69.3065\n",
      "   Avg rank std: 0.230 (lower = more reproducible)\n",
      "\n",
      "sweep-rotation-angle (merged 3 runs, control=ipissa_rotation_max_angle):\n",
      "control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      "    unknown      0.546875  0.292008      32    403.8925\n",
      "   Avg rank std: 0.292 (lower = more reproducible)\n",
      "\n",
      "sweep-scale (merged 3 runs, control=ipissa_scale_mode):\n",
      "control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      "    unknown      0.714286  0.284056       7  273.518571\n",
      "   Avg rank std: 0.284 (lower = more reproducible)\n",
      "\n",
      "sweep-snorm (merged 5 runs, control=loss_snorm):\n",
      "control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      "       True      0.593333  0.295921      25    562.0664\n",
      "      False      0.541667  0.343592       4    437.8000\n",
      "   Avg rank std: 0.320 (lower = more reproducible)\n",
      "\n",
      "sweep-training-stages (merged 5 runs, control=training_stage):\n",
      "control_val  avg_rank_pct  std_rank  n_runs  avg_metric\n",
      "    unknown        0.5625   0.29006      40  346.959075\n",
      "   Avg rank std: 0.290 (lower = more reproducible)\n",
      "\n",
      " avg_rank_pct: higher = better ranking within its sweep\n",
      " Merges latest 5 runs of each sweep type to show consistent winners\n"
     ]
    }
   ],
   "source": [
    "# Merge rankings across N=3 latest runs of SAME sweep type\n",
    "\n",
    "print(f\"=== Cross-run ranking (latest {N_LATEST_SWEEPS} runs of each sweep type) ===\\n\")\n",
    "\n",
    "# For each sweep type, take latest N runs and merge their rankings\n",
    "for base in sorted(sweep_by_base.keys()):\n",
    "    files = sweep_by_base[base][:N_LATEST_SWEEPS]  # latest N files for this type\n",
    "    \n",
    "    if len(files) < 2:\n",
    "        continue  # need multiple runs to merge\n",
    "    \n",
    "    if base not in sweeps:\n",
    "        continue\n",
    "    \n",
    "    df_s = sweeps[base]\n",
    "    config = SWEEP_CONFIG.get(base, {})\n",
    "    ctrl = config.get('control_var', 'argv')\n",
    "    \n",
    "    # Collect rankings from each run\n",
    "    run_rankings = []\n",
    "    \n",
    "    for sweep_file in files:\n",
    "        df_this = df_s[df_s['sweep_file'] == sweep_file.name].copy()\n",
    "        \n",
    "        if len(df_this) == 0 or 'main_metric' not in df_this.columns:\n",
    "            continue\n",
    "        \n",
    "        # Rank within this run\n",
    "        df_this['rank_pct'] = df_this['main_metric'].rank(pct=True)\n",
    "        \n",
    "        for _, row in df_this.iterrows():\n",
    "            ctrl_val = str(row.get(ctrl, 'unknown'))\n",
    "            run_rankings.append({\n",
    "                'sweep_file': sweep_file.name,\n",
    "                'control_val': ctrl_val,\n",
    "                'rank_pct': row['rank_pct'],\n",
    "                'main_metric': row['main_metric']\n",
    "            })\n",
    "    \n",
    "    if not run_rankings:\n",
    "        continue\n",
    "    \n",
    "    df_ranks = pd.DataFrame(run_rankings)\n",
    "    \n",
    "    # Average rank for each control value across runs\n",
    "    rank_summary = df_ranks.groupby('control_val').agg({\n",
    "        'rank_pct': ['mean', 'std', 'count'],\n",
    "        'main_metric': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    rank_summary.columns = ['control_val', 'avg_rank_pct', 'std_rank', 'n_runs', 'avg_metric']\n",
    "    rank_summary = rank_summary.sort_values('avg_rank_pct', ascending=False)\n",
    "    \n",
    "    print(f\"\\n{base} (merged {len(files)} runs, control={ctrl}):\")\n",
    "    print(rank_summary.to_string(index=False))\n",
    "    \n",
    "    # Show reproducibility: low std = consistent ranking across runs\n",
    "    if len(rank_summary) > 0:\n",
    "        avg_std = rank_summary['std_rank'].mean()\n",
    "        print(f\"   Avg rank std: {avg_std:.3f} (lower = more reproducible)\")\n",
    "\n",
    "print(\"\\n avg_rank_pct: higher = better ranking within its sweep\")\n",
    "print(f\" Merges latest {N_LATEST_SWEEPS} runs of each sweep type to show consistent winners\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e35a64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d8e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repeng (3.10.16)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
